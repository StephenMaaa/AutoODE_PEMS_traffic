{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0dc8f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "import time\n",
    "import kornia\n",
    "from DNN import Seq2Seq, LWRDataset, LWRDataset_res, train_LWR, eval_LWR, test_LWR, train_hybrid_LWR, eval_hybrid_LWR, test_hybrid_LWR \n",
    "from AutoODE import LWR_batch_version, LWR_seq2seq \n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0e99744",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LWR_seq2seq_joint(nn.Module): \n",
    "    def __init__(self): \n",
    "        super(LWR_seq2seq_joint, self).__init__()\n",
    "        self.LWR_model = model = LWR_batch_version(nx, 300, 6, kj, vf, tskip, plm = False, plm_vf = False, \n",
    "                          initial={}, boundary={}, fix_vf=False, parstep=1).to(device).to(device) \n",
    "\n",
    "        self.residual_model = Seq2Seq(input_dim = 231, hidden_dim = 1024, output_dim = 231, num_layers = 1).to(device)\n",
    "    \n",
    "    def forward(self, xi, x, initial, boundary_in, boundary_out, tsteps, pred_len): \n",
    "        input_len = int(x.shape[2] / 2) + 1 \n",
    "        with torch.no_grad():\n",
    "            pred1 = self.LWR_model(xi, initial[:, 0], boundary_in, tsteps) # first 12\n",
    "        pred = self.LWR_model(xi, initial[:, 1], boundary_out, tsteps) # last 12\n",
    "        # print(pred1.shape, x[:, :, 1:pred_len, 1:].shape)\n",
    "        res = x[:, :, 1:, 1:] - pred1.detach().clone() \n",
    "#         print(x.shape, res.shape)\n",
    "        residual = self.residual_model(res.float(), pred_len) # last 12\n",
    "#         print(residual.shape)\n",
    "#         pred = pred2.detach().clone()\n",
    "        pred += residual # residual[:, :, 1:] \n",
    "#         print(pred.shape, x.shape)\n",
    "        return pred.double() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7742dd0",
   "metadata": {},
   "source": [
    "### Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8189f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = torch.load(\"data_LWR/residual/training_time.pt\").double()\n",
    "# training_initial = torch.load(\"data_LWR/residual/training_time_initial.pt\").double()\n",
    "# training_boundary = torch.load(\"data_LWR/residual/training_time_boundary.pt\").double()\n",
    "# x_train = torch.load(\"data_LWR/residual/x_train.pt\").long()\n",
    "# test_data = torch.load(\"data_LWR/residual/test_time.pt\").double()\n",
    "# test_initial = torch.load(\"data_LWR/residual/test_time_initial.pt\").double()\n",
    "# test_boundary = torch.load(\"data_LWR/residual/test_time_boundary.pt\").double()\n",
    "# x_test = torch.load(\"data_LWR/residual/x_test.pt\").long() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba06507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = torch.load(\"data_LWR/space/training_time.pt\").double()\n",
    "# training_initial = torch.load(\"data_LWR/space/training_time_initial.pt\").double()\n",
    "# training_boundary = torch.load(\"data_LWR/space/training_time_boundary.pt\").double() \n",
    "# test_data = torch.load(\"data_LWR/space/test_time.pt\").double()\n",
    "# test_initial = torch.load(\"data_LWR/space/test_time_initial.pt\").double()\n",
    "# test_boundary = torch.load(\"data_LWR/space/test_time_boundary.pt\").double() \n",
    "# x_train = torch.load(\"data_LWR/space/x_train.pt\").long()\n",
    "# x_test = torch.load(\"data_LWR/space/x_test.pt\").long() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "625d1982",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = torch.load(\"../pems_I5_S_correct.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f31769f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = [0,  45,  56,  75,  81,  86,  89,  95, 100, 105, 109, 112, 117,\n",
    "       124, 128, 133, 137, 141, 146, 149, 152, 158, 163, 167, 171, 174,\n",
    "       180, 186, 192, 197, 200, 205, 207, 210, 211, 213, 214, 228, 231,\n",
    "       237, 240, 242, 251, 254, 258, 262, 266, 270, 277, 279, 282, 283,\n",
    "       286, 288, 291, 294, 296, 298, 300, 303, 308, 310, 315, 317, 320,\n",
    "       322, 327, 338, 342, 345, 352, 356, 359, 362, 366, 368, 374, 379] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8af5fa3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 650 650\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#nx=350  # \n",
    "nx=380 \n",
    "#kj needs to be larger than k for the solution to be stable \n",
    "# kj = np.ones((nx,), dtype=float) * 0.6\n",
    "# kj = (kj - mean[0].numpy()) / std[0].numpy()\n",
    "# kj = (kj - y_min[0].numpy()) / (y_max[0].numpy() - y_min[0].numpy()) # normalize\n",
    "\n",
    "#characteristic velocity (m/s), corresponds to roughly 120 km/h\n",
    "# vf = np.ones((nx,), dtype=float) * 38\n",
    "# vf = (vf - mean[2].numpy()) / std[2].numpy()\n",
    "# vf = (vf - y_min[2].numpy()) / (y_max[2].numpy() - y_min[2].numpy()) # normalize\n",
    "\n",
    "dx=300.\n",
    "\n",
    "## change the timestep to dt = 1, previously dt = 6 with 7 mins runtime\n",
    "dt=6\n",
    "#need an output every 5 mins (300 s), so tskip = 3 with dt = 3s\n",
    "tskip=50\n",
    "#nt=int(3600*6/6 - 50)\n",
    "#nt=7099 #6 hours (times 3600 s/hour divided by dt=3s)\n",
    "nto=13 + 1\n",
    "#nt=int(3600*nto/12/6/dt - tskip)\n",
    "dtobs=300\n",
    "nt=int((dtobs*nto)/dt - tskip) \n",
    "\n",
    "nto=13 + 1\n",
    "#nt=int(3600*nto/12/6/dt - tskip)\n",
    "dtobs=300\n",
    "nt_test=int((dtobs*nto)/dt - tskip)\n",
    "print(dt, nt, nt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f4df69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def interpolate_initial(var, xi, t0=0): \n",
    "    IM_q=interp1d(np.array(xi) * dx, var[1, :].numpy(), bounds_error=False, \n",
    "                fill_value=(var[1, 0], var[1, -1]), kind='linear') \n",
    "    IM_u=interp1d(np.array(xi) * dx, var[2, :].numpy(), bounds_error=False, \n",
    "                fill_value=(var[2, 0], var[2, -1]), kind='linear') \n",
    "    \n",
    "    x=np.linspace(0, (nx-1) * dx, nx) \n",
    "    u = IM_u(x)\n",
    "    q = IM_q(x)\n",
    "    k = q / u\n",
    "    initial = np.stack((k, q, u))\n",
    "    return torch.tensor(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "764173ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ti=np.arange(0, (nt-1)*dt, tskip*dt )\n",
    "t=np.linspace(0, (nt-1)*dt, nt) \n",
    "ti_test=np.arange(0, (nt_test-1)*dt, tskip*dt )\n",
    "t_test = np.linspace(0, (nt_test-1)*dt, nt_test)\n",
    "\n",
    "def interpolate_boundary(var, ti, t): \n",
    "    IM_q=interp1d(np.array(ti), var[1, :, 0].numpy(), bounds_error=False,\n",
    "             fill_value=(var[1, 0, 0], var[1, -1, 0]), kind='linear')\n",
    "    IM_u=interp1d(np.array(ti), var[2, :, 0].numpy(), bounds_error=False,\n",
    "             fill_value=(var[2, 0, 0], var[2, -1, 0]), kind='linear')\n",
    "    u = IM_u(t)\n",
    "    q = IM_q(t)\n",
    "    k = q / u\n",
    "    boundary = np.stack((k, q, u)) \n",
    "    return torch.tensor(boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63439bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_lwr_res(data): \n",
    "#     interpolated = []\n",
    "#     for i in range(data.shape[1]): \n",
    "#         interpolated_d = interpolate_initial(data[:, i, :], xi, t0=0) \n",
    "#         interpolated.append(interpolated_d) \n",
    "#     interpolated_data = torch.stack(interpolated) \n",
    "#     interpolated_data = interpolated_data.permute(1, 0, 2)\n",
    "#     print(interpolated_data.shape) \n",
    "    \n",
    "    training_set_input = [] \n",
    "    training_set_output = [] \n",
    "    test_set_input = [] \n",
    "    test_set_output = []\n",
    "    initial_train = []\n",
    "    boundary_train_in = []\n",
    "    boundary_train_out = []\n",
    "    initial_test = []\n",
    "    boundary_test_in = []\n",
    "    boundary_test_out = []\n",
    "    x_train = []\n",
    "    x_test = []\n",
    "    training_size = int((data.shape[1] - 25) * 0.8) \n",
    "    \n",
    "    for i in range(data.shape[1] - 25): \n",
    "        if i < training_size: \n",
    "            x_train.append(torch.tensor(xi))\n",
    "#             training_set_input.append(data[:, i:i+9, :])\n",
    "#             training_set_output.append(data[:, i+9:i+17, :])\n",
    "#             initial1 = interpolate_initial(data[:, i, :], xi, t0=0)\n",
    "#             boundary1 = interpolate_boundary(data[:, i:i+9, :], ti, t) \n",
    "#             initial2 = interpolate_initial(data[:, i+8, :], xi, t0=0)\n",
    "#             boundary2 = interpolate_boundary(data[:, i+8:i+17, :], ti, t)\n",
    "#             initial = torch.stack([initial1, initial2])\n",
    "#             initial_train.append(initial)\n",
    "#             boundary_train_in.append(boundary1)\n",
    "#             boundary_train_out.append(boundary2)\n",
    "            training_set_input.append(data[:, i:i+13, :])\n",
    "            training_set_output.append(data[:, i+13:i+25, :])\n",
    "            initial1 = interpolate_initial(data[:, i, :], xi, t0=0)\n",
    "            boundary1 = interpolate_boundary(data[:, i:i+13, :], ti, t) \n",
    "            initial2 = interpolate_initial(data[:, i+12, :], xi, t0=0)\n",
    "            boundary2 = interpolate_boundary(data[:, i+12:i+25, :], ti, t)\n",
    "            initial = torch.stack([initial1, initial2])\n",
    "            initial_train.append(initial)\n",
    "            boundary_train_in.append(boundary1)\n",
    "            boundary_train_out.append(boundary2)\n",
    "        else: \n",
    "            x_test.append(torch.tensor(xi))\n",
    "            test_set_input.append(data[:, i:i+13, :])\n",
    "            test_set_output.append(data[:, i+13:i+25, :])\n",
    "            initial1 = interpolate_initial(data[:, i, :], xi, t0=0)\n",
    "            boundary1 = interpolate_boundary(data[:, i:i+13, :], ti_test, t_test) \n",
    "            initial2 = interpolate_initial(data[:, i+12, :], xi, t0=0)\n",
    "            boundary2 = interpolate_boundary(data[:, i+12:i+25, :], ti_test, t_test)\n",
    "            initial = torch.stack([initial1, initial2])\n",
    "#             boundary = torch.stack([boundary1, boundary2])\n",
    "            initial_test.append(initial)\n",
    "            boundary_test_in.append(boundary1)\n",
    "            boundary_test_out.append(boundary2)\n",
    "    \n",
    "    return torch.stack(x_train), torch.stack(x_test), torch.stack(training_set_input), torch.stack(training_set_output), torch.stack(test_set_input), torch.stack(test_set_output), torch.stack(initial_train), torch.stack(initial_test), torch.stack(boundary_train_in), torch.stack(boundary_train_out), torch.stack(boundary_test_in), torch.stack(boundary_test_out)   \n",
    "\n",
    "x_train, x_test, training_set_input, training_set_output, test_set_input, test_set_output, initial_train, initial_test, boundary_train_in, boundary_train_out, boundary_test_in, boundary_test_out = generate_data_lwr_res(data1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3767dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_idx = list(np.arange(380))\n",
    "\n",
    "def generate_data_lwr_date(data): \n",
    "    interpolated = []\n",
    "    for i in range(data.shape[1]): \n",
    "        interpolated_d = interpolate_initial(data[:, i, :], xi, t0=0) \n",
    "        interpolated.append(interpolated_d) \n",
    "    interpolated_data = torch.stack(interpolated) \n",
    "    interpolated_data = interpolated_data.permute(1, 0, 2)\n",
    "    print(interpolated_data.shape) \n",
    "\n",
    "    training_set = [] \n",
    "    test_set = [] \n",
    "    initial_train = []\n",
    "    boundary_train = []\n",
    "    initial_test = []\n",
    "    boundary_test = []\n",
    "    x_train = []\n",
    "    x_test = [] \n",
    "    training_size = int((data.shape[1] - 13) * 0.8) \n",
    "    \n",
    "    for i in range(data.shape[1] - 13): \n",
    "        if i < training_size: \n",
    "            x_train.append(torch.tensor(sensor_idx))\n",
    "            training_set.append(interpolated_data[:, i:i+4, :]) \n",
    "            initial = interpolate_initial(data[:, i, :], xi, t0=0)\n",
    "            boundary = interpolate_boundary(data[:, i:i+4, :], ti, t) \n",
    "            initial_train.append(initial)\n",
    "            boundary_train.append(boundary)\n",
    "        else: \n",
    "            x_test.append(torch.tensor(xi)) \n",
    "            test_set.append(data[:, i:i+13, :]) \n",
    "            initial = interpolate_initial(data[:, i, :], xi, t0=0)\n",
    "            boundary = interpolate_boundary(data[:, i:i+13, :], ti_test, t_test)\n",
    "            initial_test.append(initial)\n",
    "            boundary_test.append(boundary)\n",
    "    return torch.stack(x_train), torch.stack(x_test), torch.stack(training_set), torch.stack(test_set), torch.stack(initial_train), torch.stack(initial_test), torch.stack(boundary_train), torch.stack(boundary_test)  \n",
    "\n",
    "x_train, x_test, training_set, test_set, initial_train, initial_test, boundary_train, boundary_test = generate_data_lwr_date(data1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65800eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(time_train, \"data_LWR/time_train.pt\") \n",
    "# torch.save(time_test, \"data_LWR/time_test.pt\")\n",
    "# torch.save(training_set1, \"data_LWR/training_time.pt\")\n",
    "# torch.save(test_set1, \"data_LWR/test_time.pt\")\n",
    "# torch.save(initial_train, \"data_LWR/training_time_initial.pt\")\n",
    "# torch.save(initial_test, \"data_LWR/test_time_initial.pt\")\n",
    "# torch.save(boundary_train, \"data_LWR/training_time_boundary.pt\")\n",
    "# torch.save(boundary_test, \"data_LWR/test_time_boundary.pt\")\n",
    "# torch.save(x_train, \"data_LWR/x_train.pt\")\n",
    "# torch.save(x_test, \"data_LWR/x_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a54b990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_set = LWRDataset_res(x_train, training_set, initial_train, boundary_train)\n",
    "# test_set = LWRDataset_res(x_test, test_set, initial_test, boundary_test) \n",
    "training_set = LWRDataset_res(x_train, training_set_input, training_set_output, initial_train, boundary_train_in, boundary_train_out)\n",
    "test_set = LWRDataset_res(x_test, test_set_input, test_set_output, initial_test, boundary_test_in, boundary_test_out)\n",
    "# training_set = LWRDataset_res(x_train, training_data, training_initial, training_boundary)\n",
    "# test_set = LWRDataset_res(x_test, test_data, test_initial, test_boundary)\n",
    "training_set, val_set = data.random_split(training_set, [int(len(training_set) * 0.875), int(len(training_set) - int(len(training_set) * 0.875))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfa9e0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(training_set, batch_size = 256, shuffle = True, num_workers=0, pin_memory=True)\n",
    "val_loader = data.DataLoader(val_set, batch_size = 512, shuffle = False, num_workers=0, pin_memory=True)\n",
    "test_loader = data.DataLoader(test_set, batch_size = 512, shuffle = False, num_workers=0, pin_memory=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afc197d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hybrid_LWR(model, train_loader, optimizer, criterion, steps, pred_len): \n",
    "    preds = []\n",
    "    trues = []\n",
    "    mse = [] \n",
    "    model.train()\n",
    "    for xi, initial, boundary_in, boundary_out, x, y in train_loader: \n",
    "        xi, initial, boundary_in, boundary_out, x, y = xi.to(device), initial.to(device), boundary_in.to(device), boundary_out.to(device), x.to(device), y.to(device) \n",
    "        pred = model(xi, x, initial, boundary_in, boundary_out, steps, pred_len) \n",
    "        loss = 0\n",
    "        loss = criterion(pred, y) \n",
    "#         l1_lambda = 0.001\n",
    "#         l1_norm = sum(p.abs().sum() for p in model.residual_model.parameters()) \n",
    "#         loss = loss + l1_lambda * l1_norm \n",
    "        l2_lambda = 0.001\n",
    "        l2_norm = sum(p.pow(2.0).sum() for p in model.residual_model.parameters()) \n",
    "        loss = loss + l2_lambda * l2_norm \n",
    "        \n",
    "        mse.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    #     trues.append(y.cpu().data.numpy())\n",
    "    #     preds.append(pred.cpu().data.numpy())\n",
    "    \n",
    "    # preds = np.concatenate(preds, axis = 0)\n",
    "    # trues = np.concatenate(trues, axis = 0)\n",
    "    \n",
    "    return preds, trues, np.mean(mse) \n",
    "\n",
    "def eval_hybrid_LWR(model, val_loader, criterion, steps, pred_len): \n",
    "    preds = []\n",
    "    trues = []\n",
    "    mse = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for xi, initial, boundary_in, boundary_out, x, y in val_loader: \n",
    "            xi, initial, boundary_in, boundary_out, x, y = xi.to(device), initial.to(device), boundary_in.to(device), boundary_out.to(device), x.to(device), y.to(device) \n",
    "            pred = model(xi, x, initial, boundary_in, boundary_out, steps, pred_len) \n",
    "            loss = 0\n",
    "            loss = criterion(pred, y)\n",
    "            mse.append(loss.item()) \n",
    "        \n",
    "        #     trues.append(y.cpu().data.numpy())\n",
    "        #     preds.append(pred.cpu().data.numpy())\n",
    "\n",
    "        # preds = np.concatenate(preds, axis = 0)\n",
    "        # trues = np.concatenate(trues, axis = 0) \n",
    "    \n",
    "    return preds, trues, np.mean(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372a1ab8",
   "metadata": {},
   "source": [
    "### Hyperparameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca837a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d \n",
    "\n",
    "def calibrate(data): \n",
    "    # assume the linear relation u = a * k + b \n",
    "    # cross all sensors / at each sensor \n",
    "#     print(data.shape)\n",
    "    kj = data[0, :42613].max(dim = 0).values\n",
    "    vf = data[2, :42613].max(dim = 0).values \n",
    "    IM_kj=interp1d(np.array(xi) * dx, kj.numpy(), bounds_error=False, \n",
    "                fill_value=(kj[0], kj[-1]), kind='linear') \n",
    "    IM_vf=interp1d(np.array(xi) * dx, vf.numpy(), bounds_error=False, \n",
    "                fill_value=(vf[0], vf[-1]), kind='linear')\n",
    "\n",
    "    x=np.linspace(0, (nx-1) * dx, nx) \n",
    "    kj = IM_kj(x) \n",
    "    vf = IM_vf(x) \n",
    "#     kj = (kj - y_min[0].numpy()) / (y_max[0].numpy() - y_min[0].numpy()) \n",
    "#     vf = (vf - y_min[2].numpy()) / (y_max[2].numpy() - y_min[2].numpy())\n",
    "#     k_mean = data[0].mean(dim = 0)\n",
    "#     u_mean = data[2].mean(dim = 0) \n",
    "#     k_m = data[0] - k_mean\n",
    "    \n",
    "#     b = ((k_m) * (data[2] - u_mean)).sum(dim = 0) / (k_m * k_m).sum(dim = 0)\n",
    "# #     print(b.shape)\n",
    "# #     a = u_mean - b * k_mean # vf\n",
    "#     kj = -(u_max / b)\n",
    "#     return kj, a   \n",
    "    return kj * 1.2, np.ceil(vf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4eb3985",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = torch.load(\"../pems_I5_S_correct.pt\") \n",
    "kj, vf = calibrate(data2) \n",
    "# kj, vf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc038d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps=torch.tensor(np.linspace(0, nt, nt), requires_grad=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48cb4a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_test=torch.tensor(np.linspace(0, nt_test, nt_test), requires_grad=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b31f3508",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" \n",
    "model = LWR_seq2seq_joint().to(device) \n",
    "# model = LWR_batch_version(nx, 300, 6, kj, vf, tskip, plm = False, plm_vf = False, \n",
    "#                           initial={}, boundary={}, fix_vf=False, parstep=1).to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d641784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10534879\n"
     ]
    }
   ],
   "source": [
    "name = \"hybrid_LWR_joint_norm\"\n",
    "learning_rate = 0.002\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 1, gamma=0.95)\n",
    "criterion = nn.MSELoss()\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "best_loss = 100   \n",
    "train_losses = []\n",
    "val_losses = []\n",
    "tsteps = steps.shape[0]\n",
    "tsteps_test = steps_test.shape[0] \n",
    "pred_len = 12 \n",
    "test_sensors = torch.tensor(np.arange(77)) \n",
    "num_epoch = 100 \n",
    "trial = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c110b892",
   "metadata": {},
   "source": [
    "### Training and Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f29e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "for epoch in range(1, num_epoch + 1): \n",
    "    start = time.time()\n",
    "    train_loss = train_LWR(model, train_loader, optimizer, criterion, tsteps)[-1]\n",
    "    train_losses.append(train_loss)\n",
    "    _, _, val_loss = eval_LWR(model, val_loader, criterion, tsteps) \n",
    "\n",
    "    val_losses.append(val_loss)\n",
    "    if val_loss <= best_loss: \n",
    "        best_loss = val_loss \n",
    "        best_model = model\n",
    "        torch.save({\"lr\": optimizer.param_groups[0]['lr'], \"model\": model}, \"new_result/best3_AutoODE\" + str(trial) + \".pt\")\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Epoch:\", epoch, \"completed in:\", (end - start), \"s. Training loss:\", train_loss, \". Val loss:\", val_loss)  \n",
    "    if (len(train_losses) > 30 and np.mean(val_losses[-5:]) >= np.mean(val_losses[-10:-5])):\n",
    "        break\n",
    "    scheduler.step() \n",
    "    if epoch % 5 == 0: print(optimizer.param_groups[0]['lr']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c81b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsteps_test = steps_test.shape[0] \n",
    "preds, trues, test_loss = test_LWR(model, test_loader, criterion, tsteps_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5fd7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, np.sqrt(test_loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba0c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\"preds\": preds, \"trues\": trues, \"model\": model}, \"new_result/final_AutoODE3.pt\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d38407",
   "metadata": {},
   "source": [
    "### Training hybrid model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81ff4f84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Evaluation------\n",
      "1.4775448050054347\n",
      "1.7120456082331004\n",
      "0.7139860362221334\n",
      "0.8384986918726579\n",
      "1.333096048454818\n",
      "1.8019856579344784\n",
      "0.911115803694533\n",
      "2.490755304953364\n",
      "1.7413630722957307\n",
      "1.4089541923173152\n",
      "0.8443967643347526\n",
      "1.7723366906850624\n",
      "1.553678936597252\n",
      "1.6127244388914186\n",
      "0.6315119355411253\n",
      "0.9866737720747374\n",
      "2.0886499334185444\n",
      "1.4663883975674887\n",
      "0.6976770357750764\n",
      "1.013867203056584\n",
      "2.5598786789027748\n",
      "Epoch: 1 completed in: 1000.9310097694397 s. Training loss: 1.9848561273324927 . Val loss: 1.1761740269567293 . Test loss: 1.412244238468018\n",
      "------Evaluation------\n",
      "1.3680741316774183\n",
      "1.6353807935744467\n",
      "0.6881944030591336\n",
      "0.8267429585390175\n",
      "1.266872540011741\n",
      "1.7276155160659343\n",
      "0.8460748160678183\n",
      "2.3425045742156447\n",
      "1.6401736443601613\n",
      "1.3780865340727506\n",
      "0.7973416508066672\n",
      "1.6579113489661836\n",
      "1.468215394218944\n",
      "1.523508542678485\n",
      "0.5927598806566009\n",
      "0.9271786797702319\n",
      "1.9329470831903195\n",
      "1.3777713490463985\n",
      "0.6335027366091217\n",
      "0.9460928233118773\n",
      "2.3590565404079853\n",
      "Epoch: 2 completed in: 1058.7010235786438 s. Training loss: 1.2924953641937647 . Val loss: 1.101186630710129 . Test loss: 1.3302859972050893\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\STEPHE~1\\AppData\\Local\\Temp/ipykernel_245544/2994264524.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_hybrid_LWR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtsteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\STEPHE~1\\AppData\\Local\\Temp/ipykernel_245544/3635155337.py\u001b[0m in \u001b[0;36mtrain_hybrid_LWR\u001b[1;34m(model, train_loader, optimizer, criterion, steps, pred_len)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary_in\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\STEPHE~1\\AppData\\Local\\Temp/ipykernel_245544/4191264248.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, xi, x, initial, boundary_in, boundary_out, tsteps, pred_len)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0minput_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mpred1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLWR_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtsteps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# first 12\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLWR_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtsteps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# last 12\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# print(pred1.shape, x[:, :, 1:pred_len, 1:].shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\AutoODE_PEMS_traffic\\nn\\AutoODE\\LWR.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, xi, initial, boundary, tsteps)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mnk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[0mnu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m             \u001b[0mnq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;31m#new values for 3 variables stored in one tensor per time step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "for epoch in range(1, num_epoch + 1): \n",
    "    start = time.time()\n",
    "    train_loss = train_hybrid_LWR(model, train_loader, optimizer, criterion, tsteps, pred_len)[-1]\n",
    "    end = time.time()\n",
    "    train_losses.append(train_loss) \n",
    "    print(\"------Evaluation------\") \n",
    "#     print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "    _, _, val_loss = eval_hybrid_LWR(model, val_loader, criterion, tsteps, pred_len) \n",
    "#     print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "    val_losses.append(val_loss) \n",
    "    if val_loss <= best_loss: \n",
    "        best_loss = val_loss \n",
    "        best_model = model\n",
    "        torch.save({'epoch': epoch, \"optimizer\": optimizer.state_dict(), \"model\": best_model.state_dict()}, \"hybridAutoODE_time_\" + name + str(epoch) + \".pt\") \n",
    "    best_loss = best_loss \n",
    "    \n",
    "    preds, trues, test_loss = test_hybrid_LWR(model, test_loader, criterion, test_sensors.long(), tsteps_test, 12) \n",
    "    # scaled_error = np.mean([np.sqrt(metric(preds, trues, criterion, 2)), np.sqrt(metric(preds, trues, criterion, 5)), np.sqrt(metric(preds, trues, criterion, -1))]) \n",
    "    # end = time.time()\n",
    "    print(\"Epoch:\", epoch, \"completed in:\", (end - start), \"s. Training loss:\", train_loss, \". Val loss:\", val_loss, \". Test loss:\", test_loss)  \n",
    "    if (len(train_losses) > 30 and np.mean(val_losses[-5:]) >= np.mean(val_losses[-10:-5])):\n",
    "        break\n",
    "    scheduler.step() \n",
    "    if epoch % 5 == 0: \n",
    "        print(optimizer.param_groups[0]['lr']) \n",
    "torch.save({'epoch': epoch, \"optimizer\": optimizer.state_dict(), \"model\": best_model.state_dict()}, \"hybridAutoODE_time_\" + name + str(i) + \".pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72ca9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial_1 = torch.load(\"AutoODE_result/time/time_hybridAutoODE1.pt\") \n",
    "# LWR_model = trial_1[\"model\"] \n",
    "# LWR_model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb79c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sensors = torch.tensor(np.arange(77))  \n",
    "test_sensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a804e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tsteps_test = steps_test.shape[0] \n",
    "criterion = nn.MSELoss() \n",
    "preds, trues, test_loss = test_hybrid_LWR(model, test_loader, criterion, test_sensors.long(), tsteps_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590121ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, np.sqrt(test_loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349b3e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\"preds\": preds, \"trues\": trues, \"model\": LWR_model}, \"AutoODE_result/time/time_AutoODE7.pt\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
