{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0dc8f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "import time\n",
    "from DNN import Seq2Seq, LWRDataset, LWRDataset_res, train_LWR, eval_LWR, test_LWR, train_hybrid_LWR, eval_hybrid_LWR, test_hybrid_LWR \n",
    "from AutoODE import LWR_batch_version, LWR_seq2seq \n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6506a6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LWR_seq2seq_joint(nn.Module): \n",
    "#     def __init__(self): \n",
    "#         super(LWR_seq2seq_joint, self).__init__()\n",
    "#         self.LWR_model = model = LWR_batch_version(nx, 300, 6, kj, vf, tskip, plm = False, plm_vf = False, \n",
    "#                           initial={}, boundary={}, fix_vf=False, parstep=1).to(device).to(device) \n",
    "\n",
    "#         self.residual_model = Seq2Seq(input_dim = 231, hidden_dim = 512, output_dim = 231, num_layers = 1).to(device)\n",
    "    \n",
    "#     def forward(self, xi, x, initial, boundary, tsteps): \n",
    "#         pred1 = self.LWR_model(xi, initial[:, 0], boundary[:, 0], tsteps) # first 12\n",
    "#         pred = self.LWR_model(xi, initial[:, 1], boundary[:, 1], tsteps) # last 12\n",
    "#         res = x[:, :, 1:13, 1:] - pred1\n",
    "\n",
    "#         residual = self.residual_model(res.float(), 12) # last 12\n",
    "\n",
    "# #         pred = pred2.detach().clone()\n",
    "#         pred += residual # residual[:, :, 1:] \n",
    "        \n",
    "#         return pred.double() \n",
    "\n",
    "class LWR_seq2seq_joint(nn.Module): \n",
    "    def __init__(self): \n",
    "        super(LWR_seq2seq_joint, self).__init__()\n",
    "        self.LWR_model = model = LWR_batch_version(nx, 300, 6, kj, vf, tskip, plm = False, plm_vf = False, \n",
    "                          initial={}, boundary={}, fix_vf=False, parstep=1).to(device).to(device) \n",
    "\n",
    "        self.residual_model = Seq2Seq(input_dim = 231, hidden_dim = 1024, output_dim = 231, num_layers = 1).to(device)\n",
    "    \n",
    "    def forward(self, xi, x, initial, boundary_in, boundary_out, tsteps, pred_len): \n",
    "        input_len = int(x.shape[2] / 2) + 1 \n",
    "        with torch.no_grad():\n",
    "            pred1 = self.LWR_model(xi, initial[:, 0], boundary_in, tsteps) # first 12\n",
    "        pred = self.LWR_model(xi, initial[:, 1], boundary_out, tsteps) # last 12\n",
    "        # print(pred1.shape, x[:, :, 1:pred_len, 1:].shape)\n",
    "        res = x[:, :, 1:, 1:] - pred1.detach().clone() \n",
    "#         print(x.shape, res.shape)\n",
    "        residual = self.residual_model(res.float(), pred_len) # last 12\n",
    "#         print(residual.shape)\n",
    "#         pred = pred2.detach().clone()\n",
    "        pred += residual # residual[:, :, 1:] \n",
    "#         print(pred.shape, x.shape)\n",
    "        return pred.double() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7742dd0",
   "metadata": {},
   "source": [
    "### Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8189f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = torch.load(\"data_LWR/residual/training_time.pt\").double()\n",
    "# training_initial = torch.load(\"data_LWR/residual/training_time_initial.pt\").double()\n",
    "# training_boundary = torch.load(\"data_LWR/residual/training_time_boundary.pt\").double()\n",
    "# x_train = torch.load(\"data_LWR/residual/x_train.pt\").long()\n",
    "# test_data = torch.load(\"data_LWR/residual/test_time.pt\").double()\n",
    "# test_initial = torch.load(\"data_LWR/residual/test_time_initial.pt\").double()\n",
    "# test_boundary = torch.load(\"data_LWR/residual/test_time_boundary.pt\").double()\n",
    "# x_test = torch.load(\"data_LWR/residual/x_test.pt\").long() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba06507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = torch.load(\"data_LWR/space/training_time.pt\").double()\n",
    "# training_initial = torch.load(\"data_LWR/space/training_time_initial.pt\").double()\n",
    "# training_boundary = torch.load(\"data_LWR/space/training_time_boundary.pt\").double() \n",
    "# test_data = torch.load(\"data_LWR/space/test_time.pt\").double()\n",
    "# test_initial = torch.load(\"data_LWR/space/test_time_initial.pt\").double()\n",
    "# test_boundary = torch.load(\"data_LWR/space/test_time_boundary.pt\").double() \n",
    "# x_train = torch.load(\"data_LWR/space/x_train.pt\").long()\n",
    "# x_test = torch.load(\"data_LWR/space/x_test.pt\").long() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "625d1982",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = torch.load(\"../pems_I5_S_correct.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f31769f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = [0,  45,  56,  75,  81,  86,  89,  95, 100, 105, 109, 112, 117,\n",
    "       124, 128, 133, 137, 141, 146, 149, 152, 158, 163, 167, 171, 174,\n",
    "       180, 186, 192, 197, 200, 205, 207, 210, 211, 213, 214, 228, 231,\n",
    "       237, 240, 242, 251, 254, 258, 262, 266, 270, 277, 279, 282, 283,\n",
    "       286, 288, 291, 294, 296, 298, 300, 303, 308, 310, 315, 317, 320,\n",
    "       322, 327, 338, 342, 345, 352, 356, 359, 362, 366, 368, 374, 379] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8af5fa3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 250 650\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#nx=350  # \n",
    "nx=380 \n",
    "#kj needs to be larger than k for the solution to be stable \n",
    "# kj = np.ones((nx,), dtype=float) * 0.6\n",
    "# kj = (kj - mean[0].numpy()) / std[0].numpy()\n",
    "# kj = (kj - y_min[0].numpy()) / (y_max[0].numpy() - y_min[0].numpy()) # normalize\n",
    "\n",
    "#characteristic velocity (m/s), corresponds to roughly 120 km/h\n",
    "# vf = np.ones((nx,), dtype=float) * 38\n",
    "# vf = (vf - mean[2].numpy()) / std[2].numpy()\n",
    "# vf = (vf - y_min[2].numpy()) / (y_max[2].numpy() - y_min[2].numpy()) # normalize\n",
    "\n",
    "dx=300.\n",
    "\n",
    "## change the timestep to dt = 1, previously dt = 6 with 7 mins runtime\n",
    "dt=6\n",
    "#need an output every 5 mins (300 s), so tskip = 3 with dt = 3s\n",
    "tskip=50\n",
    "#nt=int(3600*6/6 - 50)\n",
    "#nt=7099 #6 hours (times 3600 s/hour divided by dt=3s)\n",
    "nto=5 + 1\n",
    "#nt=int(3600*nto/12/6/dt - tskip)\n",
    "dtobs=300\n",
    "nt=int((dtobs*nto)/dt - tskip) \n",
    "\n",
    "nto=13 + 1\n",
    "#nt=int(3600*nto/12/6/dt - tskip)\n",
    "dtobs=300\n",
    "nt_test=int((dtobs*nto)/dt - tskip)\n",
    "print(dt, nt, nt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f4df69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def interpolate_initial(var, xi, t0=0): \n",
    "    IM_q=interp1d(np.array(xi) * dx, var[1, :].numpy(), bounds_error=False, \n",
    "                fill_value=(var[1, 0], var[1, -1]), kind='linear') \n",
    "    IM_u=interp1d(np.array(xi) * dx, var[2, :].numpy(), bounds_error=False, \n",
    "                fill_value=(var[2, 0], var[2, -1]), kind='linear') \n",
    "    \n",
    "    x=np.linspace(0, (nx-1) * dx, nx) \n",
    "    u = IM_u(x)\n",
    "    q = IM_q(x)\n",
    "    k = q / u\n",
    "    initial = np.stack((k, q, u))\n",
    "    return torch.tensor(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "764173ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ti=np.arange(0, (nt-1)*dt, tskip*dt )\n",
    "t=np.linspace(0, (nt-1)*dt, nt) \n",
    "ti_test=np.arange(0, (nt_test-1)*dt, tskip*dt )\n",
    "t_test = np.linspace(0, (nt_test-1)*dt, nt_test)\n",
    "\n",
    "def interpolate_boundary(var, ti, t): \n",
    "    IM_q=interp1d(np.array(ti), var[1, :, 0].numpy(), bounds_error=False,\n",
    "             fill_value=(var[1, 0, 0], var[1, -1, 0]), kind='linear')\n",
    "    IM_u=interp1d(np.array(ti), var[2, :, 0].numpy(), bounds_error=False,\n",
    "             fill_value=(var[2, 0, 0], var[2, -1, 0]), kind='linear')\n",
    "    u = IM_u(t)\n",
    "    q = IM_q(t)\n",
    "    k = q / u\n",
    "    boundary = np.stack((k, q, u)) \n",
    "    return torch.tensor(boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63439bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_lwr_res(data): \n",
    "#     interpolated = []\n",
    "#     for i in range(data.shape[1]): \n",
    "#         interpolated_d = interpolate_initial(data[:, i, :], xi, t0=0) \n",
    "#         interpolated.append(interpolated_d) \n",
    "#     interpolated_data = torch.stack(interpolated) \n",
    "#     interpolated_data = interpolated_data.permute(1, 0, 2)\n",
    "#     print(interpolated_data.shape) \n",
    "    \n",
    "    training_set_input = [] \n",
    "    training_set_output = [] \n",
    "    test_set_input = [] \n",
    "    test_set_output = []\n",
    "    initial_train = []\n",
    "    boundary_train_in = []\n",
    "    boundary_train_out = []\n",
    "    initial_test = []\n",
    "    boundary_test_in = []\n",
    "    boundary_test_out = []\n",
    "    x_train = []\n",
    "    x_test = []\n",
    "    training_size = int((data.shape[1] - 25) * 0.8) \n",
    "    \n",
    "    for i in range(data.shape[1] - 25): \n",
    "        if i < training_size: \n",
    "            x_train.append(torch.tensor(xi))\n",
    "            training_set_input.append(data[:, i:i+5, :])\n",
    "            training_set_output.append(data[:, i+5:i+9, :])\n",
    "            initial1 = interpolate_initial(data[:, i, :], xi, t0=0)\n",
    "            boundary1 = interpolate_boundary(data[:, i:i+5, :], ti, t) \n",
    "            initial2 = interpolate_initial(data[:, i+4, :], xi, t0=0)\n",
    "            boundary2 = interpolate_boundary(data[:, i+4:i+9, :], ti, t)\n",
    "            initial = torch.stack([initial1, initial2])\n",
    "#             boundary = torch.stack([boundary1, boundary2])\n",
    "            initial_train.append(initial)\n",
    "            boundary_train_in.append(boundary1)\n",
    "            boundary_train_out.append(boundary2)\n",
    "        else: \n",
    "            x_test.append(torch.tensor(xi))\n",
    "            test_set_input.append(data[:, i:i+13, :])\n",
    "            test_set_output.append(data[:, i+13:i+25, :])\n",
    "            initial1 = interpolate_initial(data[:, i, :], xi, t0=0)\n",
    "            boundary1 = interpolate_boundary(data[:, i:i+13, :], ti_test, t_test) \n",
    "            initial2 = interpolate_initial(data[:, i+12, :], xi, t0=0)\n",
    "            boundary2 = interpolate_boundary(data[:, i+12:i+25, :], ti_test, t_test)\n",
    "            initial = torch.stack([initial1, initial2])\n",
    "#             boundary = torch.stack([boundary1, boundary2])\n",
    "            initial_test.append(initial)\n",
    "            boundary_test_in.append(boundary1)\n",
    "            boundary_test_out.append(boundary2)\n",
    "    \n",
    "    return torch.stack(x_train), torch.stack(x_test), torch.stack(training_set_input), torch.stack(training_set_output), torch.stack(test_set_input), torch.stack(test_set_output), torch.stack(initial_train), torch.stack(initial_test), torch.stack(boundary_train_in), torch.stack(boundary_train_out), torch.stack(boundary_test_in), torch.stack(boundary_test_out)   \n",
    "\n",
    "x_train, x_test, training_set_input, training_set_output, test_set_input, test_set_output, initial_train, initial_test, boundary_train_in, boundary_train_out, boundary_test_in, boundary_test_out = generate_data_lwr_res(data1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96b9b47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(time_train, \"data_LWR/time_train.pt\") \n",
    "# torch.save(time_test, \"data_LWR/time_test.pt\")\n",
    "torch.save(training_set, \"data_LWR/training_time.pt\")\n",
    "torch.save(test_set, \"data_LWR/test_time.pt\")\n",
    "torch.save(initial_train, \"data_LWR/training_time_initial.pt\")\n",
    "torch.save(initial_test, \"data_LWR/test_time_initial.pt\")\n",
    "torch.save(boundary_train, \"data_LWR/training_time_boundary.pt\")\n",
    "torch.save(boundary_test, \"data_LWR/test_time_boundary.pt\")\n",
    "torch.save(x_train, \"data_LWR/x_train.pt\")\n",
    "torch.save(x_test, \"data_LWR/x_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3767dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensor_idx = list(np.arange(380))\n",
    "\n",
    "# def generate_data_lwr_date(data): \n",
    "#     interpolated = []\n",
    "#     for i in range(data.shape[1]): \n",
    "#         interpolated_d = interpolate_initial(data[:, i, :], xi, t0=0) \n",
    "#         interpolated.append(interpolated_d) \n",
    "#     interpolated_data = torch.stack(interpolated) \n",
    "#     interpolated_data = interpolated_data.permute(1, 0, 2)\n",
    "#     print(interpolated_data.shape) \n",
    "\n",
    "#     training_set = [] \n",
    "#     test_set = [] \n",
    "#     initial_train = []\n",
    "#     boundary_train = []\n",
    "#     initial_test = []\n",
    "#     boundary_test = []\n",
    "#     x_train = []\n",
    "#     x_test = [] \n",
    "#     training_size = int((data.shape[1] - 13) * 0.8) \n",
    "    \n",
    "#     for i in range(data.shape[1] - 13): \n",
    "#         if i < training_size: \n",
    "#             x_train.append(torch.tensor(sensor_idx))\n",
    "#             training_set.append(interpolated_data[:, i:i+4, :]) \n",
    "#             initial = interpolate_initial(data[:, i, :], xi, t0=0)\n",
    "#             boundary = interpolate_boundary(data[:, i:i+4, :], ti, t) \n",
    "#             initial_train.append(initial)\n",
    "#             boundary_train.append(boundary)\n",
    "#         else: \n",
    "#             x_test.append(torch.tensor(xi)) \n",
    "#             test_set.append(data[:, i:i+13, :]) \n",
    "#             initial = interpolate_initial(data[:, i, :], xi, t0=0)\n",
    "#             boundary = interpolate_boundary(data[:, i:i+13, :], ti_test, t_test)\n",
    "#             initial_test.append(initial)\n",
    "#             boundary_test.append(boundary)\n",
    "#     return torch.stack(x_train), torch.stack(x_test), torch.stack(training_set), torch.stack(test_set), torch.stack(initial_train), torch.stack(initial_test), torch.stack(boundary_train), torch.stack(boundary_test)  \n",
    "\n",
    "# x_train, x_test, training_set, test_set, initial_train, initial_test, boundary_train, boundary_test = generate_data_lwr_date(data1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65800eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(time_train, \"data_LWR/time_train.pt\") \n",
    "# torch.save(time_test, \"data_LWR/time_test.pt\")\n",
    "# torch.save(training_set1, \"data_LWR/training_time.pt\")\n",
    "# torch.save(test_set1, \"data_LWR/test_time.pt\")\n",
    "# torch.save(initial_train, \"data_LWR/training_time_initial.pt\")\n",
    "# torch.save(initial_test, \"data_LWR/test_time_initial.pt\")\n",
    "# torch.save(boundary_train, \"data_LWR/training_time_boundary.pt\")\n",
    "# torch.save(boundary_test, \"data_LWR/test_time_boundary.pt\")\n",
    "# torch.save(x_train, \"data_LWR/x_train.pt\")\n",
    "# torch.save(x_test, \"data_LWR/x_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a54b990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_set = LWRDataset_res(x_train, training_set, initial_train, boundary_train)\n",
    "# test_set = LWRDataset_res(x_test, test_set, initial_test, boundary_test) \n",
    "training_set = LWRDataset_res(x_train, training_set_input, training_set_output, initial_train, boundary_train_in, boundary_train_out)\n",
    "test_set = LWRDataset_res(x_test, test_set_input, test_set_output, initial_test, boundary_test_in, boundary_test_out)\n",
    "# training_set = LWRDataset_res(x_train, training_data, training_initial, training_boundary)\n",
    "# test_set = LWRDataset_res(x_test, test_data, test_initial, test_boundary)\n",
    "training_set, val_set = data.random_split(training_set, [int(len(training_set) * 0.875), int(len(training_set) - int(len(training_set) * 0.875))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cfa9e0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(training_set, batch_size = 256, shuffle = True, num_workers=0, pin_memory=True)\n",
    "val_loader = data.DataLoader(val_set, batch_size = 512, shuffle = False, num_workers=0, pin_memory=True)\n",
    "test_loader = data.DataLoader(test_set, batch_size = 512, shuffle = False, num_workers=0, pin_memory=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372a1ab8",
   "metadata": {},
   "source": [
    "### Hyperparameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9da300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial_1 = torch.load(\"AutoODE_result/time/best_AutoODE1.pt\") \n",
    "# LWR_model = trial_1[\"model\"] \n",
    "# LWR_model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01445df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in LWR_model.parameters(): \n",
    "#     p.requires_grad = False \n",
    "\n",
    "# print(sum(p.numel() for p in LWR_model.parameters() if p.requires_grad)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7f810c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d \n",
    "\n",
    "def calibrate(data): \n",
    "    # assume the linear relation u = a * k + b \n",
    "    # cross all sensors / at each sensor \n",
    "#     print(data.shape)\n",
    "    kj = data[0, :42613].max(dim = 0).values\n",
    "    vf = data[2, :42613].max(dim = 0).values \n",
    "    IM_kj=interp1d(np.array(xi) * dx, kj.numpy(), bounds_error=False, \n",
    "                fill_value=(kj[0], kj[-1]), kind='linear') \n",
    "    IM_vf=interp1d(np.array(xi) * dx, vf.numpy(), bounds_error=False, \n",
    "                fill_value=(vf[0], vf[-1]), kind='linear')\n",
    "\n",
    "    x=np.linspace(0, (nx-1) * dx, nx) \n",
    "    kj = IM_kj(x) \n",
    "    vf = IM_vf(x) \n",
    "#     kj = (kj - y_min[0].numpy()) / (y_max[0].numpy() - y_min[0].numpy()) \n",
    "#     vf = (vf - y_min[2].numpy()) / (y_max[2].numpy() - y_min[2].numpy())\n",
    "#     k_mean = data[0].mean(dim = 0)\n",
    "#     u_mean = data[2].mean(dim = 0) \n",
    "#     k_m = data[0] - k_mean\n",
    "    \n",
    "#     b = ((k_m) * (data[2] - u_mean)).sum(dim = 0) / (k_m * k_m).sum(dim = 0)\n",
    "# #     print(b.shape)\n",
    "# #     a = u_mean - b * k_mean # vf\n",
    "#     kj = -(u_max / b)\n",
    "#     return kj, a   \n",
    "    return kj * 1.2, np.ceil(vf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "559a0259",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = torch.load(\"../pems_I5_S_correct.pt\") \n",
    "kj, vf = calibrate(data2) \n",
    "# kj, vf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fc038d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps=torch.tensor(np.linspace(0, nt, nt), requires_grad=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "48cb4a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_test=torch.tensor(np.linspace(0, nt_test, nt_test), requires_grad=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b31f3508",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" \n",
    "model = LWR_seq2seq_joint().to(device) \n",
    "# model = LWR_batch_version(nx, 300, 6, kj, vf, tskip, plm = False, plm_vf = False, \n",
    "#                           initial={}, boundary={}, fix_vf=False, parstep=1).to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6d641784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10534879\n"
     ]
    }
   ],
   "source": [
    "name = \"hybrid_LWR_joint\"\n",
    "learning_rate = 0.002\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 1, gamma=0.95)\n",
    "criterion = nn.MSELoss()\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "best_loss = 100   \n",
    "train_losses = []\n",
    "val_losses = []\n",
    "tsteps = steps.shape[0]\n",
    "tsteps_test = steps_test.shape[0] \n",
    "pred_len = 4 \n",
    "test_sensors = torch.tensor(np.arange(77)) \n",
    "num_epoch = 100 \n",
    "trial = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c110b892",
   "metadata": {},
   "source": [
    "### Training and Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f29e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time \n",
    "\n",
    "# for epoch in range(1, num_epoch + 1): \n",
    "#     start = time.time()\n",
    "#     train_loss = train_LWR(model, train_loader, optimizer, criterion, tsteps)[-1]\n",
    "#     train_losses.append(train_loss)\n",
    "#     _, _, val_loss = eval_LWR(model, val_loader, criterion, tsteps) \n",
    "\n",
    "#     val_losses.append(val_loss)\n",
    "#     if val_loss <= best_loss: \n",
    "#         best_loss = val_loss \n",
    "#         best_model = model\n",
    "#         torch.save({\"lr\": optimizer.param_groups[0]['lr'], \"model\": model}, \"new_result/best3_AutoODE\" + str(trial) + \".pt\")\n",
    "\n",
    "#     end = time.time()\n",
    "#     print(\"Epoch:\", epoch, \"completed in:\", (end - start), \"s. Training loss:\", train_loss, \". Val loss:\", val_loss)  \n",
    "#     if (len(train_losses) > 30 and np.mean(val_losses[-5:]) >= np.mean(val_losses[-10:-5])):\n",
    "#         break\n",
    "#     scheduler.step() \n",
    "#     if epoch % 5 == 0: print(optimizer.param_groups[0]['lr']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c81b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsteps_test = steps_test.shape[0] \n",
    "preds, trues, test_loss = test_LWR(model, test_loader, criterion, tsteps_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5fd7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, np.sqrt(test_loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba0c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\"preds\": preds, \"trues\": trues, \"model\": model}, \"new_result/final_AutoODE3.pt\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6069d9",
   "metadata": {},
   "source": [
    "### Training hybrid model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "81ff4f84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Evaluation------\n",
      "1.6428960011021838\n",
      "1.9412610884644788\n",
      "0.8119319472760177\n",
      "0.9495375045543715\n",
      "1.5361175998313266\n",
      "1.9210895757803381\n",
      "0.966575775388252\n",
      "2.3683621722730575\n",
      "2.07315265567081\n",
      "1.5314275449146453\n",
      "0.9393176620575924\n",
      "1.9270781167109368\n",
      "1.792531767388517\n",
      "1.826598703244613\n",
      "0.7194090293533915\n",
      "1.1247491971151056\n",
      "2.312070454697704\n",
      "1.6029411838276686\n",
      "0.8154448422149889\n",
      "1.1777474397325136\n",
      "2.7939591702781885\n",
      "Epoch: 1 completed in: 260.6830003261566 s. Training loss: 0.9932009199172133 . Val loss: 0.6400725399113215 . Test loss: 1.5606761634227002\n",
      "------Evaluation------\n",
      "1.5079984617571816\n",
      "1.7441135608934248\n",
      "0.7201453168664325\n",
      "0.8582360769575711\n",
      "1.4013230437279305\n",
      "1.7739349171991527\n",
      "0.8966898111302293\n",
      "2.0720812874075727\n",
      "1.8776879123846149\n",
      "1.3999604758900004\n",
      "0.8876822601124632\n",
      "1.7891293269623272\n",
      "1.6157357892640298\n",
      "1.6437944118290397\n",
      "0.670396314272796\n",
      "1.0075253126821309\n",
      "2.062926371791811\n",
      "1.434927851564103\n",
      "0.7179861077464587\n",
      "1.0960457264751098\n",
      "2.5779521500218845\n",
      "Epoch: 2 completed in: 255.44267654418945 s. Training loss: 0.5698457908890129 . Val loss: 0.5253450732118453 . Test loss: 1.4169653565207747\n",
      "------Evaluation------\n",
      "1.4461497092967228\n",
      "1.6285006096118697\n",
      "0.660364913570799\n",
      "0.8130330480842914\n",
      "1.3543514706338111\n",
      "1.6709021049221393\n",
      "0.8536327557221776\n",
      "1.9147188691179953\n",
      "1.774389290270251\n",
      "1.3517744263253393\n",
      "0.8797552734452633\n",
      "1.7206023590385515\n",
      "1.5706028089100663\n",
      "1.5614358834002124\n",
      "0.6371702847098568\n",
      "0.972318671353721\n",
      "1.9579375020454137\n",
      "1.404611864501188\n",
      "0.709442259338429\n",
      "1.0553765563485935\n",
      "2.5042577438693976\n",
      "Epoch: 3 completed in: 255.28880524635315 s. Training loss: 0.48550653982100184 . Val loss: 0.4716349746312201 . Test loss: 1.3543489716436232\n",
      "------Evaluation------\n",
      "1.4833565440896737\n",
      "1.5814043158493365\n",
      "0.6400670029915145\n",
      "0.8414121943637539\n",
      "1.3487314294980306\n",
      "1.6245328976011093\n",
      "0.8321708364248657\n",
      "1.8698327162928585\n",
      "1.7575440919635976\n",
      "1.3354773814868\n",
      "0.8299659084795874\n",
      "1.7268694380357592\n",
      "1.5314387789913968\n",
      "1.5246821747950836\n",
      "0.6101099965596349\n",
      "0.94467775096166\n",
      "1.946664260558275\n",
      "1.394077269743001\n",
      "0.6988882420701671\n",
      "1.0637325237853945\n",
      "2.491828826496322\n",
      "Epoch: 4 completed in: 255.78380370140076 s. Training loss: 0.43491862171792994 . Val loss: 0.43779139757359675 . Test loss: 1.337022122906563\n",
      "------Evaluation------\n",
      "1.4907434141927223\n",
      "1.5953821144175844\n",
      "0.6592885296432964\n",
      "0.8312675912179363\n",
      "1.3736107828370385\n",
      "1.6427730797768823\n",
      "0.8365549291519916\n",
      "1.819061621786589\n",
      "1.7579534550681601\n",
      "1.3543506826148601\n",
      "0.8098858616317252\n",
      "1.755359807862488\n",
      "1.5480333039092558\n",
      "1.5359206513954933\n",
      "0.6324878640691748\n",
      "0.9301041671193327\n",
      "1.9102773376316051\n",
      "1.4238568363942985\n",
      "0.7088741580415767\n",
      "1.039817819261041\n",
      "2.4341566116139175\n",
      "Epoch: 5 completed in: 255.45294547080994 s. Training loss: 0.3977616528129347 . Val loss: 0.40893716317299217 . Test loss: 1.3376076485541415\n",
      "0.00118098\n",
      "------Evaluation------\n",
      "1.527591160908227\n",
      "1.566838332072036\n",
      "0.6386741049774158\n",
      "0.8959966757014903\n",
      "1.3906899639109516\n",
      "1.6084470389726893\n",
      "0.8265942439096362\n",
      "1.8639587669547713\n",
      "1.748794357786196\n",
      "1.3579612054694317\n",
      "0.8256227922289144\n",
      "1.7884675990959369\n",
      "1.578829727811226\n",
      "1.5151058024816257\n",
      "0.6160756881555852\n",
      "0.966943992212639\n",
      "1.898613718326648\n",
      "1.3946289675145178\n",
      "0.7443015518668546\n",
      "1.070372360977023\n",
      "2.4406982228286194\n",
      "Epoch: 6 completed in: 255.62443137168884 s. Training loss: 0.3647401078143335 . Val loss: 0.39019667094872407 . Test loss: 1.3459622035315444\n",
      "------Evaluation------\n",
      "1.4875453852248408\n",
      "1.5705817283302694\n",
      "0.6201911338613754\n",
      "0.8418704917748793\n",
      "1.3592581602952105\n",
      "1.6066290541918382\n",
      "0.8158263184652755\n",
      "1.8320926570325702\n",
      "1.7981299179607353\n",
      "1.3178097017527717\n",
      "0.8144184227468519\n",
      "1.8096607190761065\n",
      "1.557201000914358\n",
      "1.4723887264070752\n",
      "0.6026171519222966\n",
      "0.9323404193554212\n",
      "1.900883918480349\n",
      "1.3642727612592371\n",
      "0.7080115438102619\n",
      "1.0366167474405925\n",
      "2.4873785913860984\n",
      "Epoch: 7 completed in: 256.0869755744934 s. Training loss: 0.3365478324716183 . Val loss: 0.36647568372778366 . Test loss: 1.3302725976994483\n",
      "------Evaluation------\n",
      "1.516066393145963\n",
      "1.608606043461232\n",
      "0.6589436434047168\n",
      "0.8801586044658495\n",
      "1.3399893823624547\n",
      "1.6097041799774305\n",
      "0.8313078168156057\n",
      "1.8163487051899077\n",
      "1.7471664070465653\n",
      "1.3963035611762786\n",
      "0.8125155375078927\n",
      "1.8046718333869531\n",
      "1.5843584545429266\n",
      "1.5119290777433025\n",
      "0.6332199893465568\n",
      "0.943707545498161\n",
      "1.8556798451536576\n",
      "1.4079197161410224\n",
      "0.7284509812227993\n",
      "1.0405021541432888\n",
      "2.3911384901058534\n",
      "Epoch: 8 completed in: 254.69389462471008 s. Training loss: 0.31084639479641574 . Val loss: 0.3488651042059328 . Test loss: 1.338985160087544\n",
      "------Evaluation------\n",
      "1.5290024182911255\n",
      "1.6029531772393335\n",
      "0.6085479952541227\n",
      "0.8443584845550893\n",
      "1.3321317086265587\n",
      "1.618026646968123\n",
      "0.8338298180865323\n",
      "1.8054850444830284\n",
      "1.7829417636151355\n",
      "1.390715468976649\n",
      "0.8289835698983913\n",
      "1.810852818365914\n",
      "1.5772447270850571\n",
      "1.511426535695707\n",
      "0.617563411141417\n",
      "0.9494679942183016\n",
      "1.8813204726070107\n",
      "1.4174615382890363\n",
      "0.7396402629258734\n",
      "1.0387008550010506\n",
      "2.4387252618217254\n",
      "Epoch: 9 completed in: 255.77048873901367 s. Training loss: 0.2889149393224788 . Val loss: 0.3307094220908935 . Test loss: 1.3409228558640565\n",
      "------Evaluation------\n",
      "1.5174446459554873\n",
      "1.6335747969729097\n",
      "0.6226102621079905\n",
      "0.8481051139295642\n",
      "1.3482982251147755\n",
      "1.6554164877405444\n",
      "0.8425066997340276\n",
      "1.8512672971857438\n",
      "1.8127472603716788\n",
      "1.4396880737682283\n",
      "0.843013682234622\n",
      "1.8642883160538664\n",
      "1.6041808013013572\n",
      "1.5336719099669454\n",
      "0.6222692497756795\n",
      "0.9994180422288874\n",
      "1.901819400924294\n",
      "1.4354144685440664\n",
      "0.7732693362159041\n",
      "1.0384394719584649\n",
      "2.4329139832834454\n",
      "Epoch: 10 completed in: 254.7503674030304 s. Training loss: 0.2690172212267686 . Val loss: 0.31722782005475786 . Test loss: 1.3628741678746896\n",
      "0.0006973568802\n",
      "------Evaluation------\n",
      "1.5499689469738362\n",
      "1.634146324113269\n",
      "0.667473247168598\n",
      "0.8579668683190953\n",
      "1.3576329655527182\n",
      "1.6322266073456537\n",
      "0.864143286812638\n",
      "1.853880843237795\n",
      "1.8207929599222885\n",
      "1.450997446060668\n",
      "0.8294717815107118\n",
      "1.873134976924741\n",
      "1.5921879759654796\n",
      "1.5183204709235116\n",
      "0.6463385327937395\n",
      "0.9485027454560403\n",
      "1.921741898061938\n",
      "1.4427172096649568\n",
      "0.7663574114304452\n",
      "1.0169336704601106\n",
      "2.41647310115195\n",
      "Epoch: 11 completed in: 255.06025314331055 s. Training loss: 0.2518513416522038 . Val loss: 0.30539439410953384 . Test loss: 1.364829012850009\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\STEPHE~1\\AppData\\Local\\Temp/ipykernel_261960/1713728237.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_hybrid_LWR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtsteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\AutoODE_PEMS_traffic\\nn\\DNN\\datasets.py\u001b[0m in \u001b[0;36mtrain_hybrid_LWR\u001b[1;34m(model, train_loader, optimizer, criterion, steps, pred_len)\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[0mmse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_pytorch\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "for epoch in range(1, num_epoch + 1): \n",
    "    start = time.time()\n",
    "    train_loss = train_hybrid_LWR(model, train_loader, optimizer, criterion, tsteps, pred_len)[-1]\n",
    "    end = time.time()\n",
    "    train_losses.append(train_loss) \n",
    "    print(\"------Evaluation------\") \n",
    "#     print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "    _, _, val_loss = eval_hybrid_LWR(model, val_loader, criterion, tsteps, pred_len) \n",
    "#     print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "    val_losses.append(val_loss) \n",
    "    if val_loss <= best_loss: \n",
    "        best_loss = val_loss \n",
    "        best_model = model\n",
    "        torch.save({'epoch': epoch, \"optimizer\": optimizer.state_dict(), \"model\": best_model.state_dict()}, \"hybridAutoODE_time1_\" + name + str(epoch) + \".pt\") \n",
    "    best_loss = best_loss \n",
    "    \n",
    "    preds, trues, test_loss = test_hybrid_LWR(model, test_loader, criterion, test_sensors.long(), tsteps_test, 12) \n",
    "    # scaled_error = np.mean([np.sqrt(metric(preds, trues, criterion, 2)), np.sqrt(metric(preds, trues, criterion, 5)), np.sqrt(metric(preds, trues, criterion, -1))]) \n",
    "    # end = time.time()\n",
    "    print(\"Epoch:\", epoch, \"completed in:\", (end - start), \"s. Training loss:\", train_loss, \". Val loss:\", val_loss, \". Test loss:\", test_loss)  \n",
    "    if (len(train_losses) > 30 and np.mean(val_losses[-5:]) >= np.mean(val_losses[-10:-5])):\n",
    "        break\n",
    "    scheduler.step() \n",
    "    if epoch % 5 == 0: \n",
    "        print(optimizer.param_groups[0]['lr']) \n",
    "torch.save({'epoch': epoch, \"optimizer\": optimizer.state_dict(), \"model\": best_model.state_dict()}, \"hybridAutoODE_time_\" + name + str(i) + \".pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72ca9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial_1 = torch.load(\"AutoODE_result/time/time_hybridAutoODE1.pt\") \n",
    "# LWR_model = trial_1[\"model\"] \n",
    "# LWR_model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cb79c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
       "        72, 73, 74, 75, 76], dtype=torch.int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sensors = torch.tensor(np.arange(77))  \n",
    "test_sensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6a804e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\STEPHE~1\\AppData\\Local\\Temp/ipykernel_600140/2203983201.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtsteps_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msteps_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_hybrid_LWR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_sensors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtsteps_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\AutoODE_PEMS_traffic\\nn\\DNN\\datasets.py\u001b[0m in \u001b[0;36mtest_hybrid_LWR\u001b[1;34m(model, val_loader, criterion, test_sensors, steps)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_sensors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_sensors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\STEPHE~1\\AppData\\Local\\Temp/ipykernel_600140/2278939362.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, xi, x, initial, boundary, tsteps)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtsteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mpred1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLWR_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtsteps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# first 12\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLWR_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtsteps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# last 12\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpred1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\AutoODE_PEMS_traffic\\nn\\AutoODE\\LWR.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, xi, initial, boundary, tsteps)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mnk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[0mnu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m             \u001b[0mnq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;31m#new values for 3 variables stored in one tensor per time step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tsteps_test = steps_test.shape[0] \n",
    "criterion = nn.MSELoss() \n",
    "preds, trues, test_loss = test_hybrid_LWR(best_model, test_loader, criterion, test_sensors.long(), tsteps_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590121ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, np.sqrt(test_loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349b3e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\"preds\": preds, \"trues\": trues, \"model\": LWR_model}, \"AutoODE_result/time/time_AutoODE7.pt\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
