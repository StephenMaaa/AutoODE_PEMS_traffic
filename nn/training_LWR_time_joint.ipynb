{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0dc8f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "import time\n",
    "from DNN import Seq2Seq, LWRDataset, LWRDataset_res, train_LWR, eval_LWR, test_LWR, train_hybrid_LWR, eval_hybrid_LWR, test_hybrid_LWR \n",
    "from AutoODE import LWR_batch_version, LWR_seq2seq \n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6506a6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LWR_seq2seq_joint(nn.Module): \n",
    "    def __init__(self): \n",
    "        super(LWR_seq2seq_joint, self).__init__()\n",
    "        self.LWR_model = model = LWR_batch_version(nx, 300, 6, kj, vf, tskip, plm = False, plm_vf = False, \n",
    "                          initial={}, boundary={}, fix_vf=False, parstep=1).to(device).to(device) \n",
    "\n",
    "        self.residual_model = Seq2Seq(input_dim = 231, hidden_dim = 512, output_dim = 231, num_layers = 1).to(device)\n",
    "    \n",
    "    def forward(self, xi, x, initial, boundary, tsteps): \n",
    "        pred1 = self.LWR_model(xi, initial[:, 0], boundary[:, 0], tsteps) # first 12\n",
    "        pred = self.LWR_model(xi, initial[:, 1], boundary[:, 1], tsteps) # last 12\n",
    "        res = x[:, :, 1:13, 1:] - pred1\n",
    "\n",
    "        residual = self.residual_model(res.float(), 12) # last 12\n",
    "\n",
    "#         pred = pred2.detach().clone()\n",
    "        pred += residual # residual[:, :, 1:] \n",
    "        \n",
    "        return pred.double() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7742dd0",
   "metadata": {},
   "source": [
    "### Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8189f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = torch.load(\"data_LWR/residual/training_time.pt\").double()\n",
    "# training_initial = torch.load(\"data_LWR/residual/training_time_initial.pt\").double()\n",
    "# training_boundary = torch.load(\"data_LWR/residual/training_time_boundary.pt\").double()\n",
    "# x_train = torch.load(\"data_LWR/residual/x_train.pt\").long()\n",
    "# test_data = torch.load(\"data_LWR/residual/test_time.pt\").double()\n",
    "# test_initial = torch.load(\"data_LWR/residual/test_time_initial.pt\").double()\n",
    "# test_boundary = torch.load(\"data_LWR/residual/test_time_boundary.pt\").double()\n",
    "# x_test = torch.load(\"data_LWR/residual/x_test.pt\").long() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba06507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = torch.load(\"data_LWR/space/training_time.pt\").double()\n",
    "# training_initial = torch.load(\"data_LWR/space/training_time_initial.pt\").double()\n",
    "# training_boundary = torch.load(\"data_LWR/space/training_time_boundary.pt\").double() \n",
    "# test_data = torch.load(\"data_LWR/space/test_time.pt\").double()\n",
    "# test_initial = torch.load(\"data_LWR/space/test_time_initial.pt\").double()\n",
    "# test_boundary = torch.load(\"data_LWR/space/test_time_boundary.pt\").double() \n",
    "# x_train = torch.load(\"data_LWR/space/x_train.pt\").long()\n",
    "# x_test = torch.load(\"data_LWR/space/x_test.pt\").long() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "625d1982",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = torch.load(\"../pems_I5_S_correct.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f31769f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = [0,  45,  56,  75,  81,  86,  89,  95, 100, 105, 109, 112, 117,\n",
    "       124, 128, 133, 137, 141, 146, 149, 152, 158, 163, 167, 171, 174,\n",
    "       180, 186, 192, 197, 200, 205, 207, 210, 211, 213, 214, 228, 231,\n",
    "       237, 240, 242, 251, 254, 258, 262, 266, 270, 277, 279, 282, 283,\n",
    "       286, 288, 291, 294, 296, 298, 300, 303, 308, 310, 315, 317, 320,\n",
    "       322, 327, 338, 342, 345, 352, 356, 359, 362, 366, 368, 374, 379] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8af5fa3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 650 650\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#nx=350  # \n",
    "nx=380 \n",
    "#kj needs to be larger than k for the solution to be stable \n",
    "# kj = np.ones((nx,), dtype=float) * 0.6\n",
    "# kj = (kj - mean[0].numpy()) / std[0].numpy()\n",
    "# kj = (kj - y_min[0].numpy()) / (y_max[0].numpy() - y_min[0].numpy()) # normalize\n",
    "\n",
    "#characteristic velocity (m/s), corresponds to roughly 120 km/h\n",
    "# vf = np.ones((nx,), dtype=float) * 38\n",
    "# vf = (vf - mean[2].numpy()) / std[2].numpy()\n",
    "# vf = (vf - y_min[2].numpy()) / (y_max[2].numpy() - y_min[2].numpy()) # normalize\n",
    "\n",
    "dx=300.\n",
    "\n",
    "## change the timestep to dt = 1, previously dt = 6 with 7 mins runtime\n",
    "dt=6\n",
    "#need an output every 5 mins (300 s), so tskip = 3 with dt = 3s\n",
    "tskip=50\n",
    "#nt=int(3600*6/6 - 50)\n",
    "#nt=7099 #6 hours (times 3600 s/hour divided by dt=3s)\n",
    "nto=13 + 1\n",
    "#nt=int(3600*nto/12/6/dt - tskip)\n",
    "dtobs=300\n",
    "nt=int((dtobs*nto)/dt - tskip) \n",
    "\n",
    "nto=13 + 1\n",
    "#nt=int(3600*nto/12/6/dt - tskip)\n",
    "dtobs=300\n",
    "nt_test=int((dtobs*nto)/dt - tskip)\n",
    "print(dt, nt, nt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f4df69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def interpolate_initial(var, xi, t0=0): \n",
    "    IM_q=interp1d(np.array(xi) * dx, var[1, :].numpy(), bounds_error=False, \n",
    "                fill_value=(var[1, 0], var[1, -1]), kind='linear') \n",
    "    IM_u=interp1d(np.array(xi) * dx, var[2, :].numpy(), bounds_error=False, \n",
    "                fill_value=(var[2, 0], var[2, -1]), kind='linear') \n",
    "    \n",
    "    x=np.linspace(0, (nx-1) * dx, nx) \n",
    "    u = IM_u(x)\n",
    "    q = IM_q(x)\n",
    "    k = q / u\n",
    "    initial = np.stack((k, q, u))\n",
    "    return torch.tensor(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "764173ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ti=np.arange(0, (nt-1)*dt, tskip*dt )\n",
    "t=np.linspace(0, (nt-1)*dt, nt) \n",
    "ti_test=np.arange(0, (nt_test-1)*dt, tskip*dt )\n",
    "t_test = np.linspace(0, (nt_test-1)*dt, nt_test)\n",
    "\n",
    "def interpolate_boundary(var, ti, t): \n",
    "    IM_q=interp1d(np.array(ti), var[1, :, 0].numpy(), bounds_error=False,\n",
    "             fill_value=(var[1, 0, 0], var[1, -1, 0]), kind='linear')\n",
    "    IM_u=interp1d(np.array(ti), var[2, :, 0].numpy(), bounds_error=False,\n",
    "             fill_value=(var[2, 0, 0], var[2, -1, 0]), kind='linear')\n",
    "    u = IM_u(t)\n",
    "    q = IM_q(t)\n",
    "    k = q / u\n",
    "    boundary = np.stack((k, q, u)) \n",
    "    return torch.tensor(boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63439bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_lwr_res(data): \n",
    "#     interpolated = []\n",
    "#     for i in range(data.shape[1]): \n",
    "#         interpolated_d = interpolate_initial(data[:, i, :], xi, t0=0) \n",
    "#         interpolated.append(interpolated_d) \n",
    "#     interpolated_data = torch.stack(interpolated) \n",
    "#     interpolated_data = interpolated_data.permute(1, 0, 2)\n",
    "#     print(interpolated_data.shape) \n",
    "    \n",
    "    training_set = [] \n",
    "    test_set = [] \n",
    "    initial_train = []\n",
    "    boundary_train = []\n",
    "    initial_test = []\n",
    "    boundary_test = []\n",
    "    x_train = []\n",
    "    x_test = []\n",
    "    training_size = int((data.shape[1] - 25) * 0.8) \n",
    "    \n",
    "    for i in range(data.shape[1] - 25): \n",
    "        if i < training_size: \n",
    "            x_train.append(torch.tensor(xi))\n",
    "            training_set.append(data[:, i:i+25, :])\n",
    "            initial1 = interpolate_initial(data[:, i, :], xi, t0=0)\n",
    "            boundary1 = interpolate_boundary(data[:, i:i+13, :], ti, t) \n",
    "            initial2 = interpolate_initial(data[:, i+12, :], xi, t0=0)\n",
    "            boundary2 = interpolate_boundary(data[:, i+12:i+25, :], ti, t)\n",
    "            initial = torch.stack([initial1, initial2])\n",
    "            boundary = torch.stack([boundary1, boundary2])\n",
    "            initial_train.append(initial)\n",
    "            boundary_train.append(boundary)\n",
    "        else: \n",
    "            x_test.append(torch.tensor(xi))\n",
    "            test_set.append(data[:, i:i+25, :])\n",
    "            initial1 = interpolate_initial(data[:, i, :], xi, t0=0)\n",
    "            boundary1 = interpolate_boundary(data[:, i:i+13, :], ti, t) \n",
    "            initial2 = interpolate_initial(data[:, i+12, :], xi, t0=0)\n",
    "            boundary2 = interpolate_boundary(data[:, i+12:i+25, :], ti, t)\n",
    "            initial = torch.stack([initial1, initial2])\n",
    "            boundary = torch.stack([boundary1, boundary2])\n",
    "            initial_test.append(initial)\n",
    "            boundary_test.append(boundary) \n",
    "    \n",
    "    return torch.stack(x_train), torch.stack(x_test), torch.stack(training_set), torch.stack(test_set), torch.stack(initial_train), torch.stack(initial_test), torch.stack(boundary_train), torch.stack(boundary_test)  \n",
    "\n",
    "x_train, x_test, training_set, test_set, initial_train, initial_test, boundary_train, boundary_test = generate_data_lwr_res(data1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3767dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_idx = list(np.arange(380))\n",
    "\n",
    "def generate_data_lwr_date(data): \n",
    "    interpolated = []\n",
    "    for i in range(data.shape[1]): \n",
    "        interpolated_d = interpolate_initial(data[:, i, :], xi, t0=0) \n",
    "        interpolated.append(interpolated_d) \n",
    "    interpolated_data = torch.stack(interpolated) \n",
    "    interpolated_data = interpolated_data.permute(1, 0, 2)\n",
    "    print(interpolated_data.shape) \n",
    "\n",
    "    training_set = [] \n",
    "    test_set = [] \n",
    "    initial_train = []\n",
    "    boundary_train = []\n",
    "    initial_test = []\n",
    "    boundary_test = []\n",
    "    x_train = []\n",
    "    x_test = [] \n",
    "    training_size = int((data.shape[1] - 13) * 0.8) \n",
    "    \n",
    "    for i in range(data.shape[1] - 13): \n",
    "        if i < training_size: \n",
    "            x_train.append(torch.tensor(sensor_idx))\n",
    "            training_set.append(interpolated_data[:, i:i+4, :]) \n",
    "            initial = interpolate_initial(data[:, i, :], xi, t0=0)\n",
    "            boundary = interpolate_boundary(data[:, i:i+4, :], ti, t) \n",
    "            initial_train.append(initial)\n",
    "            boundary_train.append(boundary)\n",
    "        else: \n",
    "            x_test.append(torch.tensor(xi)) \n",
    "            test_set.append(data[:, i:i+13, :]) \n",
    "            initial = interpolate_initial(data[:, i, :], xi, t0=0)\n",
    "            boundary = interpolate_boundary(data[:, i:i+13, :], ti_test, t_test)\n",
    "            initial_test.append(initial)\n",
    "            boundary_test.append(boundary)\n",
    "    return torch.stack(x_train), torch.stack(x_test), torch.stack(training_set), torch.stack(test_set), torch.stack(initial_train), torch.stack(initial_test), torch.stack(boundary_train), torch.stack(boundary_test)  \n",
    "\n",
    "x_train, x_test, training_set, test_set, initial_train, initial_test, boundary_train, boundary_test = generate_data_lwr_date(data1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65800eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(time_train, \"data_LWR/time_train.pt\") \n",
    "# torch.save(time_test, \"data_LWR/time_test.pt\")\n",
    "# torch.save(training_set1, \"data_LWR/training_time.pt\")\n",
    "# torch.save(test_set1, \"data_LWR/test_time.pt\")\n",
    "# torch.save(initial_train, \"data_LWR/training_time_initial.pt\")\n",
    "# torch.save(initial_test, \"data_LWR/test_time_initial.pt\")\n",
    "# torch.save(boundary_train, \"data_LWR/training_time_boundary.pt\")\n",
    "# torch.save(boundary_test, \"data_LWR/test_time_boundary.pt\")\n",
    "# torch.save(x_train, \"data_LWR/x_train.pt\")\n",
    "# torch.save(x_test, \"data_LWR/x_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a54b990",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = LWRDataset_res(x_train, training_set, initial_train, boundary_train)\n",
    "test_set = LWRDataset_res(x_test, test_set, initial_test, boundary_test) \n",
    "# training_set = LWRDataset_res(x_train, training_data, training_initial, training_boundary)\n",
    "# test_set = LWRDataset_res(x_test, test_data, test_initial, test_boundary)\n",
    "training_set, val_set = data.random_split(training_set, [int(len(training_set) * 0.875), int(len(training_set) - int(len(training_set) * 0.875))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfa9e0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(training_set, batch_size = 256, shuffle = True, num_workers=0, pin_memory=True)\n",
    "val_loader = data.DataLoader(val_set, batch_size = 512, shuffle = False, num_workers=0, pin_memory=True)\n",
    "test_loader = data.DataLoader(test_set, batch_size = 512, shuffle = False, num_workers=0, pin_memory=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372a1ab8",
   "metadata": {},
   "source": [
    "### Hyperparameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9da300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial_1 = torch.load(\"AutoODE_result/time/best_AutoODE1.pt\") \n",
    "# LWR_model = trial_1[\"model\"] \n",
    "# LWR_model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01445df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in LWR_model.parameters(): \n",
    "#     p.requires_grad = False \n",
    "\n",
    "# print(sum(p.numel() for p in LWR_model.parameters() if p.requires_grad)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f810c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d \n",
    "\n",
    "def calibrate(data): \n",
    "    # assume the linear relation u = a * k + b \n",
    "    # cross all sensors / at each sensor \n",
    "#     print(data.shape)\n",
    "    kj = data[0, :42613].max(dim = 0).values\n",
    "    vf = data[2, :42613].max(dim = 0).values \n",
    "    IM_kj=interp1d(np.array(xi) * dx, kj.numpy(), bounds_error=False, \n",
    "                fill_value=(kj[0], kj[-1]), kind='linear') \n",
    "    IM_vf=interp1d(np.array(xi) * dx, vf.numpy(), bounds_error=False, \n",
    "                fill_value=(vf[0], vf[-1]), kind='linear')\n",
    "\n",
    "    x=np.linspace(0, (nx-1) * dx, nx) \n",
    "    kj = IM_kj(x) \n",
    "    vf = IM_vf(x) \n",
    "#     kj = (kj - y_min[0].numpy()) / (y_max[0].numpy() - y_min[0].numpy()) \n",
    "#     vf = (vf - y_min[2].numpy()) / (y_max[2].numpy() - y_min[2].numpy())\n",
    "#     k_mean = data[0].mean(dim = 0)\n",
    "#     u_mean = data[2].mean(dim = 0) \n",
    "#     k_m = data[0] - k_mean\n",
    "    \n",
    "#     b = ((k_m) * (data[2] - u_mean)).sum(dim = 0) / (k_m * k_m).sum(dim = 0)\n",
    "# #     print(b.shape)\n",
    "# #     a = u_mean - b * k_mean # vf\n",
    "#     kj = -(u_max / b)\n",
    "#     return kj, a   \n",
    "    return kj * 2, np.ceil(vf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "559a0259",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = torch.load(\"../pems_I5_S_correct.pt\") \n",
    "kj, vf = calibrate(data2) \n",
    "# kj, vf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc038d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps=torch.tensor(np.linspace(0, nt, nt), requires_grad=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48cb4a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_test=torch.tensor(np.linspace(0, nt_test, nt_test), requires_grad=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b31f3508",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" \n",
    "model = LWR_seq2seq_joint().to(device) \n",
    "# model = LWR_batch_version(nx, 300, 6, kj, vf, tskip, plm = False, plm_vf = False, \n",
    "#                           initial={}, boundary={}, fix_vf=False, parstep=1).to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d641784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3170783\n"
     ]
    }
   ],
   "source": [
    "name = \"hybrid_LWR_joint\"\n",
    "learning_rate = 0.002\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 1, gamma=0.95)\n",
    "criterion = nn.MSELoss()\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "best_loss = 100   \n",
    "train_losses = []\n",
    "val_losses = []\n",
    "tsteps = steps.shape[0]\n",
    "num_epoch = 100 \n",
    "trial = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c110b892",
   "metadata": {},
   "source": [
    "### Training and Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f29e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "for epoch in range(1, num_epoch + 1): \n",
    "    start = time.time()\n",
    "    train_loss = train_LWR(model, train_loader, optimizer, criterion, tsteps)[-1]\n",
    "    train_losses.append(train_loss)\n",
    "    _, _, val_loss = eval_LWR(model, val_loader, criterion, tsteps) \n",
    "\n",
    "    val_losses.append(val_loss)\n",
    "    if val_loss <= best_loss: \n",
    "        best_loss = val_loss \n",
    "        best_model = model\n",
    "        torch.save({\"lr\": optimizer.param_groups[0]['lr'], \"model\": model}, \"new_result/best3_AutoODE\" + str(trial) + \".pt\")\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Epoch:\", epoch, \"completed in:\", (end - start), \"s. Training loss:\", train_loss, \". Val loss:\", val_loss)  \n",
    "    if (len(train_losses) > 30 and np.mean(val_losses[-5:]) >= np.mean(val_losses[-10:-5])):\n",
    "        break\n",
    "    scheduler.step() \n",
    "    if epoch % 5 == 0: print(optimizer.param_groups[0]['lr']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c81b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsteps_test = steps_test.shape[0] \n",
    "preds, trues, test_loss = test_LWR(model, test_loader, criterion, tsteps_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5fd7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, np.sqrt(test_loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba0c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\"preds\": preds, \"trues\": trues, \"model\": model}, \"new_result/final_AutoODE3.pt\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6069d9",
   "metadata": {},
   "source": [
    "### Training hybrid model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81ff4f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Evaluation------\n",
      "Epoch: 1 completed in: 1463.8357820510864 s. Training loss: 2.0131008537330617 . Val loss: 1.335237555053506\n",
      "------Evaluation------\n",
      "Epoch: 2 completed in: 1728.9949719905853 s. Training loss: 1.2595100041001157 . Val loss: 1.1809719815115822\n",
      "------Evaluation------\n",
      "Epoch: 3 completed in: 1746.774498462677 s. Training loss: 1.1292362967196916 . Val loss: 1.0796818610495174\n",
      "------Evaluation------\n",
      "Epoch: 4 completed in: 1721.362154006958 s. Training loss: 1.0491306896990702 . Val loss: 1.0080065545386303\n",
      "------Evaluation------\n",
      "Epoch: 5 completed in: 1738.0617656707764 s. Training loss: 0.9929364823154455 . Val loss: 0.9682416433160266\n",
      "0.0015475618749999996\n",
      "------Evaluation------\n",
      "Epoch: 6 completed in: 1731.2247195243835 s. Training loss: 0.9414823700169369 . Val loss: 0.9171912349257376\n",
      "------Evaluation------\n",
      "Epoch: 7 completed in: 1735.9421977996826 s. Training loss: nan . Val loss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\STEPHE~1\\AppData\\Local\\Temp/ipykernel_600140/2721789749.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_hybrid_LWR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtsteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"------Evaluation------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\AutoODE_PEMS_traffic\\nn\\DNN\\datasets.py\u001b[0m in \u001b[0;36mtrain_hybrid_LWR\u001b[1;34m(model, train_loader, optimizer, criterion, steps)\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[0mmse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_pytorch\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "for epoch in range(1, num_epoch + 1): \n",
    "    start = time.time()\n",
    "    train_loss = train_hybrid_LWR(model, train_loader, optimizer, criterion, tsteps)[-1]\n",
    "    train_losses.append(train_loss) \n",
    "    print(\"------Evaluation------\") \n",
    "#     print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "    _, _, val_loss = eval_hybrid_LWR(model, val_loader, criterion, tsteps) \n",
    "#     print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "    val_losses.append(val_loss)\n",
    "    if val_loss <= best_loss: \n",
    "        best_loss = val_loss \n",
    "        best_model = model\n",
    "        torch.save({\"epoch\": epoch, \"model\": best_model}, \"time_hybridAutoODE_joint.pt\") \n",
    "    best_loss = best_loss\n",
    "    end = time.time()\n",
    "    print(\"Epoch:\", epoch, \"completed in:\", (end - start), \"s. Training loss:\", train_loss, \". Val loss:\", val_loss)  \n",
    "    if (len(train_losses) > 30 and np.mean(val_losses[-5:]) >= np.mean(val_losses[-10:-5])):\n",
    "        break\n",
    "    scheduler.step() \n",
    "    if epoch % 5 == 0: \n",
    "        print(optimizer.param_groups[0]['lr']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72ca9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial_1 = torch.load(\"AutoODE_result/time/time_hybridAutoODE1.pt\") \n",
    "# LWR_model = trial_1[\"model\"] \n",
    "# LWR_model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cb79c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
       "        72, 73, 74, 75, 76], dtype=torch.int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sensors = torch.tensor(np.arange(77))  \n",
    "test_sensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6a804e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\STEPHE~1\\AppData\\Local\\Temp/ipykernel_600140/2203983201.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtsteps_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msteps_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_hybrid_LWR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_sensors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtsteps_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\AutoODE_PEMS_traffic\\nn\\DNN\\datasets.py\u001b[0m in \u001b[0;36mtest_hybrid_LWR\u001b[1;34m(model, val_loader, criterion, test_sensors, steps)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_sensors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_sensors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\STEPHE~1\\AppData\\Local\\Temp/ipykernel_600140/2278939362.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, xi, x, initial, boundary, tsteps)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtsteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mpred1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLWR_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtsteps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# first 12\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLWR_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtsteps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# last 12\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpred1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\AutoODE_PEMS_traffic\\nn\\AutoODE\\LWR.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, xi, initial, boundary, tsteps)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mnk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[0mnu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m             \u001b[0mnq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;31m#new values for 3 variables stored in one tensor per time step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tsteps_test = steps_test.shape[0] \n",
    "criterion = nn.MSELoss() \n",
    "preds, trues, test_loss = test_hybrid_LWR(best_model, test_loader, criterion, test_sensors.long(), tsteps_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590121ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, np.sqrt(test_loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349b3e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\"preds\": preds, \"trues\": trues, \"model\": LWR_model}, \"AutoODE_result/time/time_AutoODE7.pt\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
