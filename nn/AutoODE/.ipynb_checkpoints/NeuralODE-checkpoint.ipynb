{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b7e119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchdiffeq import odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "991795f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Latent_ODE(nn.Module):\n",
    "    def __init__(self, latent_dim=4, obs_dim=2, nhidden=20, rhidden = 20, aug = False, aug_dim = 2):\n",
    "        super(Latent_ODE, self).__init__()\n",
    "        self.aug = aug\n",
    "        self.aug_dim = aug_dim\n",
    "        if self.aug:\n",
    "            self.rec = RecognitionRNN(latent_dim, obs_dim+aug_dim, rhidden)\n",
    "        else:\n",
    "            self.rec = RecognitionRNN(latent_dim, obs_dim, rhidden)\n",
    "    \n",
    "        self.func = LatentODEfunc(latent_dim, nhidden)\n",
    "        self.dec = LatentODEDecoder(latent_dim, obs_dim, nhidden)\n",
    "        \n",
    "    def forward(self, xx, output_length):\n",
    "        time_steps = torch.arange(0, output_length, 0.01).float().to(device)[:output_length]#torch.linspace(0, 59, 60).float().to(device)[:output_length]\n",
    "        if self.aug:\n",
    "            aug_ten = torch.zeros(xx.shape[0], xx.shape[1], self.aug_dim).float().to(device)\n",
    "            xx = torch.cat([xx, aug_ten], dim = -1)\n",
    "        z0 = self.rec.forward(torch.flip(xx, [1]))\n",
    "        pred_z = odeint(self.func, z0, time_steps).permute(1, 0, 2)\n",
    "        out = self.dec(pred_z)\n",
    "        if self.quantile:\n",
    "            out = self.quantile(out.unsqueeze(-1))\n",
    "        return out  \n",
    "    \n",
    "class LatentODEfunc(nn.Module):\n",
    "    def __init__(self, latent_dim=4, nhidden=20):\n",
    "        super(LatentODEfunc, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, nhidden),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(nhidden, nhidden),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(nhidden, nhidden),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(nhidden, nhidden),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(nhidden, latent_dim)\n",
    "        )\n",
    "        self.nfe = 0\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        self.nfe += 1\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "    \n",
    "class RecognitionRNN(nn.Module):\n",
    "    def __init__(self, latent_dim=4, obs_dim=2, nhidden=25):\n",
    "        super(RecognitionRNN, self).__init__()\n",
    "        self.nhidden = nhidden\n",
    "        self.model = nn.GRU(obs_dim, nhidden, batch_first = True)\n",
    "        self.linear = nn.Linear(nhidden, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #h0 = torch.zeros(1, x.shape[0], self.nhidden).to(device)\n",
    "        output, hn = self.model(x)#, h0\n",
    "        return self.linear(hn[0])\n",
    "    \n",
    "class LatentODEDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim=4, obs_dim=2, nhidden=20):\n",
    "        super(LatentODEDecoder, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, nhidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nhidden, obs_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, z):\n",
    "        out = self.model(z)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cef28d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Latent_ODE(latent_dim = 64, obs_dim = 3, nhidden = 128, rhidden = 128, aug = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a721739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 71, 31])\n"
     ]
    }
   ],
   "source": [
    "y_exact=torch.load(\"../../5S_191111_3cmp_torch.pt\")\n",
    "#first row (0) k, then (1) q, then (2) u\n",
    "#y_exact=y_exact[0:5,:]\n",
    "print(y_exact.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17e99f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
