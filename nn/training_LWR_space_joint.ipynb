{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0dc8f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "import time\n",
    "from DNN import Seq2Seq, LWRDataset, LWRDataset_res, train_LWR, eval_LWR, test_LWR, train_hybrid_LWR, eval_hybrid_LWR, test_hybrid_LWR \n",
    "from AutoODE import LWR_batch_version, LWR_seq2seq \n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6506a6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LWR_seq2seq_joint(nn.Module): \n",
    "#     def __init__(self): \n",
    "#         super(LWR_seq2seq_joint, self).__init__()\n",
    "#         self.LWR_model = model = LWR_batch_version(nx, 300, 6, kj, vf, tskip, plm = False, plm_vf = False, \n",
    "#                           initial={}, boundary={}, fix_vf=False, parstep=1).to(device).to(device) \n",
    "\n",
    "#         self.residual_model = Seq2Seq(input_dim = 231, hidden_dim = 512, output_dim = 231, num_layers = 1).to(device)\n",
    "    \n",
    "#     def forward(self, xi, x, initial, boundary, tsteps): \n",
    "#         pred1 = self.LWR_model(xi, initial[:, 0], boundary[:, 0], tsteps) # first 12\n",
    "#         pred = self.LWR_model(xi, initial[:, 1], boundary[:, 1], tsteps) # last 12\n",
    "#         res = x[:, :, 1:13, 1:] - pred1\n",
    "\n",
    "#         residual = self.residual_model(res.float(), 12) # last 12\n",
    "\n",
    "# #         pred = pred2.detach().clone()\n",
    "#         pred += residual # residual[:, :, 1:] \n",
    "        \n",
    "#         return pred.double() \n",
    "\n",
    "class LWR_seq2seq_joint(nn.Module): \n",
    "    def __init__(self): \n",
    "        super(LWR_seq2seq_joint, self).__init__()\n",
    "        self.LWR_model = model = LWR_batch_version(nx, 300, 6, kj, vf, tskip, plm = False, plm_vf = False, \n",
    "                          initial={}, boundary={}, fix_vf=False, parstep=1).to(device).to(device) \n",
    "\n",
    "        self.residual_model = Seq2Seq(input_dim = 231, hidden_dim = 1024, output_dim = 231, num_layers = 1).to(device)\n",
    "    \n",
    "    def forward(self, xi, x, initial, boundary_in, boundary_out, tsteps, pred_len): \n",
    "        input_len = int(x.shape[2] / 2) + 1 \n",
    "        with torch.no_grad():\n",
    "            pred1 = self.LWR_model(xi, initial[:, 0], boundary_in, tsteps) # first 12\n",
    "        pred = self.LWR_model(xi, initial[:, 1], boundary_out, tsteps) # last 12\n",
    "        # print(pred1.shape, x[:, :, 1:pred_len, 1:].shape)\n",
    "        res = x[:, :, 1:, 1:] - pred1.detach().clone() \n",
    "#         print(x.shape, res.shape)\n",
    "        residual = self.residual_model(res.float(), pred_len) # last 12\n",
    "#         print(residual.shape)\n",
    "#         pred = pred2.detach().clone()\n",
    "        pred += residual # residual[:, :, 1:] \n",
    "#         print(pred.shape, x.shape)\n",
    "        return pred.double() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7742dd0",
   "metadata": {},
   "source": [
    "### Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8189f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = torch.load(\"data_LWR/residual/training_time.pt\").double()\n",
    "# training_initial = torch.load(\"data_LWR/residual/training_time_initial.pt\").double()\n",
    "# training_boundary = torch.load(\"data_LWR/residual/training_time_boundary.pt\").double()\n",
    "# x_train = torch.load(\"data_LWR/residual/x_train.pt\").long()\n",
    "# test_data = torch.load(\"data_LWR/residual/test_time.pt\").double()\n",
    "# test_initial = torch.load(\"data_LWR/residual/test_time_initial.pt\").double()\n",
    "# test_boundary = torch.load(\"data_LWR/residual/test_time_boundary.pt\").double()\n",
    "# x_test = torch.load(\"data_LWR/residual/x_test.pt\").long() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba06507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = torch.load(\"data_LWR/space/training_time.pt\").double()\n",
    "# training_initial = torch.load(\"data_LWR/space/training_time_initial.pt\").double()\n",
    "# training_boundary = torch.load(\"data_LWR/space/training_time_boundary.pt\").double() \n",
    "# test_data = torch.load(\"data_LWR/space/test_time.pt\").double()\n",
    "# test_initial = torch.load(\"data_LWR/space/test_time_initial.pt\").double()\n",
    "# test_boundary = torch.load(\"data_LWR/space/test_time_boundary.pt\").double() \n",
    "# x_train = torch.load(\"data_LWR/space/x_train.pt\").long()\n",
    "# x_test = torch.load(\"data_LWR/space/x_test.pt\").long() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "625d1982",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = torch.load(\"../pems_I5_S_correct.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f31769f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = [0,  45,  56,  75,  81,  86,  89,  95, 100, 105, 109, 112, 117,\n",
    "       124, 128, 133, 137, 141, 146, 149, 152, 158, 163, 167, 171, 174,\n",
    "       180, 186, 192, 197, 200, 205, 207, 210, 211, 213, 214, 228, 231,\n",
    "       237, 240, 242, 251, 254, 258, 262, 266, 270, 277, 279, 282, 283,\n",
    "       286, 288, 291, 294, 296, 298, 300, 303, 308, 310, 315, 317, 320,\n",
    "       322, 327, 338, 342, 345, 352, 356, 359, 362, 366, 368, 374, 379] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8af5fa3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 650 650\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#nx=350  # \n",
    "nx=380 \n",
    "#kj needs to be larger than k for the solution to be stable \n",
    "# kj = np.ones((nx,), dtype=float) * 0.6\n",
    "# kj = (kj - mean[0].numpy()) / std[0].numpy()\n",
    "# kj = (kj - y_min[0].numpy()) / (y_max[0].numpy() - y_min[0].numpy()) # normalize\n",
    "\n",
    "#characteristic velocity (m/s), corresponds to roughly 120 km/h\n",
    "# vf = np.ones((nx,), dtype=float) * 38\n",
    "# vf = (vf - mean[2].numpy()) / std[2].numpy()\n",
    "# vf = (vf - y_min[2].numpy()) / (y_max[2].numpy() - y_min[2].numpy()) # normalize\n",
    "\n",
    "dx=300.\n",
    "\n",
    "## change the timestep to dt = 1, previously dt = 6 with 7 mins runtime\n",
    "dt=6\n",
    "#need an output every 5 mins (300 s), so tskip = 3 with dt = 3s\n",
    "tskip=50\n",
    "#nt=int(3600*6/6 - 50)\n",
    "#nt=7099 #6 hours (times 3600 s/hour divided by dt=3s)\n",
    "nto=13 + 1 # 7 is the best\n",
    "#nt=int(3600*nto/12/6/dt - tskip)\n",
    "dtobs=300\n",
    "nt=int((dtobs*nto)/dt - tskip) \n",
    "\n",
    "nto=13 + 1\n",
    "#nt=int(3600*nto/12/6/dt - tskip)\n",
    "dtobs=300\n",
    "nt_test=int((dtobs*nto)/dt - tskip)\n",
    "print(dt, nt, nt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00912c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sensors = np.array([0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
    "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
    "        35, 36, 37, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74,\n",
    "        75, 76, 77])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4bdeb63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70,\n",
       "       71, 72, 73, 74, 75, 76, 77])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_sensors.sort() \n",
    "# training_sensors = training_sensors - 1 \n",
    "training_sensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "837c70a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,\n",
       "       55, 56, 57])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sensors = np.array(list(set(np.arange(0, 78)) - set(training_sensors))) \n",
    "test_sensors.sort() \n",
    "test_sensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f4df69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def interpolate_initial(var, xi, t0=0): \n",
    "    IM_q=interp1d(np.array(xi) * dx, var[1, :].numpy(), bounds_error=False, \n",
    "                fill_value=(var[1, 0], var[1, -1]), kind='linear') \n",
    "    IM_u=interp1d(np.array(xi) * dx, var[2, :].numpy(), bounds_error=False, \n",
    "                fill_value=(var[2, 0], var[2, -1]), kind='linear') \n",
    "    \n",
    "    x=np.linspace(0, (nx-1) * dx, nx) \n",
    "    u = IM_u(x)\n",
    "    q = IM_q(x)\n",
    "    k = q / u\n",
    "    initial = np.stack((k, q, u))\n",
    "    return torch.tensor(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "764173ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ti=np.arange(0, (nt-1)*dt, tskip*dt )\n",
    "t=np.linspace(0, (nt-1)*dt, nt) \n",
    "ti_test=np.arange(0, (nt_test-1)*dt, tskip*dt )\n",
    "t_test = np.linspace(0, (nt_test-1)*dt, nt_test)\n",
    "\n",
    "def interpolate_boundary(var, ti, t): \n",
    "    IM_q=interp1d(np.array(ti), var[1, :, 0].numpy(), bounds_error=False,\n",
    "             fill_value=(var[1, 0, 0], var[1, -1, 0]), kind='linear')\n",
    "    IM_u=interp1d(np.array(ti), var[2, :, 0].numpy(), bounds_error=False,\n",
    "             fill_value=(var[2, 0, 0], var[2, -1, 0]), kind='linear')\n",
    "    u = IM_u(t)\n",
    "    q = IM_q(t)\n",
    "    k = q / u\n",
    "    boundary = np.stack((k, q, u)) \n",
    "    return torch.tensor(boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63439bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 53280, 380])\n"
     ]
    }
   ],
   "source": [
    "def generate_data_lwr_res(data): \n",
    "    interpolated = []\n",
    "    for i in range(data.shape[1]): \n",
    "        interpolated_d = interpolate_initial(data[:, i, :], xi, t0=0) \n",
    "        interpolated.append(interpolated_d) \n",
    "    interpolated_data = torch.stack(interpolated) \n",
    "    interpolated_data = interpolated_data.permute(1, 0, 2)\n",
    "    print(interpolated_data.shape) \n",
    "    \n",
    "    training_set_input = [] \n",
    "    training_set_output = [] \n",
    "    test_set_input = [] \n",
    "    test_set_output = []\n",
    "    initial_train = []\n",
    "    boundary_train_in = []\n",
    "    boundary_train_out = []\n",
    "    initial_test = []\n",
    "    boundary_test_in = []\n",
    "    boundary_test_out = []\n",
    "    x_train = []\n",
    "    x_test = []\n",
    "    training_size = int((data.shape[1] - 25) * 0.8) \n",
    "    \n",
    "    for i in range(data.shape[1] - 25): \n",
    "        x_train.append(torch.tensor(xi))\n",
    "#             training_set_input.append(data[:, i:i+9, :])\n",
    "#             training_set_output.append(data[:, i+9:i+17, :])\n",
    "#             initial1 = interpolate_initial(data[:, i, :], xi, t0=0)\n",
    "#             boundary1 = interpolate_boundary(data[:, i:i+9, :], ti, t) \n",
    "#             initial2 = interpolate_initial(data[:, i+8, :], xi, t0=0)\n",
    "#             boundary2 = interpolate_boundary(data[:, i+8:i+17, :], ti, t)\n",
    "#             initial = torch.stack([initial1, initial2])\n",
    "#             initial_train.append(initial)\n",
    "#             boundary_train_in.append(boundary1)\n",
    "#             boundary_train_out.append(boundary2)\n",
    "        training_set_input.append(interpolated_data[:, i:i+13, torch.tensor(xi)])\n",
    "        training_set_output.append(interpolated_data[:, i+13:i+25, torch.tensor(xi)])\n",
    "        initial1 = interpolate_initial(data[:, i, :], xi, t0=0)\n",
    "        boundary1 = interpolate_boundary(data[:, i:i+13, :], ti, t) \n",
    "        initial2 = interpolate_initial(data[:, i+12, :], xi, t0=0)\n",
    "        boundary2 = interpolate_boundary(data[:, i+12:i+25, :], ti, t)\n",
    "        initial = torch.stack([initial1, initial2])\n",
    "        initial_train.append(initial)\n",
    "        boundary_train_in.append(boundary1)\n",
    "        boundary_train_out.append(boundary2)\n",
    "\n",
    "        x_test.append(torch.tensor(xi))\n",
    "        test_set_input.append(data[:, i:i+13, :])\n",
    "        test_set_output.append(data[:, i+13:i+25, :])\n",
    "        initial1 = interpolate_initial(data[:, i, :], xi, t0=0)\n",
    "        boundary1 = interpolate_boundary(data[:, i:i+13, :], ti_test, t_test) \n",
    "        initial2 = interpolate_initial(data[:, i+12, :], xi, t0=0)\n",
    "        boundary2 = interpolate_boundary(data[:, i+12:i+25, :], ti_test, t_test)\n",
    "        initial = torch.stack([initial1, initial2])\n",
    "#             boundary = torch.stack([boundary1, boundary2])\n",
    "        initial_test.append(initial)\n",
    "        boundary_test_in.append(boundary1)\n",
    "        boundary_test_out.append(boundary2)\n",
    "    \n",
    "    return torch.stack(x_train), torch.stack(x_test), torch.stack(training_set_input), torch.stack(training_set_output), torch.stack(test_set_input), torch.stack(test_set_output), torch.stack(initial_train), torch.stack(initial_test), torch.stack(boundary_train_in), torch.stack(boundary_train_out), torch.stack(boundary_test_in), torch.stack(boundary_test_out)   \n",
    "\n",
    "x_train, x_test, training_set_input, training_set_output, test_set_input, test_set_output, initial_train, initial_test, boundary_train_in, boundary_train_out, boundary_test_in, boundary_test_out = generate_data_lwr_res(data1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96b9b47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(time_train, \"data_LWR/time_train.pt\") \n",
    "# torch.save(time_test, \"data_LWR/time_test.pt\")\n",
    "torch.save(training_set, \"data_LWR/training_time.pt\")\n",
    "torch.save(test_set, \"data_LWR/test_time.pt\")\n",
    "torch.save(initial_train, \"data_LWR/training_time_initial.pt\")\n",
    "torch.save(initial_test, \"data_LWR/test_time_initial.pt\")\n",
    "torch.save(boundary_train, \"data_LWR/training_time_boundary.pt\")\n",
    "torch.save(boundary_test, \"data_LWR/test_time_boundary.pt\")\n",
    "torch.save(x_train, \"data_LWR/x_train.pt\")\n",
    "torch.save(x_test, \"data_LWR/x_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3767dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensor_idx = list(np.arange(380))\n",
    "\n",
    "# def generate_data_lwr_date(data): \n",
    "#     interpolated = []\n",
    "#     for i in range(data.shape[1]): \n",
    "#         interpolated_d = interpolate_initial(data[:, i, :], xi, t0=0) \n",
    "#         interpolated.append(interpolated_d) \n",
    "#     interpolated_data = torch.stack(interpolated) \n",
    "#     interpolated_data = interpolated_data.permute(1, 0, 2)\n",
    "#     print(interpolated_data.shape) \n",
    "\n",
    "#     training_set = [] \n",
    "#     test_set = [] \n",
    "#     initial_train = []\n",
    "#     boundary_train = []\n",
    "#     initial_test = []\n",
    "#     boundary_test = []\n",
    "#     x_train = []\n",
    "#     x_test = [] \n",
    "#     training_size = int((data.shape[1] - 13) * 0.8) \n",
    "    \n",
    "#     for i in range(data.shape[1] - 13): \n",
    "#         if i < training_size: \n",
    "#             x_train.append(torch.tensor(sensor_idx))\n",
    "#             training_set.append(interpolated_data[:, i:i+4, :]) \n",
    "#             initial = interpolate_initial(data[:, i, :], xi, t0=0)\n",
    "#             boundary = interpolate_boundary(data[:, i:i+4, :], ti, t) \n",
    "#             initial_train.append(initial)\n",
    "#             boundary_train.append(boundary)\n",
    "#         else: \n",
    "#             x_test.append(torch.tensor(xi)) \n",
    "#             test_set.append(data[:, i:i+13, :]) \n",
    "#             initial = interpolate_initial(data[:, i, :], xi, t0=0)\n",
    "#             boundary = interpolate_boundary(data[:, i:i+13, :], ti_test, t_test)\n",
    "#             initial_test.append(initial)\n",
    "#             boundary_test.append(boundary)\n",
    "#     return torch.stack(x_train), torch.stack(x_test), torch.stack(training_set), torch.stack(test_set), torch.stack(initial_train), torch.stack(initial_test), torch.stack(boundary_train), torch.stack(boundary_test)  \n",
    "\n",
    "# x_train, x_test, training_set, test_set, initial_train, initial_test, boundary_train, boundary_test = generate_data_lwr_date(data1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65800eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(time_train, \"data_LWR/time_train.pt\") \n",
    "# torch.save(time_test, \"data_LWR/time_test.pt\")\n",
    "# torch.save(training_set1, \"data_LWR/training_time.pt\")\n",
    "# torch.save(test_set1, \"data_LWR/test_time.pt\")\n",
    "# torch.save(initial_train, \"data_LWR/training_time_initial.pt\")\n",
    "# torch.save(initial_test, \"data_LWR/test_time_initial.pt\")\n",
    "# torch.save(boundary_train, \"data_LWR/training_time_boundary.pt\")\n",
    "# torch.save(boundary_test, \"data_LWR/test_time_boundary.pt\")\n",
    "# torch.save(x_train, \"data_LWR/x_train.pt\")\n",
    "# torch.save(x_test, \"data_LWR/x_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a54b990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_set = LWRDataset_res(x_train, training_set, initial_train, boundary_train)\n",
    "# test_set = LWRDataset_res(x_test, test_set, initial_test, boundary_test) \n",
    "training_set = LWRDataset_res(x_train, training_set_input, training_set_output, initial_train, boundary_train_in, boundary_train_out)\n",
    "test_set = LWRDataset_res(x_test, test_set_input, test_set_output, initial_test, boundary_test_in, boundary_test_out)\n",
    "# training_set = LWRDataset_res(x_train, training_data, training_initial, training_boundary)\n",
    "# test_set = LWRDataset_res(x_test, test_data, test_initial, test_boundary)\n",
    "training_set, val_set = data.random_split(training_set, [int(len(training_set) * 0.875), int(len(training_set) - int(len(training_set) * 0.875))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfa9e0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(training_set, batch_size = 256, shuffle = True, num_workers=0, pin_memory=True)\n",
    "val_loader = data.DataLoader(val_set, batch_size = 512, shuffle = False, num_workers=0, pin_memory=True)\n",
    "test_loader = data.DataLoader(test_set, batch_size = 512, shuffle = False, num_workers=0, pin_memory=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372a1ab8",
   "metadata": {},
   "source": [
    "### Hyperparameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9da300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial_1 = torch.load(\"AutoODE_result/time/best_AutoODE1.pt\") \n",
    "# LWR_model = trial_1[\"model\"] \n",
    "# LWR_model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01445df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in LWR_model.parameters(): \n",
    "#     p.requires_grad = False \n",
    "\n",
    "# print(sum(p.numel() for p in LWR_model.parameters() if p.requires_grad)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f810c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d \n",
    "\n",
    "def calibrate(data): \n",
    "    # assume the linear relation u = a * k + b \n",
    "    # cross all sensors / at each sensor \n",
    "#     print(data.shape)\n",
    "    kj = data[0].max(dim = 0).values\n",
    "    vf = data[2].max(dim = 0).values \n",
    "    IM_kj=interp1d(np.array(xi) * dx, kj.numpy(), bounds_error=False, \n",
    "                fill_value=(kj[0], kj[-1]), kind='linear') \n",
    "    IM_vf=interp1d(np.array(xi) * dx, vf.numpy(), bounds_error=False, \n",
    "                fill_value=(vf[0], vf[-1]), kind='linear')\n",
    "\n",
    "    x=np.linspace(0, (nx-1) * dx, nx) \n",
    "    kj = IM_kj(x) \n",
    "    vf = IM_vf(x) \n",
    "#     kj = (kj - y_min[0].numpy()) / (y_max[0].numpy() - y_min[0].numpy()) \n",
    "#     vf = (vf - y_min[2].numpy()) / (y_max[2].numpy() - y_min[2].numpy())\n",
    "#     k_mean = data[0].mean(dim = 0)\n",
    "#     u_mean = data[2].mean(dim = 0) \n",
    "#     k_m = data[0] - k_mean\n",
    "    \n",
    "#     b = ((k_m) * (data[2] - u_mean)).sum(dim = 0) / (k_m * k_m).sum(dim = 0)\n",
    "# #     print(b.shape)\n",
    "# #     a = u_mean - b * k_mean # vf\n",
    "#     kj = -(u_max / b)\n",
    "#     return kj, a   \n",
    "    return kj * 1.2, np.ceil(vf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "559a0259",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = torch.load(\"../pems_I5_S_correct.pt\") \n",
    "kj, vf = calibrate(data2) \n",
    "# kj, vf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc038d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps=torch.tensor(np.linspace(0, nt, nt), requires_grad=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48cb4a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_test=torch.tensor(np.linspace(0, nt_test, nt_test), requires_grad=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b31f3508",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" \n",
    "model = LWR_seq2seq_joint().to(device) \n",
    "# model = LWR_batch_version(nx, 300, 6, kj, vf, tskip, plm = False, plm_vf = False, \n",
    "#                           initial={}, boundary={}, fix_vf=False, parstep=1).to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7f0566e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad37d043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"hybridAutoODE_time11_hybrid_LWR_joint6.pt\", map_location=torch.device('cuda'))\n",
    "a = checkpoint['model']\n",
    "del a[\"LWR_model.initial\"]\n",
    "del a[\"LWR_model.boundary\"]\n",
    "model.load_state_dict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d641784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10534879\n"
     ]
    }
   ],
   "source": [
    "name = \"hybrid_LWR_joint\"\n",
    "learning_rate = 0.002\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 1, gamma=0.95)\n",
    "criterion = nn.MSELoss()\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "best_loss = 100   \n",
    "train_losses = []\n",
    "val_losses = []\n",
    "tsteps = steps.shape[0]\n",
    "tsteps_test = steps_test.shape[0] \n",
    "pred_len = 12 \n",
    "test_sensors = torch.tensor(np.arange(77)) \n",
    "num_epoch = 11 \n",
    "trial = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c110b892",
   "metadata": {},
   "source": [
    "### Training and Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f29e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time \n",
    "\n",
    "# for epoch in range(1, num_epoch + 1): \n",
    "#     start = time.time()\n",
    "#     train_loss = train_LWR(model, train_loader, optimizer, criterion, tsteps)[-1]\n",
    "#     train_losses.append(train_loss)\n",
    "#     _, _, val_loss = eval_LWR(model, val_loader, criterion, tsteps) \n",
    "\n",
    "#     val_losses.append(val_loss)\n",
    "#     if val_loss <= best_loss: \n",
    "#         best_loss = val_loss \n",
    "#         best_model = model\n",
    "#         torch.save({\"lr\": optimizer.param_groups[0]['lr'], \"model\": model}, \"new_result/best3_AutoODE\" + str(trial) + \".pt\")\n",
    "\n",
    "#     end = time.time()\n",
    "#     print(\"Epoch:\", epoch, \"completed in:\", (end - start), \"s. Training loss:\", train_loss, \". Val loss:\", val_loss)  \n",
    "#     if (len(train_losses) > 30 and np.mean(val_losses[-5:]) >= np.mean(val_losses[-10:-5])):\n",
    "#         break\n",
    "#     scheduler.step() \n",
    "#     if epoch % 5 == 0: print(optimizer.param_groups[0]['lr']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c81b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsteps_test = steps_test.shape[0] \n",
    "preds, trues, test_loss = test_LWR(model, test_loader, criterion, tsteps_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5fd7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, np.sqrt(test_loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba0c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\"preds\": preds, \"trues\": trues, \"model\": model}, \"new_result/final_AutoODE3.pt\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6069d9",
   "metadata": {},
   "source": [
    "### Training hybrid model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cf804c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Evaluation------\n",
      "0.7281738548666701\n",
      "1.37729877760035\n",
      "1.0411052082046852\n",
      "0.6395277149890864\n",
      "0.7428168029901178\n",
      "1.040689485571858\n",
      "0.908934316706272\n",
      "0.8291934190470535\n",
      "1.3893077529152649\n",
      "1.317224104699368\n",
      "0.770670733342417\n",
      "0.7306734099153226\n",
      "1.0383478745917036\n",
      "1.4156947093722163\n",
      "0.6059067453563926\n",
      "0.6789548149822805\n",
      "0.9885385516649535\n",
      "1.2894828765418442\n",
      "0.8104398857778304\n",
      "0.5304945710456184\n",
      "1.3955671459589611\n",
      "1.2896125432848489\n",
      "0.6127062177341641\n",
      "0.969389548527912\n",
      "1.2307863189793449\n",
      "1.620963044266586\n",
      "1.3009079935742078\n",
      "0.678558951590673\n",
      "0.5758422627545\n",
      "1.3553460197380955\n",
      "0.750900797577814\n",
      "0.7419391667767892\n",
      "1.2970407293102082\n",
      "1.2115036368733432\n",
      "0.6470378677535017\n",
      "0.6896539210922881\n",
      "0.6969442226515667\n",
      "1.5009752481046812\n",
      "0.6265591857271255\n",
      "1.205065355520362\n",
      "1.4003122652889413\n",
      "1.481154354219613\n",
      "1.0262981635741544\n",
      "0.629380864036139\n",
      "1.2828870199089637\n",
      "1.805783538284432\n",
      "0.7543710131956063\n",
      "0.852485435898105\n",
      "1.2206030676229356\n",
      "1.749596720971928\n",
      "0.6929399170006065\n",
      "0.8946356195861026\n",
      "1.3486923860121136\n",
      "1.8350308837716949\n",
      "1.138198044439652\n",
      "1.0459766648742947\n",
      "1.3268860849303987\n",
      "1.4481187959104442\n",
      "0.6705092259400183\n",
      "1.0693105584398443\n",
      "1.43425461436858\n",
      "1.1232570956456183\n",
      "0.680356032098257\n",
      "1.2054396596615102\n",
      "1.2773879219426438\n",
      "1.2979955049143395\n",
      "0.7545715709015048\n",
      "1.1984265383867836\n",
      "2.0667648673026453\n",
      "0.9718418651157408\n",
      "1.2523356671988504\n",
      "1.4051653698057573\n",
      "1.9016993264051032\n",
      "0.7917657411440338\n",
      "0.7561385544082537\n",
      "1.150752899908995\n",
      "1.893506856007836\n",
      "0.9080228465600856\n",
      "1.1354636234296018\n",
      "1.5605314485013522\n",
      "1.7857638225436623\n",
      "0.985947233417678\n",
      "0.7593302761626946\n",
      "1.0931975055675986\n",
      "1.942439256927662\n",
      "0.7866273331220095\n",
      "0.6640132884833023\n",
      "0.9504620022211621\n",
      "1.742508308894577\n",
      "0.9033368451201803\n",
      "1.9324361582581606\n",
      "1.0209126684860066\n",
      "1.4641891717310622\n",
      "0.8498749810527315\n",
      "1.604127089129003\n",
      "1.3071688428473356\n",
      "1.2342565696354952\n",
      "0.8614357991086548\n",
      "0.7824397604657638\n",
      "1.7765997268517262\n",
      "1.1373836028715458\n",
      "0.6222290116498307\n",
      "0.9239558739539445\n",
      "1.818670194400089\n",
      "0.35834639032282306\n",
      "Epoch: 1 completed in: 945.3877160549164 s. Training loss: 1.443443398523782 . Val loss: 1.092947045616984 . Test loss: 1.114450248845871\n",
      "------Evaluation------\n",
      "0.6112621627628192\n",
      "1.1616110775352368\n",
      "0.9018224799500163\n",
      "0.5450246300330573\n",
      "0.617634722160663\n",
      "0.8892378717969412\n",
      "0.7718858837316585\n",
      "0.7619758945398912\n",
      "1.2011489513970472\n",
      "1.1414939669971085\n",
      "0.6663934145540932\n",
      "0.6402729715603125\n",
      "0.8754722348268185\n",
      "1.2502725284278398\n",
      "0.5080763668239153\n",
      "0.5967320936696513\n",
      "0.8156363426851384\n",
      "1.085184411418939\n",
      "0.6677113520374401\n",
      "0.46315548474635687\n",
      "1.1771457390454863\n",
      "1.0894527809640844\n",
      "0.5278919454210571\n",
      "0.8240183293969565\n",
      "1.0249181769278155\n",
      "1.2977765417012728\n",
      "1.0818953715061137\n",
      "0.5493955265817253\n",
      "0.4831483897620674\n",
      "1.215416362432452\n",
      "0.673832991374057\n",
      "0.6192835218803149\n",
      "1.0906194819590687\n",
      "0.9984383068566723\n",
      "0.5841927667539164\n",
      "0.547454213918655\n",
      "0.5956277072765445\n",
      "1.3445234509078727\n",
      "0.568302042828914\n",
      "1.0761981805875316\n",
      "1.3253096658746522\n",
      "1.2705689513857803\n",
      "0.7177174368704967\n",
      "0.5244987965138431\n",
      "1.0779560889081212\n",
      "1.5081749490949303\n",
      "0.5707237317204993\n",
      "0.7593323578771015\n",
      "1.0599290708678808\n",
      "1.475022243352743\n",
      "0.6490078007305083\n",
      "0.8401570675775383\n",
      "1.2804820223551654\n",
      "1.6205318432602625\n",
      "1.0365065887576232\n",
      "0.9670425226499239\n",
      "1.1844094011842459\n",
      "1.2012187352860058\n",
      "0.631445426396446\n",
      "0.9799879783850238\n",
      "1.2826649774585066\n",
      "1.0001627357462013\n",
      "0.5521039986208436\n",
      "1.0937915709719996\n",
      "1.160684639432958\n",
      "1.1382989546072488\n",
      "0.6950150487473413\n",
      "1.0785380899351564\n",
      "1.741851720637052\n",
      "0.8297369433251266\n",
      "1.0361182526280457\n",
      "1.2875404824249024\n",
      "1.6330844459209932\n",
      "0.7141794942440527\n",
      "0.6449816962411713\n",
      "0.9996903729703652\n",
      "1.73836728678275\n",
      "0.8174353156442625\n",
      "0.99507757497834\n",
      "1.4319844932811998\n",
      "1.5512754015056844\n",
      "0.8621476088241942\n",
      "0.6752361027480527\n",
      "0.9542824959478177\n",
      "1.6551051549888733\n",
      "0.6759386888156239\n",
      "0.599370153563478\n",
      "0.8190705136419794\n",
      "1.5439870401159048\n",
      "0.787148574158827\n",
      "1.331460993448652\n",
      "0.8872686765698928\n",
      "1.3201170655275494\n",
      "0.7627269871000055\n",
      "1.3142564988654666\n",
      "1.1461886663221885\n",
      "0.9733201007770631\n",
      "0.7368105723065679\n",
      "0.6483263326454584\n",
      "1.4986222242155052\n",
      "1.0174223273124092\n",
      "0.543448523173693\n",
      "0.7534546384076717\n",
      "1.5485486152895485\n",
      "0.3871373555118748\n",
      "Epoch: 2 completed in: 951.3334629535675 s. Training loss: 1.0033350526787164 . Val loss: 0.9616873740889107 . Test loss: 0.9627194167158935\n",
      "------Evaluation------\n",
      "0.5520656625026156\n",
      "1.0194234852351496\n",
      "0.8109699136569897\n",
      "0.4863176273397628\n",
      "0.5624190486805352\n",
      "0.7801306515912813\n",
      "0.7348606821334924\n",
      "0.715353779264387\n",
      "1.0066739230934647\n",
      "1.0009878688576261\n",
      "0.6334966030041344\n",
      "0.5801553634410858\n",
      "0.8116164320934741\n",
      "1.1206147440833425\n",
      "0.49337134987357845\n",
      "0.5359401064123078\n",
      "0.743950468950843\n",
      "0.9478694555786551\n",
      "0.6762795659034035\n",
      "0.424937700703689\n",
      "1.0645510913608285\n",
      "0.9738409984582715\n",
      "0.4771687804809791\n",
      "0.7172168430387837\n",
      "0.9057900766645512\n",
      "1.0641977460379737\n",
      "0.9573548287911604\n",
      "0.5264393686936506\n",
      "0.43512511725518416\n",
      "1.054954648746537\n",
      "0.5872883814917513\n",
      "0.5612887153825409\n",
      "0.9253337628879026\n",
      "0.8580220244256738\n",
      "0.5332231058954403\n",
      "0.5255783131139485\n",
      "0.550317379698251\n",
      "1.1358279240049063\n",
      "0.4856334319683635\n",
      "0.935894768054443\n",
      "1.1166318126211405\n",
      "1.2292806874505038\n",
      "0.5769359813291213\n",
      "0.5105814451891607\n",
      "0.9034348880868214\n",
      "1.29452488550837\n",
      "0.5125948900220241\n",
      "0.6978040513630923\n",
      "0.9670997093938861\n",
      "1.3686731432511658\n",
      "0.6064309845456609\n",
      "0.7776685728568486\n",
      "1.117244182631119\n",
      "1.4160152526675607\n",
      "0.8739842936064752\n",
      "0.8165378722202796\n",
      "0.9890158269718102\n",
      "1.0939437033367883\n",
      "0.5770866136697296\n",
      "0.9266719044218282\n",
      "1.1541896002743617\n",
      "0.9146423727221737\n",
      "0.48825674904762445\n",
      "1.0456701586043762\n",
      "1.038977608864073\n",
      "1.0343445205785118\n",
      "0.670891883379123\n",
      "0.9874984342717255\n",
      "1.5745237004029322\n",
      "0.7406360085195128\n",
      "0.9220969105693311\n",
      "1.1271816925606808\n",
      "1.4414366075590883\n",
      "0.6619689597872029\n",
      "0.5738380530887356\n",
      "0.9159251649472007\n",
      "1.5948375540568458\n",
      "0.7249793925259033\n",
      "0.8844981114593521\n",
      "1.2392274760910709\n",
      "1.3513074051072826\n",
      "0.8277063067998147\n",
      "0.6128245866257122\n",
      "0.868177089323401\n",
      "1.5137211506568955\n",
      "0.6102387877615245\n",
      "0.5554099598602606\n",
      "0.7284783971784582\n",
      "1.3323144493586272\n",
      "0.6932036366307266\n",
      "1.0386909771920414\n",
      "0.8307902894871427\n",
      "1.1314960163284782\n",
      "0.682586578144482\n",
      "1.1733178947216325\n",
      "0.990378349391168\n",
      "0.9377905149427362\n",
      "0.7012418496278\n",
      "0.587882901783616\n",
      "1.3733775518427318\n",
      "0.9993347278842744\n",
      "0.48678234751705335\n",
      "0.6845086058505413\n",
      "1.3135171727783734\n",
      "0.3148433236034547\n",
      "Epoch: 3 completed in: 937.5766098499298 s. Training loss: 0.8704800908398764 . Val loss: 0.8819040500990136 . Test loss: 0.8605731835209752\n",
      "------Evaluation------\n",
      "0.5771473407337248\n",
      "0.9609370377365781\n",
      "0.7364353108089107\n",
      "0.4334660184738419\n",
      "0.5745398099597069\n",
      "0.7378640755419872\n",
      "0.6858953129207332\n",
      "0.6943602278610411\n",
      "0.9453573865512045\n",
      "0.9445370479854206\n",
      "0.5318844519346148\n",
      "0.5106577136713658\n",
      "0.8433489259781145\n",
      "1.0424441575698136\n",
      "0.4126385499573383\n",
      "0.5397312980211532\n",
      "0.7321605816043806\n",
      "0.9281212935370873\n",
      "0.5897710170330576\n",
      "0.4336250703238165\n",
      "1.1706838559551742\n",
      "0.9143776715217585\n",
      "0.4401277614467497\n",
      "0.6957785683855806\n",
      "0.8664582120320856\n",
      "0.9553031179425214\n",
      "0.8575663101545957\n",
      "0.5525798068595719\n",
      "0.45759426779883794\n",
      "0.9781695725765861\n",
      "0.5432836420420044\n",
      "0.5700790548517841\n",
      "0.956340861215483\n",
      "0.7821551890764873\n",
      "0.4856667347791189\n",
      "0.6093849910670868\n",
      "0.5886390531198786\n",
      "0.9784425857722789\n",
      "0.4217593169284426\n",
      "0.9712439483559653\n",
      "1.0302320510395127\n",
      "1.1152561495548663\n",
      "0.49636044588480094\n",
      "0.5414149337918283\n",
      "0.8493249057335968\n",
      "1.1570348152323762\n",
      "0.45032831814077523\n",
      "0.6915619305472238\n",
      "0.9108256317030744\n",
      "1.2765451538273647\n",
      "0.5773979162059426\n",
      "0.7328735923707926\n",
      "1.0839425180309443\n",
      "1.2370969150236892\n",
      "0.7977701752579257\n",
      "0.6961313611423474\n",
      "0.927039643489178\n",
      "1.0554641368373234\n",
      "0.5265666414576541\n",
      "0.9183075006696084\n",
      "1.0508982425981184\n",
      "0.7745250058566696\n",
      "0.4405408784107495\n",
      "0.9387785427143821\n",
      "0.9994551512346194\n",
      "0.9646860979578037\n",
      "0.6175744743998347\n",
      "0.9460450366471425\n",
      "1.4447279801693498\n",
      "0.714200402593776\n",
      "0.8865389726205656\n",
      "1.1013364010867681\n",
      "1.26811260511826\n",
      "0.654147681831267\n",
      "0.5444184494735628\n",
      "0.8777249689410943\n",
      "1.4097626220074009\n",
      "0.7235361069332464\n",
      "0.8047112937631828\n",
      "1.1294268873796156\n",
      "1.2433643795952867\n",
      "0.7393571400318676\n",
      "0.5449265494845782\n",
      "0.8602921796417402\n",
      "1.3432015578763812\n",
      "0.5533868023142935\n",
      "0.5124413734497688\n",
      "0.728600364302053\n",
      "1.1876350959427733\n",
      "0.6489842780371812\n",
      "0.93388415024135\n",
      "0.7816439972503453\n",
      "1.050389124152837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6227090374683844\n",
      "1.0745879327673742\n",
      "0.9508576395474477\n",
      "0.8347947744536612\n",
      "0.6921576845701434\n",
      "0.5572106255105178\n",
      "1.2362492966986285\n",
      "0.8452314494563983\n",
      "0.45142180495460993\n",
      "0.7433593047613332\n",
      "1.2018331617620635\n",
      "0.30746038490936933\n",
      "Epoch: 4 completed in: 938.1009383201599 s. Training loss: 0.7821393829652387 . Val loss: 0.8348197797324965 . Test loss: 0.8062777121613762\n",
      "------Evaluation------\n",
      "0.4599174734904272\n",
      "0.7859415149080804\n",
      "0.650503527098274\n",
      "0.3495848123111242\n",
      "0.4519852676806122\n",
      "0.6035517514715555\n",
      "0.5426378077773252\n",
      "0.5442809285348859\n",
      "0.7488874903243142\n",
      "0.8342209068833026\n",
      "0.46430816521367774\n",
      "0.43476738057167547\n",
      "0.6236019788529739\n",
      "0.9309324881288786\n",
      "0.38712196306009355\n",
      "0.4532786698294536\n",
      "0.5906380217866449\n",
      "0.7577625248498515\n",
      "0.48298102986032465\n",
      "0.3298516704740085\n",
      "0.8953101714547587\n",
      "0.7664069762247694\n",
      "0.3847275450292612\n",
      "0.5566626027643865\n",
      "0.687077927016739\n",
      "0.7820249260781339\n",
      "0.7066238149402784\n",
      "0.43228648355399185\n",
      "0.3683617631915819\n",
      "0.8058709878174547\n",
      "0.4823254520508467\n",
      "0.43461499838891093\n",
      "0.7020366396659137\n",
      "0.6993973805462915\n",
      "0.44880921005695307\n",
      "0.4366658780429295\n",
      "0.4560547136630446\n",
      "0.7857721143656328\n",
      "0.377995408961608\n",
      "0.7710998326303996\n",
      "0.8858919035822048\n",
      "0.9855008516014733\n",
      "0.4038797757403805\n",
      "0.4029937184404746\n",
      "0.6912666250834975\n",
      "0.981878154839771\n",
      "0.36276500286610247\n",
      "0.5662766460583604\n",
      "0.72316154172271\n",
      "1.0630404645212588\n",
      "0.468998225431987\n",
      "0.6549184492090482\n",
      "0.9040766551120378\n",
      "0.9985265171198181\n",
      "0.7173281698788989\n",
      "0.5887610388842474\n",
      "0.8075613920793757\n",
      "0.8642967148355997\n",
      "0.45859271680890457\n",
      "0.7338255821266437\n",
      "0.8178903765609408\n",
      "0.7057196321410685\n",
      "0.38660606085012433\n",
      "0.8344526820777731\n",
      "0.8472578206633883\n",
      "0.7996361165210957\n",
      "0.5389069679615305\n",
      "0.8003189254669167\n",
      "1.1565260413697962\n",
      "0.569230699218487\n",
      "0.7259310904404888\n",
      "0.8969020654763408\n",
      "1.1584610107926887\n",
      "0.5824345798680209\n",
      "0.45049088230245843\n",
      "0.7331184458011168\n",
      "1.2287986892240084\n",
      "0.6377754361260912\n",
      "0.7018319782160455\n",
      "0.9175356275193606\n",
      "1.0767810573146381\n",
      "0.631750220664101\n",
      "0.47744776774566144\n",
      "0.6952166567304078\n",
      "1.1652614369378103\n",
      "0.49976899985932693\n",
      "0.43412310509400126\n",
      "0.6079185635833625\n",
      "0.9392962356526635\n",
      "0.5477797443464433\n",
      "0.7433503848025902\n",
      "0.6615822509373482\n",
      "0.9355630984179236\n",
      "0.5212539938468503\n",
      "0.821148889526955\n",
      "0.7911642062824513\n",
      "0.7146697423841973\n",
      "0.5894097300045718\n",
      "0.48952787794915575\n",
      "1.0511772993870387\n",
      "0.7055176881381673\n",
      "0.37495372013475425\n",
      "0.5713939970537892\n",
      "0.9958358538648625\n",
      "0.2525653618748218\n",
      "Epoch: 5 completed in: 938.9453454017639 s. Training loss: 0.7206179952519649 . Val loss: 0.6972907009995387 . Test loss: 0.6709971748250076\n",
      "0.0015475618749999996\n",
      "------Evaluation------\n",
      "0.46593499780630243\n",
      "0.7101695586906613\n",
      "0.6480542095046753\n",
      "0.30889618229367294\n",
      "0.4232450167043784\n",
      "0.6387212395468534\n",
      "0.5493196946129489\n",
      "0.5204990384702262\n",
      "0.7245108549911512\n",
      "0.799066265871268\n",
      "0.4589361446945661\n",
      "0.4295263913418759\n",
      "0.6032395005551583\n",
      "0.8772215804904369\n",
      "0.3676275532227572\n",
      "0.44907660732951676\n",
      "0.5543780903048635\n",
      "0.7176171587833908\n",
      "0.4966610858067909\n",
      "0.3489824372932262\n",
      "0.8187171684264981\n",
      "0.7242811246629169\n",
      "0.3741613146918393\n",
      "0.5256897536250764\n",
      "0.6480226130642373\n",
      "0.7782534728504041\n",
      "0.6485330607411305\n",
      "0.4115129640206978\n",
      "0.35695952344074555\n",
      "0.7908904770872568\n",
      "0.43927245769223144\n",
      "0.44851334996942765\n",
      "0.6947014518887492\n",
      "0.68392417357718\n",
      "0.4110245009561837\n",
      "0.44399049548361286\n",
      "0.4840261423358846\n",
      "0.6934642169914684\n",
      "0.3508590755843276\n",
      "0.7500963618114661\n",
      "0.8454266216143985\n",
      "0.9686424244032215\n",
      "0.36939426624782395\n",
      "0.40952948392711813\n",
      "0.6562394386001583\n",
      "0.8908768470546317\n",
      "0.3568384085997797\n",
      "0.5427380630546155\n",
      "0.7195089712734586\n",
      "1.021097203748786\n",
      "0.4618702556516091\n",
      "0.6507963430373853\n",
      "0.9004984233564236\n",
      "0.967818911220323\n",
      "0.663889993180098\n",
      "0.568419635947143\n",
      "0.7339513750570671\n",
      "0.8984395003137751\n",
      "0.4747368135641484\n",
      "0.7426725842402676\n",
      "0.8267892637701739\n",
      "0.6674638494688909\n",
      "0.34470862795675766\n",
      "0.8378246741444969\n",
      "0.8097083619449119\n",
      "0.81858322662609\n",
      "0.5331136881628021\n",
      "0.8290529677432934\n",
      "1.1347648171391742\n",
      "0.5390687645016118\n",
      "0.6800124439768347\n",
      "0.8793829869176573\n",
      "1.0847517043724804\n",
      "0.5436058838736382\n",
      "0.4442040431489378\n",
      "0.736324916408061\n",
      "1.2162347990286155\n",
      "0.5936574060750148\n",
      "0.6160527503917446\n",
      "0.8559984971152191\n",
      "1.0149745325868353\n",
      "0.5805842168291631\n",
      "0.4408847264643183\n",
      "0.6467283716750063\n",
      "1.0786927019884767\n",
      "0.4635540797970729\n",
      "0.42224827528140146\n",
      "0.5807649053238847\n",
      "0.9283995719358992\n",
      "0.5135805593528054\n",
      "0.6885422769058337\n",
      "0.6529987566769968\n",
      "0.8933461694602245\n",
      "0.4751061834747881\n",
      "0.8096243165233254\n",
      "0.7393047430025338\n",
      "0.7180223719179867\n",
      "0.5748952030308963\n",
      "0.43907469528092974\n",
      "1.0641993154129505\n",
      "0.6800634251245603\n",
      "0.3618221069640141\n",
      "0.5735386112555575\n",
      "0.8994167441403028\n",
      "0.23262068504920594\n",
      "Epoch: 6 completed in: 944.9172694683075 s. Training loss: 0.6447550654020721 . Val loss: 0.6962133369715938 . Test loss: 0.6464405151383777\n",
      "------Evaluation------\n",
      "0.4220380276240669\n",
      "0.6055046299297996\n",
      "0.5345697158769596\n",
      "0.2994039162597499\n",
      "0.4021940148742975\n",
      "0.523590561125296\n",
      "0.4766468051382774\n",
      "0.4690393521912872\n",
      "0.625056902624633\n",
      "0.6924635479120599\n",
      "0.4288933099613319\n",
      "0.3899077209122983\n",
      "0.5257889287563318\n",
      "0.768761155093339\n",
      "0.33978685697747685\n",
      "0.41450556640211517\n",
      "0.5098392002224141\n",
      "0.6235420265098086\n",
      "0.43418461930342966\n",
      "0.3116808393774744\n",
      "0.6989381267214871\n",
      "0.628469247034055\n",
      "0.31939342922216485\n",
      "0.4736508769253732\n",
      "0.5829348271580199\n",
      "0.6841762862701342\n",
      "0.587980791544221\n",
      "0.37756750098683256\n",
      "0.33934388929854314\n",
      "0.6966787606667727\n",
      "0.38312790227916343\n",
      "0.4064094938151353\n",
      "0.6158096758806672\n",
      "0.5872086418296582\n",
      "0.3833967708015281\n",
      "0.38025930861481416\n",
      "0.4275489185071184\n",
      "0.6056949155590855\n",
      "0.3382045048983773\n",
      "0.6474588487406809\n",
      "0.738017052591662\n",
      "0.877073254733935\n",
      "0.34200465598610297\n",
      "0.349129071404434\n",
      "0.5799452975448449\n",
      "0.7708894849444178\n",
      "0.3109833985809104\n",
      "0.4802627178268881\n",
      "0.5864507420332474\n",
      "0.8798551003068877\n",
      "0.38840659907673936\n",
      "0.5579898326724083\n",
      "0.7619676762651248\n",
      "0.8038249585333955\n",
      "0.5573844201583942\n",
      "0.5041809055375408\n",
      "0.6391124272637162\n",
      "0.8034472770659954\n",
      "0.4049818526346701\n",
      "0.6666301667383067\n",
      "0.7028096603150101\n",
      "0.6218496349327179\n",
      "0.31429873714490053\n",
      "0.6730871618698059\n",
      "0.7203102708899473\n",
      "0.7079049363639336\n",
      "0.47487272268407466\n",
      "0.6852798501346249\n",
      "0.9610557217399234\n",
      "0.49450473297673436\n",
      "0.6019274087374591\n",
      "0.7642963062930078\n",
      "0.9820912669775811\n",
      "0.4871959853177297\n",
      "0.40760173138609157\n",
      "0.6164518198148252\n",
      "1.05785074912685\n",
      "0.5364302492658526\n",
      "0.5576577633766252\n",
      "0.7071906066827407\n",
      "0.9234436615397766\n",
      "0.5136399501122701\n",
      "0.4234341929237918\n",
      "0.5660600944345561\n",
      "0.9598732295870636\n",
      "0.4268893820303341\n",
      "0.4234393160052573\n",
      "0.5423054443450436\n",
      "0.7616819968219176\n",
      "0.4634717888959836\n",
      "0.6352671072063076\n",
      "0.5776533515266026\n",
      "0.760853834241608\n",
      "0.44229408767388795\n",
      "0.642134993548556\n",
      "0.6464736938344239\n",
      "0.6167466946842576\n",
      "0.5049572636555494\n",
      "0.4065159493457368\n",
      "0.8835391057331954\n",
      "0.5591265639239947\n",
      "0.33461215127617516\n",
      "0.5121081670808763\n",
      "0.7702389546219279\n",
      "0.3754233449630111\n",
      "Epoch: 7 completed in: 947.51935505867 s. Training loss: 0.5908863158332934 . Val loss: 0.6149883083993739 . Test loss: 0.5686765613501756\n",
      "------Evaluation------\n",
      "0.42302157735712637\n",
      "0.6076147176675022\n",
      "0.5220634853803772\n",
      "0.3022468485439274\n",
      "0.39415229539845725\n",
      "0.5427346749075828\n",
      "0.4599638942292112\n",
      "0.4988024631849425\n",
      "0.682092740222829\n",
      "0.723138316296412\n",
      "0.4338019236365322\n",
      "0.3818767101729446\n",
      "0.5524951726662088\n",
      "0.7912701894007016\n",
      "0.3345154489619699\n",
      "0.44338084111552106\n",
      "0.5581325208373485\n",
      "0.6294169335385309\n",
      "0.4352711300232686\n",
      "0.6639159513516022\n",
      "0.8304169332181444\n",
      "0.640511378904385\n",
      "0.3330015975739894\n",
      "0.6099204939482887\n",
      "0.5674058308362532\n",
      "0.6765291832834708\n",
      "0.6144354939484332\n",
      "0.3824538716316692\n",
      "0.3469948327459993\n",
      "0.6469056700710699\n",
      "0.4131230022852096\n",
      "0.38871117888387074\n",
      "0.6264388925765138\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "for epoch in range(1, num_epoch + 1): \n",
    "    start = time.time()\n",
    "    train_loss = train_hybrid_LWR(model, train_loader, optimizer, criterion, tsteps, pred_len)[-1]\n",
    "    end = time.time()\n",
    "    train_losses.append(train_loss) \n",
    "    print(\"------Evaluation------\") \n",
    "#     print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "    _, _, val_loss = eval_hybrid_LWR(model, val_loader, criterion, tsteps, pred_len) \n",
    "#     print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "    val_losses.append(val_loss) \n",
    "    if val_loss <= best_loss: \n",
    "        best_loss = val_loss \n",
    "        best_model = model\n",
    "        torch.save({'epoch': epoch, \"optimizer\": optimizer.state_dict(), \"model\": best_model.state_dict()}, \"hybridAutoODE_time11_\" + name + str(epoch) + \".pt\") \n",
    "    best_loss = best_loss \n",
    "    \n",
    "    preds, trues, test_loss = test_hybrid_LWR(model, test_loader, criterion, test_sensors.long(), tsteps_test, 12) \n",
    "    # scaled_error = np.mean([np.sqrt(metric(preds, trues, criterion, 2)), np.sqrt(metric(preds, trues, criterion, 5)), np.sqrt(metric(preds, trues, criterion, -1))]) \n",
    "    # end = time.time()\n",
    "    print(\"Epoch:\", epoch, \"completed in:\", (end - start), \"s. Training loss:\", train_loss, \". Val loss:\", val_loss, \". Test loss:\", test_loss)  \n",
    "    if (len(train_losses) > 30 and np.mean(val_losses[-5:]) >= np.mean(val_losses[-10:-5])):\n",
    "        break\n",
    "    scheduler.step() \n",
    "    if epoch % 5 == 0: \n",
    "        print(optimizer.param_groups[0]['lr']) \n",
    "torch.save({'epoch': epoch, \"optimizer\": optimizer.state_dict(), \"model\": best_model.state_dict()}, \"hybridAutoODE_time11_\" + name + str(i) + \".pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ff4f84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Evaluation------\n",
      "1.4506389420813106\n",
      "1.7071135049916244\n",
      "0.6933416307989573\n",
      "0.8246733490962183\n",
      "1.3395996531737142\n",
      "1.7816231463280217\n",
      "0.9182381317344014\n",
      "2.458795698914859\n",
      "1.771200691541793\n",
      "1.400144560027514\n",
      "0.8102746065924421\n",
      "1.7948953099636826\n",
      "1.5297677658777797\n",
      "1.5675300033922726\n",
      "0.6278097345553219\n",
      "0.9663948591514857\n",
      "2.079567329158805\n",
      "1.4605451906407363\n",
      "0.6858121428314232\n",
      "1.003717295746328\n",
      "2.589612445282421\n",
      "Epoch: 1 completed in: 850.8684267997742 s. Training loss: 1.5640309134081027 . Val loss: 1.1500599546191668 . Test loss: 1.4029188567562434\n",
      "------Evaluation------\n",
      "1.2702373926261368\n",
      "1.4974597263912819\n",
      "0.6311486232996025\n",
      "0.7402052566002222\n",
      "1.1575841026349556\n",
      "1.5499875878271125\n",
      "0.8198222051875195\n",
      "2.1756406651416538\n",
      "1.5722713648652522\n",
      "1.2638407219549463\n",
      "0.7017587798713193\n",
      "1.6154594318814175\n",
      "1.3301270758419015\n",
      "1.4314639306365782\n",
      "0.5674969946527405\n",
      "0.8567608650708158\n",
      "1.8206632166604826\n",
      "1.317339610366851\n",
      "0.5864507937025009\n",
      "0.8448382473207463\n",
      "2.3166753452887385\n",
      "Epoch: 2 completed in: 870.1185376644135 s. Training loss: 1.0434119825152959 . Val loss: 0.9674700967937124 . Test loss: 1.2412967589439414\n",
      "------Evaluation------\n",
      "1.2400238515448365\n",
      "1.5057437530714384\n",
      "0.5673214008830118\n",
      "0.7426785946046727\n",
      "1.154445675819029\n",
      "1.5275589938699115\n",
      "0.7637989685426417\n",
      "2.082561382371805\n",
      "1.3977810239690733\n",
      "1.2724484881644436\n",
      "0.6948832875937618\n",
      "1.5104979244546013\n",
      "1.2349599217706833\n",
      "1.4100015267630313\n",
      "0.529306663012442\n",
      "0.7380969794769838\n",
      "1.6904290112744116\n",
      "1.3187900483874864\n",
      "0.5605877918862413\n",
      "0.8377947649375015\n",
      "2.1582216917489503\n",
      "Epoch: 3 completed in: 870.3052520751953 s. Training loss: 0.902103057637859 . Val loss: 0.8706720720205868 . Test loss: 1.1875205592450933\n",
      "------Evaluation------\n",
      "1.2228903685100763\n",
      "1.4276367295130883\n",
      "0.5659387258406587\n",
      "0.7042216297815023\n",
      "1.1563797396658235\n",
      "1.4742048721982035\n",
      "0.7640903894055986\n",
      "2.037910238259765\n",
      "1.3821291289927768\n",
      "1.2245488723890152\n",
      "0.6716259893606051\n",
      "1.4601722227243121\n",
      "1.2078556761354502\n",
      "1.3505453099686064\n",
      "0.5308118709951632\n",
      "0.7701137838378148\n",
      "1.6912596118650458\n",
      "1.2979329749815856\n",
      "0.5588756171973858\n",
      "0.8004050407600295\n",
      "2.084221127000868\n",
      "Epoch: 4 completed in: 870.4947848320007 s. Training loss: 0.8188730413905202 . Val loss: 0.8025568089061107 . Test loss: 1.1611319009230179\n",
      "------Evaluation------\n",
      "1.2173221853663942\n",
      "1.4435955151604933\n",
      "0.533603532727505\n",
      "0.6911644514508276\n",
      "1.1163504263734925\n",
      "1.4005404770767564\n",
      "0.7230688492182569\n",
      "1.872462875595197\n",
      "1.355054977342011\n",
      "1.2040637888522054\n",
      "0.7019262525298087\n",
      "1.538188329120445\n",
      "1.1950027838415365\n",
      "1.416711253191663\n",
      "0.5309929150230613\n",
      "0.6716896069505041\n",
      "1.6961678988128703\n",
      "1.2473662684268836\n",
      "0.5273604403206745\n",
      "0.8111833697703549\n",
      "2.090608069225939\n",
      "Epoch: 5 completed in: 872.9214177131653 s. Training loss: 0.738145208002715 . Val loss: 0.7342573357194567 . Test loss: 1.142115441256042\n",
      "0.0015475618749999996\n",
      "------Evaluation------\n",
      "1.1704055602309482\n",
      "1.4090152372075548\n",
      "0.5957848239854046\n",
      "0.6747838277620078\n",
      "1.1044666669120942\n",
      "1.428829218765431\n",
      "0.7434202747121522\n",
      "1.9000724486635994\n",
      "1.3195738202813454\n",
      "1.2067295976134804\n",
      "0.6475558101878688\n",
      "1.5721632358385254\n",
      "1.2272935941620133\n",
      "1.3405906266092213\n",
      "0.5279279893123017\n",
      "0.7175211180577379\n",
      "1.6781931929771325\n",
      "1.2453931077109226\n",
      "0.5795585545616833\n",
      "0.8050077417041749\n",
      "2.132782326681259\n",
      "Epoch: 6 completed in: 873.0148963928223 s. Training loss: 0.671010786228982 . Val loss: 0.6897059243204776 . Test loss: 1.144146132092231\n",
      "------Evaluation------\n",
      "1.1857776608307502\n",
      "1.4317620468229733\n",
      "0.5744734446757591\n",
      "0.6458358715826686\n",
      "1.1040914418885652\n",
      "1.4344035455941582\n",
      "0.6839909004323689\n",
      "1.845311228704091\n",
      "1.3239661133851566\n",
      "1.208512141145089\n",
      "0.6645519262258356\n",
      "1.5343325305908198\n",
      "1.2365858654938235\n",
      "1.4838847546679552\n",
      "0.561353252108374\n",
      "0.6942674115536656\n",
      "1.7336584751812223\n",
      "1.326983241068757\n",
      "0.5428170954626989\n",
      "0.8292953284882225\n",
      "2.1498991726202816\n",
      "Epoch: 7 completed in: 874.0493369102478 s. Training loss: 0.6109743010643324 . Val loss: 0.6247625857621317 . Test loss: 1.1521787356439634\n",
      "------Evaluation------\n",
      "1.1884275013233514\n",
      "1.4329948666363568\n",
      "0.5480634512856435\n",
      "0.6655308120011844\n",
      "1.10487639449291\n",
      "1.4283010481708462\n",
      "0.6993368469079803\n",
      "1.781168460521808\n",
      "1.3355827898006691\n",
      "1.166262403041701\n",
      "0.7350509653373776\n",
      "1.5484641470964602\n",
      "1.2693350161208548\n",
      "1.3904509818258728\n",
      "0.5412118172256808\n",
      "0.6726730134842441\n",
      "1.7742109064850637\n",
      "1.336031977189717\n",
      "0.5163893129969739\n",
      "0.8029289394383955\n",
      "2.1331654873345074\n",
      "Epoch: 8 completed in: 875.9251770973206 s. Training loss: 0.554382885185385 . Val loss: 0.5606505994773409 . Test loss: 1.146212244700838\n",
      "------Evaluation------\n",
      "1.2686387175060747\n",
      "1.4238338510248447\n",
      "0.5354671310364809\n",
      "0.6755983346853826\n",
      "1.1593584422305487\n",
      "1.4619136846613519\n",
      "0.7028017949962359\n",
      "1.751219499202012\n",
      "1.5416092518005218\n",
      "1.2107274894345164\n",
      "0.69116008258832\n",
      "1.5399049110067646\n",
      "1.3188434031180594\n",
      "1.4468443418303751\n",
      "0.5663018011209148\n",
      "0.6929121913733246\n",
      "1.952344357611489\n",
      "1.4139383800494865\n",
      "0.5731523932454804\n",
      "0.8586669164699923\n",
      "2.232701372491527\n",
      "Epoch: 9 completed in: 874.5274777412415 s. Training loss: 0.5037050777061991 . Val loss: 0.5290768250017811 . Test loss: 1.1913303974992238\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "for epoch in range(1, num_epoch + 1): \n",
    "    start = time.time()\n",
    "    train_loss = train_hybrid_LWR(model, train_loader, optimizer, criterion, tsteps, pred_len)[-1]\n",
    "    end = time.time()\n",
    "    train_losses.append(train_loss) \n",
    "    print(\"------Evaluation------\") \n",
    "#     print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "    _, _, val_loss = eval_hybrid_LWR(model, val_loader, criterion, tsteps, pred_len) \n",
    "#     print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "    val_losses.append(val_loss) \n",
    "    if val_loss <= best_loss: \n",
    "        best_loss = val_loss \n",
    "        best_model = model\n",
    "        torch.save({'epoch': epoch, \"optimizer\": optimizer.state_dict(), \"model\": best_model.state_dict()}, \"hybridAutoODE_time1_\" + name + str(epoch) + \".pt\") \n",
    "    best_loss = best_loss \n",
    "    \n",
    "    preds, trues, test_loss = test_hybrid_LWR(model, test_loader, criterion, test_sensors.long(), tsteps_test, 12) \n",
    "    # scaled_error = np.mean([np.sqrt(metric(preds, trues, criterion, 2)), np.sqrt(metric(preds, trues, criterion, 5)), np.sqrt(metric(preds, trues, criterion, -1))]) \n",
    "    # end = time.time()\n",
    "    print(\"Epoch:\", epoch, \"completed in:\", (end - start), \"s. Training loss:\", train_loss, \". Val loss:\", val_loss, \". Test loss:\", test_loss)  \n",
    "    if (len(train_losses) > 30 and np.mean(val_losses[-5:]) >= np.mean(val_losses[-10:-5])):\n",
    "        break\n",
    "    scheduler.step() \n",
    "    if epoch % 5 == 0: \n",
    "        print(optimizer.param_groups[0]['lr']) \n",
    "torch.save({'epoch': epoch, \"optimizer\": optimizer.state_dict(), \"model\": best_model.state_dict()}, \"hybridAutoODE_time_\" + name + str(i) + \".pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9065fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2395193728681326\n",
      "1.389914626153061\n",
      "0.5160113737259078\n",
      "0.7034931884899598\n",
      "1.1489836771875195\n",
      "1.4246052804050064\n",
      "0.6984217244665941\n",
      "1.873078337033836\n",
      "1.422865570448069\n",
      "1.1759706733595656\n",
      "0.7167739627661114\n",
      "1.5831143187084764\n",
      "1.2471317159854012\n",
      "1.3728029295680368\n",
      "0.5465852824874864\n",
      "0.7480991082339441\n",
      "1.635199999135902\n",
      "1.2410370985155266\n",
      "0.5840985800296167\n",
      "0.8736852013743981\n",
      "2.089362657178429\n"
     ]
    }
   ],
   "source": [
    "preds, trues, test_loss = test_hybrid_LWR(model, test_loader, criterion, test_sensors.long(), tsteps_test, 12) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef0a30bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.153845460862904"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8361b6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\"preds\": preds, \"trues\": trues, \"model\": model.state_dict()}, \"result/hybridAutoODE_time_hybrid_LWR_joint6.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cb79c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
       "        72, 73, 74, 75, 76], dtype=torch.int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sensors = torch.tensor(np.arange(77))  \n",
    "test_sensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6a804e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\STEPHE~1\\AppData\\Local\\Temp/ipykernel_600140/2203983201.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtsteps_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msteps_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_hybrid_LWR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_sensors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtsteps_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\AutoODE_PEMS_traffic\\nn\\DNN\\datasets.py\u001b[0m in \u001b[0;36mtest_hybrid_LWR\u001b[1;34m(model, val_loader, criterion, test_sensors, steps)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_sensors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_sensors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\STEPHE~1\\AppData\\Local\\Temp/ipykernel_600140/2278939362.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, xi, x, initial, boundary, tsteps)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtsteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mpred1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLWR_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtsteps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# first 12\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLWR_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboundary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtsteps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# last 12\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpred1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\AutoODE_PEMS_traffic\\nn\\AutoODE\\LWR.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, xi, initial, boundary, tsteps)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mnk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[0mnu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m             \u001b[0mnq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;31m#new values for 3 variables stored in one tensor per time step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tsteps_test = steps_test.shape[0] \n",
    "criterion = nn.MSELoss() \n",
    "preds, trues, test_loss = test_hybrid_LWR(best_model, test_loader, criterion, test_sensors.long(), tsteps_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590121ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, np.sqrt(test_loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349b3e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\"preds\": preds, \"trues\": trues, \"model\": LWR_model}, \"AutoODE_result/time/time_AutoODE7.pt\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
