{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9997bf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "\n",
    "from datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "602f535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC(nn.Module): \n",
    "    def __init__(self, input_dim, input_len, hidden_dim, output_dim): \n",
    "        super(FC, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.input_len = input_len\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_len * input_dim, hidden_dim), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(hidden_dim, hidden_dim), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(hidden_dim, hidden_dim), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(hidden_dim, hidden_dim), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(hidden_dim, hidden_dim), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(hidden_dim, output_dim) \n",
    "        )\n",
    "    \n",
    "    def forward(self, x, output_length): \n",
    "#         x = x.permute(0, 2, 1).float().to(device)\n",
    "        x = x.reshape(x.shape[0], -1) \n",
    "\n",
    "        outputs = []\n",
    "        for i in range(output_length): \n",
    "            out = self.fc(x)\n",
    "            xx = torch.cat([x[:, self.input_dim:], out], dim = 1)  \n",
    "            outputs.append(out)\n",
    "#             print(out.shape)\n",
    "        outputs = torch.cat(outputs, dim = 1)\n",
    "        outputs = outputs.reshape((x.shape[0], 3, 12, -1))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23d8bdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, num_layers, dropout_rate = 0):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.linear = nn.Linear(input_dim, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers,\n",
    "                            dropout = dropout_rate, batch_first = True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear(x))\n",
    "        outputs, hidden = self.lstm(x)\n",
    "        return outputs, hidden\n",
    "    \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dim, num_layers, dropout_rate = 0):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.lstm = nn.LSTM(output_dim, hidden_dim, num_layers = num_layers, \n",
    "                            dropout = dropout_rate, batch_first = True)\n",
    "        \n",
    "        self.out = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        output, hidden = self.lstm(x, hidden)   \n",
    "        prediction = self.out(output.float())\n",
    "        return prediction, hidden   \n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, output_dim, hidden_dim, num_layers):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = Encoder(input_dim = input_dim, embedding_dim = embedding_dim, hidden_dim = hidden_dim, num_layers = num_layers).to(device)\n",
    "        self.decoder = Decoder(output_dim = output_dim, hidden_dim = hidden_dim, num_layers = num_layers).to(device)\n",
    "        self.output_dim = output_dim\n",
    "            \n",
    "    def forward(self, x, target_length):\n",
    "        batch_size = x.size(0) \n",
    "        input_length = x.size(2) \n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        x = x.reshape((batch_size, input_length, -1))\n",
    "        \n",
    "        output_dim = self.decoder.output_dim\n",
    "        encoder_output, encoder_hidden = self.encoder(x)\n",
    "\n",
    "        decoder_output = torch.zeros((batch_size, 1, output_dim), device = device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        \n",
    "        outputs = []\n",
    "        for t in range(target_length):  \n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_output, decoder_hidden)\n",
    "            outputs.append(decoder_output)\n",
    "        out = torch.cat(outputs, dim = 1) \n",
    "        out = out.reshape((batch_size, target_length, 3, -1))\n",
    "        out = out.permute((0, 2, 1, 3))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0739f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdiffeq import odeint\n",
    "\n",
    "class Latent_ODE(nn.Module):\n",
    "    def __init__(self, latent_dim=4, obs_dim=2, nhidden=20, rhidden = 20, aug = False, aug_dim = 2):\n",
    "        super(Latent_ODE, self).__init__()\n",
    "        self.aug = aug\n",
    "        self.aug_dim = aug_dim\n",
    "        if self.aug:\n",
    "            self.rec = RecognitionRNN(latent_dim, obs_dim+aug_dim, rhidden)\n",
    "        else:\n",
    "            self.rec = RecognitionRNN(latent_dim, obs_dim, rhidden)\n",
    "    \n",
    "        self.func = LatentODEfunc(latent_dim, nhidden)\n",
    "        self.dec = LatentODEDecoder(latent_dim, obs_dim, nhidden)\n",
    "        \n",
    "    def forward(self, x, output_length):\n",
    "        time_steps = torch.arange(0, output_length, 0.01).float().to(device)[:output_length] \n",
    "        batch_size = x.size(0) \n",
    "        input_length = x.size(2)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        x = x.reshape((batch_size, input_length, -1))\n",
    "        if self.aug:\n",
    "            aug_ten = torch.zeros(x.shape[0], x.shape[1], self.aug_dim).float().to(device)\n",
    "            x = torch.cat([x, aug_ten], dim = -1)\n",
    "#         print(xx.shape)\n",
    "#         print(torch.flip(xx, [1]).shape)\n",
    "        z0 = self.rec.forward(torch.flip(x, [1]))\n",
    "        pred_z = odeint(self.func, z0, time_steps).permute(1, 0, 2)\n",
    "        out = self.dec(pred_z)\n",
    "#         print(out.shape)\n",
    "        out = out.reshape((batch_size, output_length, 3, -1))\n",
    "        out = out.permute((0, 2, 1, 3))\n",
    "        return out  \n",
    "    \n",
    "class LatentODEfunc(nn.Module):\n",
    "    def __init__(self, latent_dim=4, nhidden=20):\n",
    "        super(LatentODEfunc, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, nhidden),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(nhidden, nhidden),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(nhidden, nhidden),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(nhidden, nhidden),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(nhidden, latent_dim)\n",
    "        )\n",
    "        self.nfe = 0\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        self.nfe += 1\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "    \n",
    "class RecognitionRNN(nn.Module):\n",
    "    def __init__(self, latent_dim=4, obs_dim=2, nhidden=25):\n",
    "        super(RecognitionRNN, self).__init__()\n",
    "        self.nhidden = nhidden\n",
    "        self.model = nn.GRU(obs_dim, nhidden, batch_first = True)\n",
    "        self.linear = nn.Linear(nhidden, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #h0 = torch.zeros(1, x.shape[0], self.nhidden).to(device)\n",
    "        output, hn = self.model(x)#, h0\n",
    "        return self.linear(hn[0])\n",
    "    \n",
    "class LatentODEDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim=4, obs_dim=2, nhidden=20):\n",
    "        super(LatentODEDecoder, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, nhidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nhidden, obs_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, z):\n",
    "        out = self.model(z)\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33354944",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_LWR_sparse2_3cmp(nn.Module):\n",
    "    def __init__(self, nx, dx, dt, kj, vf, xi, tskip, plm = \"none\", initial='random', boundary='zeros',\n",
    "                fix_vf=False, parstep=1):\n",
    "        self.nx = nx\n",
    "        #xi are the locations along distance where data is available\n",
    "        self.xi = xi\n",
    "        self.tskip = tskip \n",
    "            \n",
    "        super(Neural_LWR_sparse2_3cmp, self).__init__()\n",
    "        \n",
    "        self.cmps=[\"k\",\"q\",\"u\"]  #density, flow, velocity\n",
    "#         self.initial={}\n",
    "#         self.boundary={}\n",
    "        \n",
    "        self.initial = initial # shape: [batch, 3, # sensors]\n",
    "        self.boundary = boundary # shape: [batch, seq_len, 3]\n",
    "#         if initial == 'random':\n",
    "#             self.initial[\"u\"] = torch.nn.Parameter(torch.rand(nx))\n",
    "#             self.initial[\"k\"] = torch.nn.Parameter(torch.rand(nx))\n",
    "#             self.initial[\"q\"] = self.initial[\"k\"] * self.initial[\"v\"]\n",
    "#         elif initial == 'zeros':\n",
    "#             for c in self.cmps: \n",
    "#                 self.initial[c] = torch.zeros(nx, requires_grad=True).double()\n",
    "#         else:\n",
    "#             assert list(initial.keys()) == self.cmps, \"initial conditions should be dictionary with k,q and u\"\n",
    "#             for c in self.cmps:\n",
    "#                 self.initial[c] = torch.tensor(initial[c])\n",
    "            \n",
    "#         # influx at upstream border - needs to be known or assumed\n",
    "#         if boundary == 'zeros':\n",
    "#             for c in self.cmps:\n",
    "#                 self.boundary[c] = torch.zeros(nt, requires_grad=True).double()\n",
    "#         else:\n",
    "#             assert list(boundary.keys()) == self.cmps, \"boundary conditions should be dictionary with u,k and q\"\n",
    "#             for c in self.cmps:\n",
    "#                 self.boundary[c] = torch.tensor(boundary[c])\n",
    "            \n",
    "        #factor by which parameter resolution is reduced with respect to nx\n",
    "        self.parstep=parstep\n",
    "        \n",
    "        # use piecewise linear function for kj\n",
    "        if plm == \"none\": \n",
    "            self.kappa = torch.nn.Parameter(torch.tensor(kj[::self.parstep]), requires_grad=True)\n",
    "        elif plm == \"initial\": \n",
    "            self.plm = PiecewiseLinearModel(n_breaks = 2, num_regions = self.nx) \n",
    "        else: \n",
    "            self.plm = plm\n",
    "        \n",
    "        #characteristic velocity vf\n",
    "        if not fix_vf:\n",
    "            self.vf=torch.nn.Parameter(torch.tensor(vf[::self.parstep]), requires_grad=True)\n",
    "#             self.plm = PiecewiseLinearModel(n_breaks = 2, num_regions = self.nx, x = vf)\n",
    "        else:\n",
    "            self.vf=torch.tensor(vf[::self.parstep])\n",
    "        \n",
    "        self.dx = torch.tensor(dx)\n",
    "        self.dt = torch.tensor(dt)\n",
    "        \n",
    "    def forward(self, tsteps):\n",
    "        nt=len(tsteps) \n",
    "\n",
    "#         t = torch.linspace(0, 1, nt).repeat(self.nx, 1)\n",
    "#         kappa = self.plm(t)\n",
    "#         self.k=[self.initial[\"k\"]]   # density\n",
    "#         self.u=[self.initial[\"u\"]]   # velocity\n",
    "#         self.q=[self.initial[\"q\"]]   # flow \n",
    "        batch_size = self.initial.shape[0]\n",
    "        self.k = [self.initial[:, 0]]\n",
    "        self.q = [self.initial[:, 1]]\n",
    "        self.u = [self.initial[:, 2]]\n",
    "        \n",
    "        #initial values at output points\n",
    "        self.ki=[self.initial[:, 0][self.xi]]\n",
    "        self.ui=[self.initial[:, 1][self.xi]]\n",
    "        self.qi=[self.initial[:, 2][self.xi]]\n",
    "        \n",
    "        for n in range(1,nt):\n",
    "            #This corresponds to the upwind scheme according to Gaddam et al. (2015).\n",
    "            nk=torch.zeros((batch_size, nx), requires_grad=True).double()\n",
    "            nu=torch.zeros((batch_size, nx), requires_grad=True).double()\n",
    "            nq=torch.zeros((batch_size, nx), requires_grad=True).double()\n",
    "            \n",
    "            #new values for 3 variables stored in one tensor per time step\n",
    "            nk[:, 0] = self.boundary[:, n, 0]\n",
    "            nq[:, 0] = self.boundary[:, n, 1]\n",
    "            nu[:, 0] = self.boundary[:, n, 2]\n",
    "                                  \n",
    "            #full-resolution tensor hkappa and hv1, from down-sampled versions\n",
    "            idx=torch.arange(self.nx) / self.parstep\n",
    "            hkappa=self.kappa[idx.long()] #.repeat(batch_size, 1)\n",
    "#             hkappa = kappa[:, n - 1]\n",
    "#             print(hkappa.shape)\n",
    "#             hvf=self.vf[idx.long()] #.repeat(batch_size, 1)\n",
    "#             hvf = vf[:, n - 1]\n",
    "            \n",
    "#             print(self.q[n-1][0], nq[0]) \n",
    "            ### \n",
    "            # Method of lines + RK4 method \n",
    "            # dt * f(t[n], y[n]) \n",
    "#             k1_k = - (self.q[n-1][2:] - self.q[n-1][:-2]) / (2 * self.dx) # central difference \n",
    "            k1_k = - (self.q[n-1][:, 1:] - self.q[n-1][:, :-1]) / self.dx # finite difference \n",
    "\n",
    "            nk_1 = torch.cat((nk[:, 0].unsqueeze(1), self.k[n-1][:, 1:] + k1_k / 2 * self.dt), dim = 1) \n",
    "            nu_1 = hvf[1:] * (1 - nk_1[:, 1:] / hkappa[1:]) \n",
    "            nq_1 = nk_1[:, 1:] * nu_1\n",
    "            nq_1 = torch.cat((nq[:, 0].unsqueeze(1), nq_1)) \n",
    "\n",
    "            # dt * f(t[n] + dt/2, y[n] + k1/2)  \n",
    "            k2_k = - (nq_1[:, 1:] - nq_1[:, :-1]) / self.dx\n",
    "            nk_2 = torch.cat((nk[:, 0].unsqueeze(1), self.k[n-1][:, 1:] + k2_k / 2 * self.dt), dim = 1) \n",
    "            nu_2 = hvf[1:] * (1 - nk_2[:, 1:] / hkappa[1:])\n",
    "            nq_2 = nk_2[:, 1:] * nu_2 \n",
    "            nq_2 = torch.cat((nq[:, 0].unsqueeze(1), nq_2)) \n",
    "            \n",
    "            k3_k = - (nq_2[:, 1:] - nq_2[:, :-1]) / self.dx \n",
    "            nk_3 = torch.cat((nk[:, 0].unsqueeze(1), self.k[n-1][:, 1:] + k3_k * self.dt)) \n",
    "            nu_3 = hvf[1:] * (1 - nk_3[:, 1:] / hkappa[1:])\n",
    "            nq_3 = nk_3[:, 1:] * nu_3 \n",
    "            nq_3 = torch.cat((nq[:, 0].unsqueeze(1), nq_3)) \n",
    "\n",
    "            # dt * f(t[n] + dt, y[n] + k3) \n",
    "            k4_k = - (nq_3[:, 1:] - nq_3[:, :-1]) / self.dx\n",
    "            nk[1:] += self.k[n-1][:, 1:] + 1/6 * (k1_k + 2 * k2_k + 2 * k3_k + k4_k) * self.dt \n",
    "            nu[1:] += hvf[1:] * (1 - nk[:, 1:] / hkappa[:, 1:]) \n",
    "            nq[1:] += nk[:, 1:] * nu[:, 1:] \n",
    "\n",
    "            self.k.append(nk)\n",
    "            self.u.append(nu)\n",
    "            self.q.append(nq)\n",
    "#             print(nk)\n",
    "#             print(nu)\n",
    "#             print(nq)\n",
    "#             print(nk.shape)\n",
    "            #only output every tskip timesteps\n",
    "            if (n % self.tskip) == 0:\n",
    "                self.ki.append(nk[self.xi])\n",
    "                self.ui.append(nu[self.xi])\n",
    "                self.qi.append(nq[self.xi])\n",
    "           \n",
    "        return torch.stack([torch.stack(self.ki),torch.stack(self.qi),torch.stack(self.ui)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a3ddf2",
   "metadata": {},
   "source": [
    "### Data for time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae599ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = torch.load(\"training_time.pt\").float()\n",
    "test_data = torch.load(\"test_time.pt\").float()\n",
    "\n",
    "training_set = Dataset(training_data)\n",
    "test_set = Dataset(test_data)\n",
    "training_set, val_set = data.random_split(training_set, [int(len(training_set) * 0.875), int(len(training_set) * 0.125)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5f06d8",
   "metadata": {},
   "source": [
    "#### Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bcc633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46c487f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([44400, 3, 24, 80]), torch.Size([8856, 3, 24, 80]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "833dd929",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = torch.cat((training_data, test_data), dim = 0)\n",
    "data_np = np.array(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83bd91d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.tensor([data_np[:, 0, :, :].mean(), data_np[:, 1, :, :].mean(), data_np[:, 2, :, :].mean()])\n",
    "std = torch.tensor([data_np[:, 0, :, :].std(), data_np[:, 1, :, :].std(), data_np[:, 2, :, :].std()])\n",
    "data_norm = torch.zeros(data_np.shape, dtype = torch.float) \n",
    "data_norm[:, 0, :, :] = (data1[:, 0, :, :] - mean[0]) / std[0]\n",
    "data_norm[:, 1, :, :] = (data1[:, 1, :, :] - mean[1]) / std[1]\n",
    "data_norm[:, 2, :, :] = (data1[:, 2, :, :] - mean[2]) / std[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95b0bd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([53256, 3, 24, 80])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d4e7a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9438, -0.9939, -0.9917,  ..., -0.8835, -0.8501, -0.8427],\n",
       "        [-0.9232, -0.9814, -0.9703,  ..., -0.9263, -0.8627, -0.8454],\n",
       "        [-0.9619, -0.9880, -0.9853,  ..., -0.9368, -0.8046, -0.8556],\n",
       "        ...,\n",
       "        [-0.9932, -1.0236, -1.0096,  ..., -0.9724, -0.9206, -0.9441],\n",
       "        [-0.9891, -1.0241, -1.0206,  ..., -0.9704, -0.9108, -0.9473],\n",
       "        [-1.0120, -1.0367, -1.0234,  ..., -0.9601, -0.9142, -0.9507]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_norm[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7256c00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0346,  0.8775, 28.5914]), tensor([0.0333, 0.6063, 4.1726]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e92217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = Dataset(data_norm[:44400])\n",
    "test_set = Dataset(data_norm[44400:])\n",
    "training_set, val_set = data.random_split(training_set, [int(len(training_set) * 0.875), int(len(training_set) * 0.125)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2b0b282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38850\n",
      "5550\n",
      "8856\n"
     ]
    }
   ],
   "source": [
    "print(len(training_set))\n",
    "print(len(val_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05e1a085",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm = torch.zeros(test_data.shape, dtype = torch.float) \n",
    "test_data[:, 0, :, :] = (test_data[:, 0, :, :] - mean[0]) / std[0]\n",
    "test_data[:, 1, :, :] = (test_data[:, 1, :, :] - mean[1]) / std[1]\n",
    "test_data[:, 2, :, :] = (test_data[:, 2, :, :] - mean[2]) / std[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6aaa07",
   "metadata": {},
   "source": [
    "#### Dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d5c7c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = Dataset(test_data)\n",
    "test_loader = data.DataLoader(test_set, batch_size = 128, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ba7e25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(training_set, batch_size = 128, shuffle = True)\n",
    "val_loader = data.DataLoader(val_set, batch_size = 128, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d5c0f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion): \n",
    "    preds = []\n",
    "    trues = []\n",
    "    mse = [] \n",
    "#     count = 0\n",
    "    model.train()\n",
    "    for X, y in train_loader: \n",
    "#         if count % 5 == 0 : print(\"running batch\", count)\n",
    "#         count += 1\n",
    "        X, y = X.to(device), y.to(device)\n",
    "#         y = y.reshape((y.shape[0], -1))\n",
    "        pred = model(X, 12) \n",
    "        \n",
    "        loss = 0\n",
    "        loss = criterion(pred, y)\n",
    "        mse.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        trues.append(y.cpu().data.numpy())\n",
    "        preds.append(pred.cpu().data.numpy())\n",
    "    \n",
    "    preds = np.concatenate(preds, axis = 0)\n",
    "    trues = np.concatenate(trues, axis = 0)\n",
    "    \n",
    "    return preds, trues, np.mean(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ac999d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, val_loader, best_loss, criterion, name): \n",
    "    preds = []\n",
    "    trues = []\n",
    "    mse = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in val_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "#             y = y.reshape((y.shape[0], -1))\n",
    "            pred = model(X, 12)\n",
    "            \n",
    "            loss = 0\n",
    "            loss = criterion(pred, y)\n",
    "            mse.append(loss.item()) \n",
    "            \n",
    "            trues.append(y.cpu().data.numpy())\n",
    "            preds.append(pred.cpu().data.numpy())\n",
    "\n",
    "        preds = np.concatenate(preds, axis = 0)\n",
    "        trues = np.concatenate(trues, axis = 0)\n",
    "    \n",
    "    val_loss = np.mean(mse)\n",
    "    if val_loss <= best_loss: \n",
    "        best_loss = val_loss\n",
    "#             torch.save(model.state_dict(), 'model.pt')\n",
    "        torch.save(model, name + \".pth\")\n",
    "\n",
    "    return preds, trues, val_loss, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b89ed67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_true(model, val_loader, best_loss, criterion, name): \n",
    "    preds = []\n",
    "    trues = []\n",
    "    mse = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in val_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            pred = model(X, 12)\n",
    "            pred[:, 0, :, :] = (pred[:, 0, :, :] * std[0] + mean[0])\n",
    "            pred[:, 1, :, :] = (pred[:, 1, :, :] * std[1] + mean[1])\n",
    "            pred[:, 2, :, :] = (pred[:, 2, :, :] * std[2] + mean[2])\n",
    "                                \n",
    "            y[:, 0, :, :] = (y[:, 0, :, :] * std[0] + mean[0])\n",
    "            y[:, 1, :, :] = (y[:, 1, :, :] * std[1] + mean[1])\n",
    "            y[:, 2, :, :] = (y[:, 2, :, :] * std[2] + mean[2])\n",
    "            loss = 0\n",
    "            loss = criterion(pred, y)\n",
    "            mse.append(loss.item()) \n",
    "            \n",
    "            trues.append(y.cpu().data.numpy())\n",
    "            preds.append(pred.cpu().data.numpy())\n",
    "\n",
    "        preds = np.concatenate(preds, axis = 0)\n",
    "        trues = np.concatenate(trues, axis = 0)\n",
    "    \n",
    "    val_loss = np.mean(mse)\n",
    "\n",
    "\n",
    "    return preds, trues, val_loss, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2e8458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 3 * 80 \n",
    "input_len = 12\n",
    "hidden_dim = 512\n",
    "output_dim = 3 * 80\n",
    "\n",
    "device = \"cuda\"\n",
    "model = FC(input_dim, input_len, hidden_dim, output_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7c038ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model = Seq2Seq(input_dim = 3 * 80, embedding_dim = 256, output_dim = 3 * 80, hidden_dim = 512, num_layers = 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4ef6c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model = Latent_ODE(latent_dim = 256, obs_dim = 240, nhidden = 256, rhidden = 256, aug = False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a0b2a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2648816\n"
     ]
    }
   ],
   "source": [
    "name = \"FC\"\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 1, gamma=0.95)\n",
    "criterion = nn.MSELoss()\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "best_loss = 100   \n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd5af3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 completed in: 5.6383960247039795s. Training loss: 0.2366814226108162. Val loss: 0.17446700449694286\n",
      "Epoch: 2 completed in: 5.02957820892334s. Training loss: 0.16155681217481432. Val loss: 0.15604772232472897\n",
      "Epoch: 3 completed in: 5.027646541595459s. Training loss: 0.14381112121535758. Val loss: 0.1407723089849407\n",
      "Epoch: 4 completed in: 5.038166761398315s. Training loss: 0.13456907022842451. Val loss: 0.14030628228052097\n",
      "Epoch: 5 completed in: 4.998900651931763s. Training loss: 0.12890779273584485. Val loss: 0.12695559791543268\n",
      "0.007737809374999999\n",
      "Epoch: 6 completed in: 5.066921710968018s. Training loss: 0.12242634253772466. Val loss: 0.12545786476270718\n",
      "Epoch: 7 completed in: 5.007626056671143s. Training loss: 0.11824067270285205. Val loss: 0.11883871240372007\n",
      "Epoch: 8 completed in: 5.062180757522583s. Training loss: 0.11483679643194926. Val loss: 0.11911268921738322\n",
      "Epoch: 9 completed in: 5.072439432144165s. Training loss: 0.11084156454001602. Val loss: 0.11413075334646484\n",
      "Epoch: 10 completed in: 5.0104711055755615s. Training loss: 0.1098950809161914. Val loss: 0.11481059003960002\n",
      "0.005987369392383786\n",
      "Epoch: 11 completed in: 5.014112234115601s. Training loss: 0.10656110937462042. Val loss: 0.11120410178872672\n",
      "Epoch: 12 completed in: 5.065636396408081s. Training loss: 0.10324807835154627. Val loss: 0.10687582194805145\n",
      "Epoch: 13 completed in: 5.029446125030518s. Training loss: 0.10340955422112816. Val loss: 0.10627555881034244\n",
      "Epoch: 14 completed in: 5.039051055908203s. Training loss: 0.0991080843255316. Val loss: 0.1012729038907723\n",
      "Epoch: 15 completed in: 5.013563871383667s. Training loss: 0.09525396768003702. Val loss: 0.09792452136223967\n",
      "0.00463291230159753\n",
      "Epoch: 16 completed in: 5.0552077293396s. Training loss: 0.09320537649144076. Val loss: 0.09824514558369463\n",
      "Epoch: 17 completed in: 5.013075590133667s. Training loss: 0.09213766489962213. Val loss: 0.09555740265006368\n",
      "Epoch: 18 completed in: 5.035659074783325s. Training loss: 0.09005160721656132. Val loss: 0.09296017123216932\n",
      "Epoch: 19 completed in: 5.062736988067627s. Training loss: 0.08743645966445145. Val loss: 0.09199042787606065\n",
      "Epoch: 20 completed in: 5.034971237182617s. Training loss: 0.0854261108723126. Val loss: 0.08838499557565559\n",
      "0.0035848592240854188\n",
      "Epoch: 21 completed in: 5.014378547668457s. Training loss: 0.0830929915567762. Val loss: 0.08763317662206563\n",
      "Epoch: 22 completed in: 5.063485145568848s. Training loss: 0.08225705594706692. Val loss: 0.08546622317623008\n",
      "Epoch: 23 completed in: 5.013091325759888s. Training loss: 0.08263920921538222. Val loss: 0.084507805718617\n",
      "Epoch: 24 completed in: 4.991355657577515s. Training loss: 0.0803146172854069. Val loss: 0.08578383482315323\n",
      "Epoch: 25 completed in: 5.075566053390503s. Training loss: 0.07694695621581846. Val loss: 0.08120658079331572\n",
      "0.0027738957312183374\n",
      "Epoch: 26 completed in: 5.033406019210815s. Training loss: 0.07560165205627288. Val loss: 0.08006712980568409\n",
      "Epoch: 27 completed in: 4.999476909637451s. Training loss: 0.07397203329999588. Val loss: 0.07868395627222279\n",
      "Epoch: 28 completed in: 5.049587249755859s. Training loss: 0.07308328715398123. Val loss: 0.07932478028603575\n",
      "Epoch: 29 completed in: 5.0122294425964355s. Training loss: 0.07148579709035785. Val loss: 0.07705550581555475\n",
      "Epoch: 30 completed in: 5.020365476608276s. Training loss: 0.06965976430250234. Val loss: 0.07466878555715084\n",
      "0.0021463876394293723\n",
      "Epoch: 31 completed in: 5.065669059753418s. Training loss: 0.06783039078704621. Val loss: 0.0733402447605675\n",
      "Epoch: 32 completed in: 5.098691701889038s. Training loss: 0.0666621119690765. Val loss: 0.07394372019916773\n",
      "Epoch: 33 completed in: 5.023446083068848s. Training loss: 0.06569221042292683. Val loss: 0.07148568975654515\n",
      "Epoch: 34 completed in: 5.028270483016968s. Training loss: 0.06446424326369245. Val loss: 0.07096142787486315\n",
      "Epoch: 35 completed in: 5.054559230804443s. Training loss: 0.06412859015951031. Val loss: 0.06968420278280973\n",
      "0.0016608338398760713\n",
      "Epoch: 36 completed in: 5.030850887298584s. Training loss: 0.0627818693112778. Val loss: 0.06881685851311142\n",
      "Epoch: 37 completed in: 5.030100107192993s. Training loss: 0.06169502459172355. Val loss: 0.067712634971196\n",
      "Epoch: 38 completed in: 5.4282519817352295s. Training loss: 0.06019135252082426. Val loss: 0.06661845769055864\n",
      "Epoch: 39 completed in: 5.124392986297607s. Training loss: 0.0594812570703461. Val loss: 0.06686111471869728\n",
      "Epoch: 40 completed in: 5.59350848197937s. Training loss: 0.058929923456162214. Val loss: 0.06536616672846404\n",
      "0.0012851215656510308\n",
      "Epoch: 41 completed in: 5.061997652053833s. Training loss: 0.05807121897018269. Val loss: 0.06487514129416509\n",
      "Epoch: 42 completed in: 5.04246187210083s. Training loss: 0.057093104163772966. Val loss: 0.06378651486540382\n",
      "Epoch: 43 completed in: 5.048582315444946s. Training loss: 0.05599059897327894. Val loss: 0.06345850483260372\n",
      "Epoch: 44 completed in: 5.065052270889282s. Training loss: 0.05546751350017363. Val loss: 0.06314910067753358\n",
      "Epoch: 45 completed in: 5.017463684082031s. Training loss: 0.05623934817451395. Val loss: 0.06302659619938243\n",
      "0.000994402569870922\n",
      "Epoch: 46 completed in: 5.023736000061035s. Training loss: 0.05453363787627926. Val loss: 0.062032628381116825\n",
      "Epoch: 47 completed in: 5.0771403312683105s. Training loss: 0.05376749869288975. Val loss: 0.06237556522881443\n",
      "Epoch: 48 completed in: 5.04539680480957s. Training loss: 0.053416801310193385. Val loss: 0.06087116389112039\n",
      "Epoch: 49 completed in: 5.0052876472473145s. Training loss: 0.05247435739607011. Val loss: 0.06121946701949293\n",
      "Epoch: 50 completed in: 5.0820770263671875s. Training loss: 0.05199670158081541. Val loss: 0.060184761035171425\n",
      "0.0007694497527671312\n",
      "Epoch: 51 completed in: 5.0432562828063965s. Training loss: 0.051788100641907045. Val loss: 0.05965625816448168\n",
      "Epoch: 52 completed in: 5.013650178909302s. Training loss: 0.051202980544124. Val loss: 0.059294038198210976\n",
      "Epoch: 53 completed in: 5.075713396072388s. Training loss: 0.05028484569323298. Val loss: 0.05861456895416433\n",
      "Epoch: 54 completed in: 5.024065971374512s. Training loss: 0.04994072865596727. Val loss: 0.05845026519488205\n",
      "Epoch: 55 completed in: 4.997937440872192s. Training loss: 0.049947530729696155. Val loss: 0.06001514501192353\n",
      "0.000595385551055294\n",
      "Epoch: 56 completed in: 5.056776523590088s. Training loss: 0.049467417288963735. Val loss: 0.05787725924429568\n",
      "Epoch: 57 completed in: 5.0762739181518555s. Training loss: 0.04877273262919564. Val loss: 0.05750825188376687\n",
      "Epoch: 58 completed in: 5.029650688171387s. Training loss: 0.04838843233148126. Val loss: 0.05741044286299835\n",
      "Epoch: 59 completed in: 5.017592906951904s. Training loss: 0.04819289165990133. Val loss: 0.057194502939554775\n",
      "Epoch: 60 completed in: 5.076246976852417s. Training loss: 0.04776876014167149. Val loss: 0.056795584207231346\n",
      "0.00046069798986951934\n",
      "Epoch: 61 completed in: 5.01374077796936s. Training loss: 0.04740883169793769. Val loss: 0.05689243464307352\n",
      "Epoch: 62 completed in: 5.02654767036438s. Training loss: 0.04720636455979394. Val loss: 0.05655794649977575\n",
      "Epoch: 63 completed in: 5.063309907913208s. Training loss: 0.04700974186294173. Val loss: 0.05641274619847536\n",
      "Epoch: 64 completed in: 5.029517889022827s. Training loss: 0.04655268279786565. Val loss: 0.056069607761773194\n",
      "Epoch: 65 completed in: 5.026962041854858s. Training loss: 0.04622521712199638. Val loss: 0.05592942110855471\n",
      "0.00035647932250560207\n",
      "Epoch: 66 completed in: 5.096134424209595s. Training loss: 0.04602321945620995. Val loss: 0.05575271145525304\n",
      "Epoch: 67 completed in: 5.030651092529297s. Training loss: 0.045780314818808905. Val loss: 0.05554158917882226\n",
      "Epoch: 68 completed in: 5.050119876861572s. Training loss: 0.04555707747165702. Val loss: 0.05545383556322618\n",
      "Epoch: 69 completed in: 5.088468551635742s. Training loss: 0.04531348208700748. Val loss: 0.05519313331354748\n",
      "Epoch: 70 completed in: 5.016226530075073s. Training loss: 0.04510220051988175. Val loss: 0.05508380925113505\n",
      "0.00027583690436774953\n",
      "Epoch: 71 completed in: 5.045725345611572s. Training loss: 0.04492495960163835. Val loss: 0.054939361035146496\n",
      "Epoch: 72 completed in: 5.059216737747192s. Training loss: 0.044737014833739715. Val loss: 0.05477199618789283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73 completed in: 5.022761821746826s. Training loss: 0.04465727106128868. Val loss: 0.054776296273551205\n",
      "Epoch: 74 completed in: 5.045770645141602s. Training loss: 0.044398225966448844. Val loss: 0.05465252858332612\n",
      "Epoch: 75 completed in: 5.0257768630981445s. Training loss: 0.04428143179240195. Val loss: 0.054556530392305416\n",
      "0.00021343733845877503\n",
      "Epoch: 76 completed in: 5.058190822601318s. Training loss: 0.04408612457643214. Val loss: 0.0543900468302044\n",
      "Epoch: 77 completed in: 5.051549673080444s. Training loss: 0.043929239943329444. Val loss: 0.05425691833211617\n",
      "Epoch: 78 completed in: 5.024392366409302s. Training loss: 0.04380851435033899. Val loss: 0.05417237871072509\n",
      "Epoch: 79 completed in: 5.109514474868774s. Training loss: 0.04364922253022853. Val loss: 0.05414840553633191\n",
      "Epoch: 80 completed in: 5.05009388923645s. Training loss: 0.0434985380301154. Val loss: 0.054087264886633915\n",
      "0.00016515374385013573\n",
      "Epoch: 81 completed in: 5.043016195297241s. Training loss: 0.043423310461405074. Val loss: 0.05403386420485648\n",
      "Epoch: 82 completed in: 5.075186729431152s. Training loss: 0.04343570545805912. Val loss: 0.05396518068896099\n",
      "Epoch: 83 completed in: 5.023488998413086s. Training loss: 0.04319212529318113. Val loss: 0.05385605863888155\n",
      "Epoch: 84 completed in: 5.024361848831177s. Training loss: 0.04305063775054326. Val loss: 0.053833536634391006\n",
      "Epoch: 85 completed in: 5.079861402511597s. Training loss: 0.04295816700170307. Val loss: 0.05381595986810597\n",
      "0.00012779281874799285\n",
      "Epoch: 86 completed in: 5.023906707763672s. Training loss: 0.04287125771914266. Val loss: 0.05368280732496218\n",
      "Epoch: 87 completed in: 5.016541004180908s. Training loss: 0.042799280270149835. Val loss: 0.053641831163655625\n",
      "Epoch: 88 completed in: 5.0643839836120605s. Training loss: 0.0426880117064636. Val loss: 0.053632822734388436\n",
      "Epoch: 89 completed in: 5.018661975860596s. Training loss: 0.04262171158763139. Val loss: 0.05355184423652562\n",
      "Epoch: 90 completed in: 5.022968530654907s. Training loss: 0.042540770967638024. Val loss: 0.05347836229272864\n",
      "9.888364709658946e-05\n",
      "Epoch: 91 completed in: 5.069563150405884s. Training loss: 0.042483489997194784. Val loss: 0.05347060539167036\n",
      "Epoch: 92 completed in: 5.044596910476685s. Training loss: 0.042402321730103144. Val loss: 0.053389839658683\n",
      "Epoch: 93 completed in: 5.044325351715088s. Training loss: 0.042325339439374055. Val loss: 0.053351790136234326\n",
      "Epoch: 94 completed in: 5.017014265060425s. Training loss: 0.0422842475512114. Val loss: 0.05337422417307442\n",
      "Epoch: 95 completed in: 5.06795072555542s. Training loss: 0.042209696857944914. Val loss: 0.053338064388795334\n",
      "7.651428115381812e-05\n",
      "Epoch: 96 completed in: 5.70088267326355s. Training loss: 0.04214840779375089. Val loss: 0.05328405428339134\n",
      "Epoch: 97 completed in: 5.385167121887207s. Training loss: 0.042092237523511836. Val loss: 0.053347273814407264\n",
      "Epoch: 98 completed in: 5.8500940799713135s. Training loss: 0.04204493518428583. Val loss: 0.05327705971219323\n",
      "Epoch: 99 completed in: 5.146183729171753s. Training loss: 0.04200477138357727. Val loss: 0.05319136067886244\n",
      "Epoch: 100 completed in: 5.003848075866699s. Training loss: 0.04193683198996281. Val loss: 0.053206241012296894\n",
      "5.920529220333995e-05\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_epoch = 100 \n",
    "\n",
    "for epoch in range(1, num_epoch + 1): \n",
    "    start = time.time()\n",
    "    train_loss = train(model, train_loader, optimizer, criterion)[-1]\n",
    "    train_losses.append(train_loss)\n",
    "    _, _, val_loss, best_loss = val(model, val_loader, best_loss, criterion, name) \n",
    "    val_losses.append(val_loss)\n",
    "    best_loss = best_loss\n",
    "    end = time.time()\n",
    "    print(f\"Epoch: {epoch} completed in: {end - start}s. Training loss: {train_loss}. Val loss: {val_loss}\") \n",
    "    \n",
    "    scheduler.step() \n",
    "    if epoch % 5 == 0: print(optimizer.param_groups[0]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40bf991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, val_loss, best_loss = val_true(model, val_loader, best_loss, criterion, name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "911ebfe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4899429807608778"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8cdc1083",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, test_loss, best_loss = val_true(model, test_loader, best_loss, criterion, name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "77666bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7503080221159117"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5faef05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 24, 80])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = data_norm[1].unsqueeze(dim = 0).to(device)\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "01246685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0120, -1.0367, -1.0234, -1.0151, -1.0167, -1.0020, -0.8603, -1.0366,\n",
       "        -0.7483, -0.9782, -0.9445, -0.9412, -0.9398, -0.9197, -0.9352, -0.8993,\n",
       "        -0.9802, -0.9509, -0.9617, -0.9769, -0.9378,  0.2531, -0.9428, -0.9116,\n",
       "        -0.9673, -0.9580, -0.9093, -1.0052, -0.9688, -0.9609, -0.9761, -0.9457,\n",
       "        -0.9855, -0.9818, -0.9926, -0.9093, -1.0037, -1.0000, -0.9782, -0.9310,\n",
       "        -0.9146, -0.9850, -0.9981, -1.0138, -0.9507, -1.0365, -1.0365, -0.9677,\n",
       "        -0.9593, -0.9584, -0.9800, -0.9118, -0.9162, -0.8667, -0.9870, -0.9868,\n",
       "        -0.9496, -0.9653, -0.9729, -0.9662, -0.8962, -0.8402, -0.7919, -0.8443,\n",
       "        -0.7767, -0.9603, -0.9602, -0.9666, -0.9610, -0.9592, -0.9364, -0.9652,\n",
       "        -0.9510, -0.9741, -0.9672, -0.8974, -0.9910, -0.9601, -0.9142, -0.9507],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[0, 0, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "22ebf968",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = model(sample[:12], 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a15733f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 12, 80])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3f788021",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = training_data[1].unsqueeze(dim = 0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f4f287b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam[:, 0, :, :] = (sam[:, 0, :, :] - mean[0]) / std[0]\n",
    "sam[:, 1, :, :] = (sam[:, 1, :, :] - mean[1]) / std[1]\n",
    "sam[:, 2, :, :] = (sam[:, 2, :, :] - mean[2]) / std[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ab378b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9438, -0.9939, -0.9917,  ..., -0.8835, -0.8501, -0.8427],\n",
       "        [-0.9232, -0.9814, -0.9703,  ..., -0.9263, -0.8627, -0.8454],\n",
       "        [-0.9619, -0.9880, -0.9853,  ..., -0.9368, -0.8046, -0.8556],\n",
       "        ...,\n",
       "        [-0.9932, -1.0236, -1.0096,  ..., -0.9724, -0.9206, -0.9441],\n",
       "        [-0.9891, -1.0241, -1.0206,  ..., -0.9704, -0.9108, -0.9473],\n",
       "        [-1.0120, -1.0367, -1.0234,  ..., -0.9601, -0.9142, -0.9507]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1c1d0afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1[:, 0, :, :] = (pred1[:, 0, :, :] * std[0] + mean[0])\n",
    "pred1[:, 1, :, :] = (pred1[:, 1, :, :] * std[1] + mean[1])\n",
    "pred1[:, 2, :, :] = (pred1[:, 2, :, :] * std[2] + mean[2])\n",
    "                                \n",
    "sample[:, 0, :, :] = (sample[:, 0, :, :] * std[0] + mean[0])\n",
    "sample[:, 1, :, :] = (sample[:, 1, :, :] * std[1] + mean[1])\n",
    "sample[:, 2, :, :] = (sample[:, 2, :, :] * std[2] + mean[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b24c7ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1827, device='cuda:0', grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(pred1, sample[:, :, 12:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fc901dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2652, device='cuda:0', grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(pred1, sam[:, :, 12:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c18b61de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0009, 0.0001, 0.0006, 0.0008, 0.0008, 0.0013, 0.0060, 0.0001, 0.0097,\n",
       "        0.0021, 0.0032, 0.0033, 0.0033, 0.0040, 0.0035, 0.0047, 0.0020, 0.0030,\n",
       "        0.0026, 0.0021, 0.0034, 0.0430, 0.0032, 0.0043, 0.0024, 0.0027, 0.0044,\n",
       "        0.0012, 0.0024, 0.0026, 0.0021, 0.0031, 0.0018, 0.0019, 0.0016, 0.0044,\n",
       "        0.0012, 0.0013, 0.0021, 0.0036, 0.0042, 0.0018, 0.0014, 0.0009, 0.0030,\n",
       "        0.0001, 0.0001, 0.0024, 0.0027, 0.0027, 0.0020, 0.0043, 0.0041, 0.0058,\n",
       "        0.0018, 0.0018, 0.0030, 0.0025, 0.0022, 0.0025, 0.0048, 0.0067, 0.0083,\n",
       "        0.0065, 0.0088, 0.0027, 0.0027, 0.0024, 0.0026, 0.0027, 0.0035, 0.0025,\n",
       "        0.0030, 0.0022, 0.0024, 0.0047, 0.0016, 0.0027, 0.0042, 0.0030],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[0, 0, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7f6e299e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18311750880>]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(np.arange(80), pred1[0, 0, -1, :].cpu().detach().numpy())\n",
    "plt.plot(np.arange(80), sample[0, 0, -1, :].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b924907a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x183127f0b20>]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(np.arange(80), pred1[0, 1, -1, :].cpu().detach().numpy())\n",
    "plt.plot(np.arange(80), sample[0, 1, -1, :].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "990643b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x183191ff4c0>]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(np.arange(80), pred1[0, 2, -1, :].cpu().detach().numpy())\n",
    "plt.plot(np.arange(80), sample[0, 2, -1, :].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553b11a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "num_epoch = 100 \n",
    "\n",
    "for epoch in range(1, num_epoch + 1): \n",
    "    start = time.time()\n",
    "    train_loss = train(model, train_loader, optimizer, criterion)[-1]\n",
    "    train_losses.append(train_loss)\n",
    "    _, _, val_loss, best_loss = val(model, val_loader, best_loss, criterion, name) \n",
    "    val_losses.append(val_loss)\n",
    "    best_loss = best_loss\n",
    "    end = time.time()\n",
    "    print(f\"Epoch: {epoch} completed in: {end - start}s. Training loss: {train_loss}. Val loss: {val_loss}\") \n",
    "    \n",
    "    scheduler.step() \n",
    "    if epoch % 5 == 0: print(optimizer.param_groups[0]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f03f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb927b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 completed in: 8.313804864883423s. Training loss: 409.91368660056276. Val loss: 0.9922548248009249\n",
      "Epoch: 2 completed in: 8.409478664398193s. Training loss: 0.9552405627542421. Val loss: 0.9608251764015718\n",
      "Epoch: 3 completed in: 7.858785152435303s. Training loss: 0.9416561426692888. Val loss: 0.9519645463336598\n",
      "Epoch: 4 completed in: 7.829137325286865s. Training loss: 0.9340540572608772. Val loss: 0.9416836215691133\n",
      "Epoch: 5 completed in: 7.829220294952393s. Training loss: 0.9259938115352079. Val loss: 0.9388267722996798\n",
      "0.007737809374999999\n",
      "Epoch: 6 completed in: 7.797724723815918s. Training loss: 0.9225881301650876. Val loss: 0.9246533919464458\n",
      "Epoch: 7 completed in: 7.9079813957214355s. Training loss: 0.9072769045045501. Val loss: 0.9195777502926913\n",
      "Epoch: 8 completed in: 7.820415735244751s. Training loss: 0.9017188523552919. Val loss: 0.9144576056437059\n",
      "Epoch: 9 completed in: 7.830266952514648s. Training loss: 0.8973955829676828. Val loss: 0.9139095707373186\n",
      "Epoch: 10 completed in: 8.0868661403656s. Training loss: 0.89358273775954. Val loss: 0.9071230007843538\n",
      "0.005987369392383786\n",
      "Epoch: 11 completed in: 7.899218559265137s. Training loss: 0.8909093190572763. Val loss: 0.9065994105555795\n",
      "Epoch: 12 completed in: 7.368522882461548s. Training loss: 0.8880381209677771. Val loss: 0.9021334512667223\n",
      "Epoch: 13 completed in: 7.212588787078857s. Training loss: 0.8868391705971015. Val loss: 0.9028991799462925\n",
      "Epoch: 14 completed in: 7.767894983291626s. Training loss: 0.8840844984117308. Val loss: 0.8996789496053349\n",
      "Epoch: 15 completed in: 7.890259265899658s. Training loss: 0.8836371508475981. Val loss: 0.8990914916450327\n",
      "0.00463291230159753\n",
      "Epoch: 16 completed in: 7.81952977180481s. Training loss: 0.8819456733763218. Val loss: 0.8971634927121076\n",
      "Epoch: 17 completed in: 7.854947566986084s. Training loss: 0.8803961184856138. Val loss: 0.8951128016818654\n",
      "Epoch: 18 completed in: 7.790480613708496s. Training loss: 0.8792360509304624. Val loss: 0.8964048055085269\n",
      "Epoch: 19 completed in: 7.897785902023315s. Training loss: 0.8769662946854767. Val loss: 0.891412921927192\n",
      "Epoch: 20 completed in: 7.749918222427368s. Training loss: 0.8760303313794889. Val loss: 0.8906802738254721\n",
      "0.0035848592240854188\n",
      "Epoch: 21 completed in: 7.997805595397949s. Training loss: 0.8753353492601922. Val loss: 0.8910491927103563\n",
      "Epoch: 22 completed in: 7.769186496734619s. Training loss: 0.8742687643358582. Val loss: 0.8902443240989338\n",
      "Epoch: 23 completed in: 7.864126920700073s. Training loss: 0.874407318861861. Val loss: 0.8902078325098212\n",
      "Epoch: 24 completed in: 7.677419424057007s. Training loss: 0.8738461683847403. Val loss: 0.88907105949792\n",
      "Epoch: 25 completed in: 7.931649208068848s. Training loss: 0.873308957407349. Val loss: 0.888577944853089\n",
      "0.0027738957312183374\n",
      "Epoch: 26 completed in: 8.030166625976562s. Training loss: 0.8732020874556742. Val loss: 0.8893191936341199\n",
      "Epoch: 27 completed in: 7.77545166015625s. Training loss: 0.872398621157596. Val loss: 0.8886138403957541\n",
      "Epoch: 28 completed in: 7.7866387367248535s. Training loss: 0.8728955480221071. Val loss: 0.8884541676803068\n",
      "Epoch: 29 completed in: 7.795892238616943s. Training loss: 0.8719861103515876. Val loss: 0.8884378495541486\n",
      "Epoch: 30 completed in: 7.8876612186431885s. Training loss: 0.8722809792349213. Val loss: 0.8875995535742153\n",
      "0.0021463876394293723\n",
      "Epoch: 31 completed in: 7.806792736053467s. Training loss: 0.8715935249469782. Val loss: 0.8874770917675712\n",
      "Epoch: 32 completed in: 7.835932493209839s. Training loss: 0.8712438460635511. Val loss: 0.887214021249251\n",
      "Epoch: 33 completed in: 7.821974754333496s. Training loss: 0.871077828893536. Val loss: 0.8878712369637056\n",
      "Epoch: 34 completed in: 8.370899200439453s. Training loss: 0.8709583643235659. Val loss: 0.8866446113044565\n",
      "Epoch: 35 completed in: 8.129265069961548s. Training loss: 0.8708190555243116. Val loss: 0.8864978172562339\n",
      "0.0016608338398760713\n",
      "Epoch: 36 completed in: 7.896785736083984s. Training loss: 0.870434998093467. Val loss: 0.8858249390667136\n",
      "Epoch: 37 completed in: 7.912086248397827s. Training loss: 0.8696659117152816. Val loss: 0.8861137709834359\n",
      "Epoch: 38 completed in: 7.894523859024048s. Training loss: 0.8700441678887919. Val loss: 0.8859071988951076\n",
      "Epoch: 39 completed in: 7.793963432312012s. Training loss: 0.8696528714346258. Val loss: 0.885744564912536\n",
      "Epoch: 40 completed in: 7.818718671798706s. Training loss: 0.8690146062719194. Val loss: 0.884854407473044\n",
      "0.0012851215656510308\n",
      "Epoch: 41 completed in: 7.804227113723755s. Training loss: 0.8687786532467917. Val loss: 0.8842498470436443\n",
      "Epoch: 42 completed in: 7.84018611907959s. Training loss: 0.8684907641850019. Val loss: 0.8845380016348579\n",
      "Epoch: 43 completed in: 7.972460031509399s. Training loss: 0.868185562130652. Val loss: 0.8841851922598752\n",
      "Epoch: 44 completed in: 7.548877954483032s. Training loss: 0.8675952030247763. Val loss: 0.8836146389896219\n",
      "Epoch: 45 completed in: 7.569829702377319s. Training loss: 0.8673967515167437. Val loss: 0.8829143440181558\n",
      "0.000994402569870922\n",
      "Epoch: 46 completed in: 7.463048696517944s. Training loss: 0.8673339033205258. Val loss: 0.8829367513006384\n",
      "Epoch: 47 completed in: 7.578715085983276s. Training loss: 0.8665848237119222. Val loss: 0.8825816065073013\n",
      "Epoch: 48 completed in: 7.530712842941284s. Training loss: 0.8666943509719873. Val loss: 0.8822089867158369\n",
      "Epoch: 49 completed in: 7.517860174179077s. Training loss: 0.8661879642229331. Val loss: 0.8826630941846154\n",
      "Epoch: 50 completed in: 7.55648136138916s. Training loss: 0.8663024237673533. Val loss: 0.881736233830452\n",
      "0.0007694497527671312\n",
      "Epoch: 51 completed in: 7.519725322723389s. Training loss: 0.8661565686527052. Val loss: 0.8817971267483451\n",
      "Epoch: 52 completed in: 7.638703107833862s. Training loss: 0.8656813708183012. Val loss: 0.881656140089035\n",
      "Epoch: 53 completed in: 7.505691051483154s. Training loss: 0.8656419843043152. Val loss: 0.8817547451366078\n",
      "Epoch: 54 completed in: 7.565029621124268s. Training loss: 0.8652860832057501. Val loss: 0.881220893426375\n",
      "Epoch: 55 completed in: 7.623081684112549s. Training loss: 0.8649584454925436. Val loss: 0.881005041978576\n",
      "0.000595385551055294\n",
      "Epoch: 56 completed in: 7.5334632396698s. Training loss: 0.8648019146762396. Val loss: 0.8811400912024758\n",
      "Epoch: 57 completed in: 7.6344592571258545s. Training loss: 0.8645745445238916. Val loss: 0.880839158188213\n",
      "Epoch: 58 completed in: 8.191263914108276s. Training loss: 0.8645014008016962. Val loss: 0.8805961283770475\n",
      "Epoch: 59 completed in: 7.588672876358032s. Training loss: 0.864889271753399. Val loss: 0.8805033266544342\n",
      "Epoch: 60 completed in: 7.489883661270142s. Training loss: 0.8640819719355357. Val loss: 0.8804341771385886\n",
      "0.00046069798986951934\n",
      "Epoch: 61 completed in: 7.564307689666748s. Training loss: 0.864295480674819. Val loss: 0.8802924725142393\n",
      "Epoch: 62 completed in: 7.5017712116241455s. Training loss: 0.8641942229710127. Val loss: 0.880686342716217\n",
      "Epoch: 63 completed in: 7.589952707290649s. Training loss: 0.8641821589124831. Val loss: 0.8801973069256003\n",
      "Epoch: 64 completed in: 7.518665075302124s. Training loss: 0.8642526961078769. Val loss: 0.8799329576167193\n",
      "Epoch: 65 completed in: 7.554596185684204s. Training loss: 0.8638380948258074. Val loss: 0.8800587125799872\n",
      "0.00035647932250560207\n",
      "Epoch: 66 completed in: 7.524052381515503s. Training loss: 0.8633409456202858. Val loss: 0.8795989223501899\n",
      "Epoch: 67 completed in: 7.538071155548096s. Training loss: 0.8635037806081144. Val loss: 0.8794599310918287\n",
      "Epoch: 68 completed in: 8.167430639266968s. Training loss: 0.8634320413203616. Val loss: 0.8793437331914902\n",
      "Epoch: 69 completed in: 7.936278581619263s. Training loss: 0.8632442576712683. Val loss: 0.8793415386568416\n",
      "Epoch: 70 completed in: 7.607195854187012s. Training loss: 0.8629277977896365. Val loss: 0.8792800144715742\n",
      "0.00027583690436774953\n",
      "Epoch: 71 completed in: 7.5388572216033936s. Training loss: 0.8630865635840517. Val loss: 0.8790870945562016\n",
      "Epoch: 72 completed in: 7.4798314571380615s. Training loss: 0.8628326985788973. Val loss: 0.8791058415716345\n",
      "Epoch: 73 completed in: 7.529775142669678s. Training loss: 0.862842319435195. Val loss: 0.8789174096150831\n",
      "Epoch: 74 completed in: 7.475098609924316s. Training loss: 0.8625121779347721. Val loss: 0.8788794807412408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75 completed in: 7.497751474380493s. Training loss: 0.8625136535418662. Val loss: 0.8787609176202253\n",
      "0.00021343733845877503\n",
      "Epoch: 76 completed in: 7.489464282989502s. Training loss: 0.8627201626567464. Val loss: 0.8787498054179278\n",
      "Epoch: 77 completed in: 7.573403358459473s. Training loss: 0.8625641920064625. Val loss: 0.8786634017120708\n",
      "Epoch: 78 completed in: 7.7927985191345215s. Training loss: 0.8627473347281155. Val loss: 0.878494683991779\n",
      "Epoch: 79 completed in: 7.548799753189087s. Training loss: 0.862122374537744. Val loss: 0.8784645687450062\n",
      "Epoch: 80 completed in: 7.56614875793457s. Training loss: 0.8624633285952242. Val loss: 0.8784158866513859\n",
      "0.00016515374385013573\n",
      "Epoch: 81 completed in: 7.533100128173828s. Training loss: 0.8620813055650184. Val loss: 0.878429498184811\n",
      "Epoch: 82 completed in: 7.517958641052246s. Training loss: 0.8623767810824671. Val loss: 0.878405594012954\n",
      "Epoch: 83 completed in: 7.5636913776397705s. Training loss: 0.8617579382109014. Val loss: 0.8783376907760446\n",
      "Epoch: 84 completed in: 7.55548095703125s. Training loss: 0.8620127584589156. Val loss: 0.878270070661198\n",
      "Epoch: 85 completed in: 7.560029983520508s. Training loss: 0.8626009906200987. Val loss: 0.8782557967034254\n",
      "0.00012779281874799285\n",
      "Epoch: 86 completed in: 7.574664354324341s. Training loss: 0.8622791053433168. Val loss: 0.8783343366601251\n",
      "Epoch: 87 completed in: 7.4957239627838135s. Training loss: 0.8618919639603088. Val loss: 0.8783779577775435\n",
      "Epoch: 88 completed in: 7.542429447174072s. Training loss: 0.862155061607298. Val loss: 0.8782042860984802\n",
      "Epoch: 89 completed in: 7.732555150985718s. Training loss: 0.8622375599255687. Val loss: 0.8781531128016385\n",
      "Epoch: 90 completed in: 8.371886968612671s. Training loss: 0.8617717084523878. Val loss: 0.8781900554895401\n",
      "9.888364709658946e-05\n",
      "Epoch: 91 completed in: 7.7561728954315186s. Training loss: 0.8619918199746233. Val loss: 0.8780743344263597\n",
      "Epoch: 92 completed in: 8.374530792236328s. Training loss: 0.8617543152680522. Val loss: 0.8780426884239371\n",
      "Epoch: 93 completed in: 7.892087697982788s. Training loss: 0.8618297255352924. Val loss: 0.8780272657221014\n",
      "Epoch: 94 completed in: 7.560364484786987s. Training loss: 0.8615675982283918. Val loss: 0.8779750683090903\n",
      "Epoch: 95 completed in: 7.514960050582886s. Training loss: 0.8619006125158385. Val loss: 0.8779550465670499\n",
      "7.651428115381812e-05\n",
      "Epoch: 96 completed in: 7.549015522003174s. Training loss: 0.8616636624853862. Val loss: 0.8779700141061436\n",
      "Epoch: 97 completed in: 7.671229600906372s. Training loss: 0.8613096118757599. Val loss: 0.8779330863194033\n",
      "Epoch: 98 completed in: 7.5456860065460205s. Training loss: 0.8618292890881237. Val loss: 0.8779370771213011\n",
      "Epoch: 99 completed in: 7.687641620635986s. Training loss: 0.862038515312107. Val loss: 0.8779563280669126\n",
      "Epoch: 100 completed in: 7.514613151550293s. Training loss: 0.8614608551326551. Val loss: 0.8780008974400434\n",
      "5.920529220333995e-05\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_epoch = 100 \n",
    "\n",
    "for epoch in range(1, num_epoch + 1): \n",
    "    start = time.time()\n",
    "    train_loss = train(model, train_loader, optimizer, criterion)[-1]\n",
    "    train_losses.append(train_loss)\n",
    "    _, _, val_loss, best_loss = val(model, val_loader, best_loss, criterion, name) \n",
    "    val_losses.append(val_loss)\n",
    "    best_loss = best_loss\n",
    "    end = time.time()\n",
    "    print(f\"Epoch: {epoch} completed in: {end - start}s. Training loss: {train_loss}. Val loss: {val_loss}\") \n",
    "    \n",
    "    scheduler.step() \n",
    "    if epoch % 5 == 0: print(optimizer.param_groups[0]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58edafb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, val_loss, best_loss = val_true(model, val_loader, best_loss, criterion, name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94f7a96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.324819705703042"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c53abe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, test_loss, best_loss = val_true(model, test_loader, best_loss, criterion, name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27511ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.285899019241333"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f35bc8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running batch 0\n",
      "running batch 5\n",
      "running batch 10\n",
      "running batch 15\n",
      "running batch 20\n",
      "running batch 25\n",
      "running batch 30\n",
      "running batch 35\n",
      "running batch 40\n",
      "running batch 45\n",
      "running batch 50\n",
      "running batch 55\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\STEPHE~1\\AppData\\Local\\Temp/ipykernel_228572/3740666141.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\STEPHE~1\\AppData\\Local\\Temp/ipykernel_228572/599015187.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, criterion)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#         y = y.reshape((y.shape[0], -1))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\STEPHE~1\\AppData\\Local\\Temp/ipykernel_228572/1515444648.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, output_length)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m#         print(torch.flip(xx, [1]).shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mz0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mpred_z\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0modeint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_z\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m#         print(out.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_pytorch\\lib\\site-packages\\torchdiffeq\\_impl\\odeint.py\u001b[0m in \u001b[0;36modeint\u001b[1;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mevent_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0msolution\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mevent_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolution\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintegrate_until_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_pytorch\\lib\\site-packages\\torchdiffeq\\_impl\\solvers.py\u001b[0m in \u001b[0;36mintegrate\u001b[1;34m(self, t)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_before_integrate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0msolution\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_advance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msolution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_pytorch\\lib\\site-packages\\torchdiffeq\\_impl\\rk_common.py\u001b[0m in \u001b[0;36m_advance\u001b[1;34m(self, next_t)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mnext_t\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mn_steps\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_num_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'max_num_steps exceeded ({}>={})'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_num_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrk_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_adaptive_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m             \u001b[0mn_steps\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_interp_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterp_coeff\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrk_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_pytorch\\lib\\site-packages\\torchdiffeq\\_impl\\rk_common.py\u001b[0m in \u001b[0;36m_adaptive_step\u001b[1;34m(self, rk_state)\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[1;31m# trigger both. (i.e. interleaving them would be wrong.)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0my1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my1_error\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_runge_kutta_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtableau\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtableau\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m         \u001b[1;31m# dtypes:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;31m# y1.dtype == self.y0.dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env_pytorch\\lib\\site-packages\\torchdiffeq\\_impl\\rk_common.py\u001b[0m in \u001b[0;36m_runge_kutta_step\u001b[1;34m(func, y0, f0, t0, dt, t1, tableau)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_UncheckedAssign\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0malpha_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_i\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtableau\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtableau\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0malpha_i\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[1;31m# Always step to perturbing just before the end time, in case of discontinuities.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mti\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_epoch = 100 \n",
    "\n",
    "for epoch in range(1, num_epoch + 1): \n",
    "    start = time.time()\n",
    "    train_loss = train(model, train_loader, optimizer, criterion)[-1]\n",
    "    train_losses.append(train_loss)\n",
    "    _, _, val_loss, best_loss = val(model, val_loader, best_loss, criterion, name) \n",
    "    val_losses.append(val_loss)\n",
    "    best_loss = best_loss\n",
    "    end = time.time()\n",
    "    print(f\"Epoch: {epoch} completed in: {end - start}s. Training loss: {train_loss}. Val loss: {val_loss}\") \n",
    "    \n",
    "    scheduler.step() \n",
    "    if epoch % 5 == 0: print(optimizer.param_groups[0]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e606c47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
